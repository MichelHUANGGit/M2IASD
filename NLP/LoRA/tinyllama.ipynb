{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huang\\Desktop\\M2IASD\\NLP\\env311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from lora import count_parameters, apply_LoRA_tinyllama, save_AB_weights_tinyllama, load_AB_weights_tinyllama\n",
    "# from transformers import BitsAndBytesConfig\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_use_double_quant=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=torch.bfloat16\n",
    "# )\n",
    "\n",
    "model_id = \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\huang\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\tuetschek--e2e_nlg\\bfeceb720929c2705bd227d1cfe5eaaab102a0bdac10dad618dac1e00c737430 (last modified on Sun Jun 16 15:39:04 2024) since it couldn't be found locally at tuetschek/e2e_nlg, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from data_utils import DataCollator, CustomDataCollator, CustomDataLoader, preprocess_fn, get_tokenizer\n",
    "tokenizer = get_tokenizer()\n",
    "dataset = load_dataset(\"tuetschek/e2e_nlg\")\n",
    "dataset = dataset.map(preprocess_fn, fn_kwargs={\"tokenizer\":tokenizer})\n",
    "device = torch.device(\"cuda\")\n",
    "data_collator = DataCollator(pad_token_id=32000, max_length=256, device=device)\n",
    "train_loader = iter(DataLoader(dataset=dataset[\"train\"], batch_size=16, collate_fn=data_collator)) # type: ignore\n",
    "batch = next(train_loader)\n",
    "collate_fn = CustomDataCollator(pad_token_id=32000, max_length=256, device=device)\n",
    "loader = CustomDataLoader(dataset[\"train\"], batch_size=16, collate_fn=collate_fn) # type: ignore\n",
    "batch_ = loader.next_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time as t\n",
    "\n",
    "train_loader = iter(DataLoader(dataset=dataset[\"train\"], batch_size=16, collate_fn=data_collator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.645299434661865\n"
     ]
    }
   ],
   "source": [
    "t0 = t()\n",
    "for i in range(2629):\n",
    "    batch_ = loader.next_batch()\n",
    "    if len(batch_['input_ids']) != 16:\n",
    "        print(len(batch_['input_ids']))\n",
    "print(t()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "6.414844274520874\n"
     ]
    }
   ],
   "source": [
    "t0 = t()\n",
    "for i in range(2629):\n",
    "    batch = next(train_loader)\n",
    "    if len(batch['input_ids']) != 16:\n",
    "        print(len(batch['input_ids']))\n",
    "print(t()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CustomDataLoader(dataset[\"train\"], batch_size=1, collate_fn=collate_fn) # type: ignore\n",
    "batch = loader.next_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zizzi is a one star rated pub that is family friendly.</s>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmask = batch['loss_mask']\n",
    "tokenizer.decode(batch['input_ids'][lmask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zizzi is a one star rated pub that is family friendly.</s>'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(batch['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Trainable parameters: 1,100,052,480\n",
      "After Trainable parameters: 563,200\n"
     ]
    }
   ],
   "source": [
    "LoRA_llama = apply_LoRA_tinyllama(target_layers=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"], r=2, new_vocsize=32001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32001, 2048]), torch.Size([32001, 2048]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LoRA_llama.lm_head.weight.shape, LoRA_llama.model.embed_tokens.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LoRA_llama.lm_head.weight.data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LoRA_llama.model.layers[0].self_attn.q_proj.B.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_AB_weights_tinyllama(\n",
    "    save_dir=r\"logs\\2024-06-27\\run1\\model_weights\", \n",
    "    model=LoRA_llama, \n",
    "    target_layers=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0015, -0.0024, -0.0068,  ...,  0.0053, -0.0010, -0.0134],\n",
       "        [ 0.0026,  0.0059, -0.0177,  ...,  0.0006,  0.0005,  0.0106],\n",
       "        [-0.0004,  0.0018, -0.0181,  ...,  0.0070,  0.0017, -0.0108],\n",
       "        ...,\n",
       "        [ 0.0151, -0.0018,  0.0112,  ..., -0.0061,  0.0195, -0.0146],\n",
       "        [-0.0168, -0.0021, -0.0069,  ...,  0.0039, -0.0183,  0.0141],\n",
       "        [-0.0165, -0.0016, -0.0076,  ...,  0.0041, -0.0182,  0.0143]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LoRA_llama.model.layers[0].self_attn.q_proj.base_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32002, 2048)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from LoRA.data_utils import get_tokenizer\n",
    "tokenizer = get_tokenizer()\n",
    "LoRA_llama.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32002, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-21): 22 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): LoRA_Linear(\n",
       "            (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (B): Linear(in_features=2048, out_features=2, bias=False)\n",
       "            (A): Linear(in_features=2, out_features=2048, bias=False)\n",
       "          )\n",
       "          (k_proj): LoRA_Linear(\n",
       "            (base_layer): Linear(in_features=2048, out_features=256, bias=False)\n",
       "            (B): Linear(in_features=2048, out_features=2, bias=False)\n",
       "            (A): Linear(in_features=2, out_features=256, bias=False)\n",
       "          )\n",
       "          (v_proj): LoRA_Linear(\n",
       "            (base_layer): Linear(in_features=2048, out_features=256, bias=False)\n",
       "            (B): Linear(in_features=2048, out_features=2, bias=False)\n",
       "            (A): Linear(in_features=2, out_features=256, bias=False)\n",
       "          )\n",
       "          (o_proj): LoRA_Linear(\n",
       "            (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (B): Linear(in_features=2048, out_features=2, bias=False)\n",
       "            (A): Linear(in_features=2, out_features=2048, bias=False)\n",
       "          )\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=32002, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "LoRA_llama.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "B,L = 4,256\n",
    "vocsize = tokenizer.vocab_size\n",
    "device = torch.device(\"cuda\")\n",
    "random_inputs = torch.randint(low=0, high=vocsize, size=(B,L)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huang\\Desktop\\M2IASD\\NLP\\env311\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:649: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = LoRA_llama(random_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256, 32002])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"tuetschek/e2e_nlg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 12953, 29901, 13]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Description:\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fn(sample, tokenizer):\n",
    "    input_ids = tokenizer.encode(sample[\"meaning_representation\"] + \"\\n Description:\\n\")\n",
    "    labels = tokenizer.encode(sample[\"human_reference\"] + \"</s>\", add_special_tokens=False)\n",
    "    return dict(input_ids=input_ids, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 42061/42061 [00:10<00:00, 3980.97 examples/s]\n",
      "Map: 100%|██████████| 4672/4672 [00:01<00:00, 3707.07 examples/s]\n",
      "Map: 100%|██████████| 4693/4693 [00:01<00:00, 3529.59 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(preprocess_fn, fn_kwargs={\"tokenizer\":tokenizer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['meaning_representation', 'human_reference', 'input_ids', 'labels', 'length'])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = dataset[\"train\"][0]\n",
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> name[The Vaults], eatType[pub], priceRange[more than £30], customer rating[5 out of 5], near[Café Adriatic]\n",
      " Description:\n",
      "\n",
      "42\n",
      "The Vaults pub near Café Adriatic has a 5 star rating.  Prices start at £30.</s>\n"
     ]
    }
   ],
   "source": [
    "len(sample[\"input_ids\"])\n",
    "print(tokenizer.decode(sample[\"input_ids\"]))\n",
    "print(len(sample[\"input_ids\"]))\n",
    "print(tokenizer.decode(sample[\"labels\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataCollator:\n",
    "    \n",
    "    def __init__(self, pad_token_id, max_length, device):\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.max_length = max_length\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, batch:list[dict]):\n",
    "        '''\n",
    "        The input of the model should be the restaurant description + <sep> + human_reference, as the model is pre-trained to predict the next token\n",
    "        it'll do a next token prediction, if it were perfect, we'd have a shifted (by 1) input.\n",
    "        We can then define the targets as the shifted input, and compute a loss. \n",
    "        The loss should only be computed for tokens after '<sep>'.\n",
    "        '''\n",
    "        batch_size = len(batch)\n",
    "        input_ids = [sample['input_ids'] + sample['labels'] for sample in batch]\n",
    "        attention_mask = torch.zeros(size=(batch_size, self.max_length,), dtype=torch.bool)\n",
    "        loss_mask = torch.zeros(size=(batch_size, self.max_length,), dtype=torch.bool)\n",
    "        for i, sample in enumerate(batch):\n",
    "            attention_mask[i, :len(input_ids[i])] = 1\n",
    "            loss_mask[i, len(sample['input_ids']):len(sample['input_ids'])+len(sample['labels'])] = True\n",
    "            current_length = len(input_ids[i])\n",
    "            input_ids[i] += [self.pad_token_id]*(self.max_length-current_length)\n",
    "        input_ids = torch.tensor(input_ids, dtype=torch.int16)\n",
    "        labels = torch.cat([torch.tensor(sample[\"labels\"], dtype=torch.int64) for sample in batch])\n",
    "        return dict(input_ids=input_ids, attention_mask=attention_mask, loss_mask=loss_mask, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "collate_fn = DataCollator(32000, 128, None)\n",
    "loader = DataLoader(dataset[\"train\"], batch_size=4, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'loss_mask', 'labels'])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(loader))\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    1,  1024, 29961,  1576,   478,  1292, 29879,  1402, 17545,  1542,\n",
       "        29961,  5467,  1402,  8666,  6069, 29961,  5514,  1135, 15151, 29941,\n",
       "        29900,  1402, 11962, 21700, 29961, 29945,   714,   310, 29871, 29945,\n",
       "         1402,  2978, 29961, 29907, 28059, 27449,  2454, 29962,    13, 12953,\n",
       "        29901,    13,   450,   478,  1292, 29879,  2529,  2978,   315, 28059,\n",
       "        27449,  2454,   756,   263, 29871, 29945,  5810, 21700, 29889, 29871,\n",
       "         1588,  1575,  1369,   472, 15151, 29941, 29900, 29889,     2, 32000,\n",
       "        32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "        32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "        32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "        32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "        32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "        32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert batch[\"input_ids\"][batch[\"loss_mask\"]].shape == batch[\"labels\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch['input_ids'][losk_mask] : The Vaults pub near Café Adriatic has a 5 star rating.  Prices start at £30.</s> Close to Café Brazil, The Cambridge Blue pub serves delicious Tuscan Beef for the cheap price of £10.50. Delicious Pub food.</s> The Eagle is a low rated coffee shop near Burger King and the riverside that is family friendly and is less than £20 for Japanese food.</s> Located near The Sorrento is a French Theme eatery and coffee shop called The Mill, with a price range at £20-£25 it is in the riverside area.</s>\n",
      "actual label : The Vaults pub near Café Adriatic has a 5 star rating.  Prices start at £30.</s> Close to Café Brazil, The Cambridge Blue pub serves delicious Tuscan Beef for the cheap price of £10.50. Delicious Pub food.</s> The Eagle is a low rated coffee shop near Burger King and the riverside that is family friendly and is less than £20 for Japanese food.</s> Located near The Sorrento is a French Theme eatery and coffee shop called The Mill, with a price range at £20-£25 it is in the riverside area.</s>\n"
     ]
    }
   ],
   "source": [
    "print(\"batch['input_ids'][losk_mask] :\", tokenizer.decode(batch[\"input_ids\"][batch['loss_mask']]))\n",
    "print(\"actual label :\", tokenizer.decode(batch[\"labels\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([139])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"labels\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import get_tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 1024, 29961, 1576, 21139, 10335, 15472, 1402, 17545, 1542, 29961, 29878, 22837, 424, 1402, 9687, 29961, 10512, 713, 1402, 8666, 6069, 29961, 5514, 1135, 15151, 29941, 29900, 1822, 13, 9868, 29901, 13, 1576, 478, 1292, 29879, 2529, 2978, 315, 28059, 27449, 2454, 756, 263, 29871, 29945, 5810, 21700, 29889, 29871, 1588, 1575, 1369, 472, 15151, 29941, 29900, 29889, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = tokenizer(\n",
    "    dataset[\"train\"][25615]['meaning_representation']+'.\\nDescription:\\n'+dataset[\"train\"][0]['human_reference'],\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    ")\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 1024, 29961, 1576, 21139, 10335, 15472, 1402, 17545, 1542, 29961, 29878, 22837, 424, 1402, 9687, 29961, 10512, 713, 1402, 8666, 6069, 29961, 5514, 1135, 15151, 29941, 29900, 1822, 13, 9868, 29901, 13, 1576, 478, 1292, 29879, 2529, 2978, 315, 28059, 27449, 2454, 756, 263, 29871, 29945, 5810, 21700, 29889, 29871, 1588, 1575, 1369, 472, 15151, 29941, 29900, 29889, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2 = tokenizer(\n",
    "    dataset[\"train\"][25615]['meaning_representation']+'.\\nDescription:\\n'+dataset[\"train\"][0]['human_reference'],\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    ")\n",
    "\n",
    "out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> name[The Vaults], eatType[pub], priceRange[more than £30], customer rating[5 out of 5], near[Café Adriatic].\n",
      "Description:\n",
      "The Vaults pub near Café Adriatic has a 5 star rating.  Prices start at £30.\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1024,\n",
       " 29961,\n",
       " 1576,\n",
       " 478,\n",
       " 1292,\n",
       " 29879,\n",
       " 1402,\n",
       " 17545,\n",
       " 1542,\n",
       " 29961,\n",
       " 5467,\n",
       " 1402,\n",
       " 8666,\n",
       " 6069,\n",
       " 29961,\n",
       " 5514,\n",
       " 1135,\n",
       " 15151,\n",
       " 29941,\n",
       " 29900,\n",
       " 1402,\n",
       " 11962,\n",
       " 21700,\n",
       " 29961,\n",
       " 29945,\n",
       " 714,\n",
       " 310,\n",
       " 29871,\n",
       " 29945,\n",
       " 1402,\n",
       " 2978,\n",
       " 29961,\n",
       " 29907,\n",
       " 28059,\n",
       " 27449,\n",
       " 2454,\n",
       " 1822,\n",
       " 13,\n",
       " 9868,\n",
       " 29901,\n",
       " 13,\n",
       " 1576,\n",
       " 478,\n",
       " 1292,\n",
       " 29879,\n",
       " 2529,\n",
       " 2978,\n",
       " 315,\n",
       " 28059,\n",
       " 27449,\n",
       " 2454,\n",
       " 756,\n",
       " 263,\n",
       " 29871,\n",
       " 29945,\n",
       " 5810,\n",
       " 21700,\n",
       " 29889,\n",
       " 29871,\n",
       " 1588,\n",
       " 1575,\n",
       " 1369,\n",
       " 472,\n",
       " 15151,\n",
       " 29941,\n",
       " 29900,\n",
       " 29889]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\n",
    "    dataset[\"train\"][0]['meaning_representation']+'.\\nDescription:\\n'+dataset[\"train\"][0]['human_reference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([29900, 29889])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_data(sample):\n",
    "#     return tokenizer(sample[\"text\"])\n",
    "\n",
    "data = load_dataset(\"tatsu-lab/alpaca\")\n",
    "data = data.map(process_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meaning_representation': 'name[The Vaults], eatType[pub], priceRange[more than £30], customer rating[5 out of 5], near[Café Adriatic]',\n",
       " 'human_reference': 'The Vaults pub near Café Adriatic has a 5 star rating.  Prices start at £30.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from LoRA.data_utils import DataCollator\n",
    "\n",
    "collate_fn = DataCollator(tokenizer, 256, device)\n",
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = tokenizer(train[0][\"meaning_representation\"]+\"<sep>\", max_length=256, truncation=True, padding=\"max_length\")\n",
    "sample[\"input_ids\"] = torch.tensor(sample[\"input_ids\"]).view(-1,1).to(device)\n",
    "sample[\"attention_mask\"] = torch.tensor(sample[\"attention_mask\"]).view(-1,1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1],\n",
       "        [ 1024],\n",
       "        [29961],\n",
       "        [ 1576],\n",
       "        [  478],\n",
       "        [ 1292],\n",
       "        [29879],\n",
       "        [ 1402],\n",
       "        [17545],\n",
       "        [ 1542],\n",
       "        [29961],\n",
       "        [ 5467],\n",
       "        [ 1402],\n",
       "        [ 8666],\n",
       "        [ 6069],\n",
       "        [29961],\n",
       "        [ 5514],\n",
       "        [ 1135],\n",
       "        [15151],\n",
       "        [29941],\n",
       "        [29900],\n",
       "        [ 1402],\n",
       "        [11962],\n",
       "        [21700],\n",
       "        [29961],\n",
       "        [29945],\n",
       "        [  714],\n",
       "        [  310],\n",
       "        [29871],\n",
       "        [29945],\n",
       "        [ 1402],\n",
       "        [ 2978],\n",
       "        [29961],\n",
       "        [29907],\n",
       "        [28059],\n",
       "        [27449],\n",
       "        [ 2454],\n",
       "        [29962],\n",
       "        [32001],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000],\n",
       "        [32000]], device='cuda:0'), 'attention_mask': tensor([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]], device='cuda:0')}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = tokenizer(train[0][\"meaning_representation\"])\n",
    "# sample[\"input_ids\"].append(tokenizer.sep_token_id)\n",
    "# sample[\"input_ids\"] = torch.tensor(sample[\"input_ids\"])\n",
    "# sample[\"attention_mask\"] = torch.tensor(sample[\"attention_mask\"])\n",
    "sample.append(tokenizer.sep_token_id)\n",
    "sample = torch.tensor(sample).to(device)\n",
    "# sample.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    1,  1024, 29961,  1576,   478,  1292, 29879,  1402, 17545,  1542,\n",
       "        29961,  5467,  1402,  8666,  6069, 29961,  5514,  1135, 15151, 29941,\n",
       "        29900,  1402, 11962, 21700, 29961, 29945,   714,   310, 29871, 29945,\n",
       "         1402,  2978, 29961, 29907, 28059, 27449,  2454, 29962, 32001],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 2\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mLoRA_llama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\M2IASD\\NLP\\env311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\M2IASD\\NLP\\env311\\Lib\\site-packages\\transformers\\generation\\utils.py:1758\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1750\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1751\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1752\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   1753\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1754\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1755\u001b[0m     )\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 1758\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1759\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1762\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1764\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1766\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1767\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1769\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   1770\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[0;32m   1771\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1772\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config) \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1773\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\M2IASD\\NLP\\env311\\Lib\\site-packages\\transformers\\generation\\utils.py:2392\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[0;32m   2389\u001b[0m unfinished_sequences \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(batch_size, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   2390\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_initial_cache_position(input_ids, model_kwargs)\n\u001b[1;32m-> 2392\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_unfinished_sequences(this_peer_finished, synced_gpus, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice):\n\u001b[0;32m   2393\u001b[0m     \u001b[38;5;66;03m# prepare model inputs\u001b[39;00m\n\u001b[0;32m   2394\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   2396\u001b[0m     \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = LoRA_llama.generate(**sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1, 32002])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ment'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(out.logits[-1,0,:].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description: name[The Rice Boat], food[Italian], customer rating[low], area[riverside], familyFriendly[yes]\n",
      "model output: <s> name[The Rice Boat], food[Italian], customer rating[low], area[riverside], familyFriendly[yes]<sep> The Waterman is a family friendly restaurant in the riverside. It is located near The Rice\n",
      "human reference: North of the city centre, overlooking the river, is a family restaurant named The Rice Boat. It serves Italian food and is rated 1 star.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def see_prediction(sample):\n",
    "    text = sample[\"meaning_representation\"] + \"<sep>\"\n",
    "    text = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    outputs = LoRA_llama.generate(**text, max_new_tokens=20)\n",
    "    print(\"Description:\", sample[\"meaning_representation\"])\n",
    "    print(\"model output:\", tokenizer.decode(outputs[0]))\n",
    "    print(\"human reference:\", sample[\"human_reference\"])\n",
    "\n",
    "    \n",
    "sample_id = random.randint(0,100)\n",
    "sample = train[sample_id]\n",
    "see_prediction(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 39])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest input_text (MR+HR): 442\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "split = \"train\"\n",
    "input_lengths = np.array(\n",
    "    [len(dataset[split][i][\"human_reference\"])+ len(dataset[split][i][\"meaning_representation\"])\n",
    "    for i in range(len(dataset[split]))]\n",
    ")\n",
    "print(\"Longest input_text (MR+HR):\", np.max(input_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAGdCAYAAADjWSL8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAlaElEQVR4nO3dfXBU1f3H8c9CyALCboyQLBkDIlgw5UEEDFuVnzaZJBipVjpTlCq2CANNHCGKEGvxoQ+h0Ae1VRzHFuwU60NH0JKKxmBC1YASjRDUVGgwUNiEgtkFhPCQ8/uDyS0LAZKYp7N5v2buTPbeszfnywH2M+fee9ZljDECAACwTLeO7gAAAEBLEGIAAICVCDEAAMBKhBgAAGAlQgwAALASIQYAAFiJEAMAAKxEiAEAAFaK6ugOtJX6+nrt3r1bffv2lcvl6ujuAACAJjDG6MCBA0pISFC3bueea4nYELN7924lJiZ2dDcAAEAL7Ny5UxdffPE520RsiOnbt6+kk38IHo+ng3sDAACaIhQKKTEx0fkcP5eIDTENl5A8Hg8hBgAAyzTlVpBm3dibl5en8ePHq2/fvoqLi9PNN9+sioqKsDbXXXedXC5X2DZ79uywNlVVVcrMzFTv3r0VFxen+fPn6/jx42FtioqKdOWVV8rtdmvo0KFasWJFc7oKAAAiXLNCTHFxsbKysrRhwwYVFBTo2LFjSktL06FDh8LazZw5U3v27HG2JUuWOMdOnDihzMxMHT16VO+9956ee+45rVixQosWLXLaVFZWKjMzU9dff73Kyso0d+5c3XXXXXrjjTe+ZrkAACBSuIwxpqVv3rt3r+Li4lRcXKyJEydKOjkTc8UVV+ixxx5r9D2vv/66brzxRu3evVvx8fGSpKeffloLFizQ3r17FR0drQULFig/P1/l5eXO+6ZOnara2lqtXbu2SX0LhULyer0KBoNcTgIAwBLN+fz+WuvEBINBSVJsbGzY/pUrV6pfv34aMWKEcnNz9dVXXznHSkpKNHLkSCfASFJ6erpCoZC2bt3qtElNTQ07Z3p6ukpKSs7al7q6OoVCobANAABErhbf2FtfX6+5c+fq6quv1ogRI5z9t912mwYNGqSEhARt3rxZCxYsUEVFhV555RVJUiAQCAswkpzXgUDgnG1CoZAOHz6sXr16ndGfvLw8PfLIIy0tBwAAWKbFISYrK0vl5eV65513wvbPmjXL+XnkyJEaMGCAUlJStH37dg0ZMqTlPT2P3Nxc5eTkOK8bHtECAACRqUWXk7Kzs7VmzRq9/fbb512IJjk5WZK0bds2SZLP51N1dXVYm4bXPp/vnG08Hk+jszCS5Ha7ncepeawaAIDI16wQY4xRdna2Vq1apXXr1mnw4MHnfU9ZWZkkacCAAZIkv9+vLVu2qKamxmlTUFAgj8ejpKQkp01hYWHYeQoKCuT3+5vTXQAAEMGaFWKysrL0l7/8Rc8//7z69u2rQCCgQCCgw4cPS5K2b9+un/3sZyotLdWOHTv02muv6Y477tDEiRM1atQoSVJaWpqSkpJ0++236+OPP9Ybb7yhBx98UFlZWXK73ZKk2bNn69///rfuv/9+ffbZZ3rqqaf00ksvad68ea1cPgAAsFWzHrE+2+p5y5cv15133qmdO3fqBz/4gcrLy3Xo0CElJibqu9/9rh588MGwyztffPGF5syZo6KiIl1wwQWaPn26Fi9erKio/92iU1RUpHnz5umTTz7RxRdfrJ/+9Ke68847m1wYj1gDAGCf5nx+f611YjozQgwAAPZpt3ViAAAAOgohBgAAWIkQAwAArNTixe6AruiShfnnbbNjcWY79AQAwEwMAACwEiEGAABYiRADAACsRIgBAABWIsQAAAArEWIAAICVCDEAAMBKhBgAAGAlQgwAALASIQYAAFiJEAMAAKxEiAEAAFYixAAAACsRYgAAgJUIMQAAwEqEGAAAYCVCDAAAsBIhBgAAWIkQAwAArESIAQAAViLEAAAAKxFiAACAlQgxAADASoQYAABgJUIMAACwEiEGAABYiRADAACsRIgBAABWIsQAAAArEWIAAICVCDEAAMBKhBgAAGAlQgwAALASIQYAAFiJEAMAAKwU1dEdANC4Sxbmn7fNjsWZ7dATAOicmIkBAABWIsQAAAArEWIAAICVCDEAAMBKhBgAAGAlQgwAALASIQYAAFiJEAMAAKxEiAEAAFYixAAAACsRYgAAgJUIMQAAwEqEGAAAYCVCDAAAsBIhBgAAWIkQAwAArESIAQAAViLEAAAAKxFiAACAlQgxAADASoQYAABgpWaFmLy8PI0fP159+/ZVXFycbr75ZlVUVIS1OXLkiLKysnTRRRepT58+mjJliqqrq8PaVFVVKTMzU71791ZcXJzmz5+v48ePh7UpKirSlVdeKbfbraFDh2rFihUtqxBoZ5cszD/vBgD4+poVYoqLi5WVlaUNGzaooKBAx44dU1pamg4dOuS0mTdvnv7+97/r5ZdfVnFxsXbv3q1bbrnFOX7ixAllZmbq6NGjeu+99/Tcc89pxYoVWrRokdOmsrJSmZmZuv7661VWVqa5c+fqrrvu0htvvNEKJQMAgEjgMsaYlr557969iouLU3FxsSZOnKhgMKj+/fvr+eef1/e+9z1J0meffabLL79cJSUlmjBhgl5//XXdeOON2r17t+Lj4yVJTz/9tBYsWKC9e/cqOjpaCxYsUH5+vsrLy53fNXXqVNXW1mrt2rVN6lsoFJLX61UwGJTH42lpiUCY1ppF2bE4s1V+V1POAwA2ac7n99e6JyYYDEqSYmNjJUmlpaU6duyYUlNTnTbDhw/XwIEDVVJSIkkqKSnRyJEjnQAjSenp6QqFQtq6davT5tRzNLRpOEdj6urqFAqFwjYAABC5olr6xvr6es2dO1dXX321RowYIUkKBAKKjo5WTExMWNv4+HgFAgGnzakBpuF4w7FztQmFQjp8+LB69ep1Rn/y8vL0yCOPtLQcoF1xXwwAfH0tnonJyspSeXm5XnjhhdbsT4vl5uYqGAw6286dOzu6SwAAoA21aCYmOztba9as0fr163XxxRc7+30+n44ePara2tqw2Zjq6mr5fD6nzfvvvx92voanl05tc/oTTdXV1fJ4PI3OwkiS2+2W2+1uSTkAAMBCzZqJMcYoOztbq1at0rp16zR48OCw42PHjlWPHj1UWFjo7KuoqFBVVZX8fr8kye/3a8uWLaqpqXHaFBQUyOPxKCkpyWlz6jka2jScAwAAoFkzMVlZWXr++ef16quvqm/fvs49LF6vV7169ZLX69WMGTOUk5Oj2NhYeTwe3X333fL7/ZowYYIkKS0tTUlJSbr99tu1ZMkSBQIBPfjgg8rKynJmUmbPnq0//OEPuv/++/WjH/1I69at00svvaT8fO4jAAAAJzVrJmbZsmUKBoO67rrrNGDAAGd78cUXnTa/+93vdOONN2rKlCmaOHGifD6fXnnlFed49+7dtWbNGnXv3l1+v18/+MEPdMcdd+jRRx912gwePFj5+fkqKCjQ6NGj9Zvf/EbPPvus0tPTW6FkAAAQCb7WOjGdGevEoLlsfGKIdWIARJrmfH63+BFrAJGDhfUA2IgQA+vxAQwAXRPfYg0AAKxEiAEAAFYixAAAACsRYgAAgJUIMQAAwEo8nYQuwcY1YAAA58ZMDAAAsBIhBgAAWIkQAwAArESIAQAAViLEAAAAKxFiAACAlQgxAADASoQYAABgJUIMAACwEiv2AhGO1YoBRCpmYgAAgJUIMQAAwEpcTgIsxqUiAF0ZIQZAu2pK8NqxOLMdegLAdlxOAgAAViLEAAAAKxFiAACAlQgxAADASoQYAABgJUIMAACwEiEGAABYiRADAACsRIgBAABWIsQAAAArEWIAAICVCDEAAMBKhBgAAGAlQgwAALASIQYAAFiJEAMAAKxEiAEAAFYixAAAACsRYgAAgJUIMQAAwEpRHd0BAJHjkoX5Hd0FAF0IMzEAAMBKhBgAAGAlQgwAALASIQYAAFiJEAMAAKxEiAEAAFYixAAAACsRYgAAgJUIMQAAwEqs2AugSViNF0Bnw0wMAACwEiEGAABYiRADAACsRIgBAABWIsQAAAArEWIAAICVCDEAAMBKhBgAAGAlQgwAALBSs0PM+vXrNXnyZCUkJMjlcmn16tVhx++88065XK6wLSMjI6zN/v37NW3aNHk8HsXExGjGjBk6ePBgWJvNmzfr2muvVc+ePZWYmKglS5Y0vzoAABCxmh1iDh06pNGjR+vJJ588a5uMjAzt2bPH2f7617+GHZ82bZq2bt2qgoICrVmzRuvXr9esWbOc46FQSGlpaRo0aJBKS0u1dOlSPfzww3rmmWea210AABChmv3dSZMmTdKkSZPO2cbtdsvn8zV67NNPP9XatWv1wQcfaNy4cZKk3//+97rhhhv061//WgkJCVq5cqWOHj2qP/3pT4qOjtY3v/lNlZWV6be//W1Y2AEAAF1Xm9wTU1RUpLi4OA0bNkxz5szRvn37nGMlJSWKiYlxAowkpaamqlu3btq4caPTZuLEiYqOjnbapKenq6KiQl9++WWjv7Ourk6hUChsAwAAkavVQ0xGRob+/Oc/q7CwUL/61a9UXFysSZMm6cSJE5KkQCCguLi4sPdERUUpNjZWgUDAaRMfHx/WpuF1Q5vT5eXlyev1OltiYmJrlwYAADqRZl9OOp+pU6c6P48cOVKjRo3SkCFDVFRUpJSUlNb+dY7c3Fzl5OQ4r0OhEEEGAIAI1uaPWF966aXq16+ftm3bJkny+XyqqakJa3P8+HHt37/fuY/G5/Opuro6rE3D67Pda+N2u+XxeMI2AAAQudo8xOzatUv79u3TgAEDJEl+v1+1tbUqLS112qxbt0719fVKTk522qxfv17Hjh1z2hQUFGjYsGG68MIL27rLAADAAs0OMQcPHlRZWZnKysokSZWVlSorK1NVVZUOHjyo+fPna8OGDdqxY4cKCwt10003aejQoUpPT5ckXX755crIyNDMmTP1/vvv691331V2dramTp2qhIQESdJtt92m6OhozZgxQ1u3btWLL76oxx9/POxyEQAA6NqaHWI2bdqkMWPGaMyYMZKknJwcjRkzRosWLVL37t21efNmfec739E3vvENzZgxQ2PHjtU///lPud1u5xwrV67U8OHDlZKSohtuuEHXXHNN2BowXq9Xb775piorKzV27Fjde++9WrRoEY9XAwAAh8sYYzq6E20hFArJ6/UqGAxyf0yEu2Rhfkd3Aa1sx+LMju4CgA7SnM9vvjsJAABYiRADAACsRIgBAABWIsQAAAArtfqKvUBr4qZdAMDZEGIARKymhGCehALsRYgB0OkQPgA0BffEAAAAKxFiAACAlQgxAADASoQYAABgJUIMAACwEiEGAABYiRADAACsRIgBAABWYrE7AFbiKykAMBMDAACsRIgBAABWIsQAAAArEWIAAICVCDEAAMBKhBgAAGAlQgwAALASIQYAAFiJEAMAAKxEiAEAAFYixAAAACsRYgAAgJUIMQAAwEqEGAAAYCVCDAAAsBIhBgAAWIkQAwAArESIAQAAViLEAAAAKxFiAACAlQgxAADASoQYAABgJUIMAACwEiEGAABYiRADAACsRIgBAABWIsQAAAArEWIAAICVCDEAAMBKhBgAAGAlQgwAALASIQYAAFiJEAMAAKwU1dEdQNd1ycL8ju4CAMBizMQAAAArEWIAAICVCDEAAMBKhBgAAGAlQgwAALASIQYAAFiJEAMAAKxEiAEAAFYixAAAACuxYi+ALq0pK0fvWJzZDj0B0FzMxAAAACs1O8SsX79ekydPVkJCglwul1avXh123BijRYsWacCAAerVq5dSU1P1+eefh7XZv3+/pk2bJo/Ho5iYGM2YMUMHDx4Ma7N582Zde+216tmzpxITE7VkyZLmVwcAACJWs0PMoUOHNHr0aD355JONHl+yZImeeOIJPf3009q4caMuuOACpaen68iRI06badOmaevWrSooKNCaNWu0fv16zZo1yzkeCoWUlpamQYMGqbS0VEuXLtXDDz+sZ555pgUlAgCASOQyxpgWv9nl0qpVq3TzzTdLOjkLk5CQoHvvvVf33XefJCkYDCo+Pl4rVqzQ1KlT9emnnyopKUkffPCBxo0bJ0lau3atbrjhBu3atUsJCQlatmyZfvKTnygQCCg6OlqStHDhQq1evVqfffZZk/oWCoXk9XoVDAbl8XhaWiLaEN9iDVtwTwzQfprz+d2q98RUVlYqEAgoNTXV2ef1epWcnKySkhJJUklJiWJiYpwAI0mpqanq1q2bNm7c6LSZOHGiE2AkKT09XRUVFfryyy8b/d11dXUKhUJhGwAAiFytGmICgYAkKT4+Pmx/fHy8cywQCCguLi7seFRUlGJjY8PaNHaOU3/H6fLy8uT1ep0tMTHx6xcEAAA6rYh5Oik3N1fBYNDZdu7c2dFdAgAAbahVQ4zP55MkVVdXh+2vrq52jvl8PtXU1IQdP378uPbv3x/WprFznPo7Tud2u+XxeMI2AAAQuVo1xAwePFg+n0+FhYXOvlAopI0bN8rv90uS/H6/amtrVVpa6rRZt26d6uvrlZyc7LRZv369jh075rQpKCjQsGHDdOGFF7ZmlwEAgKWaHWIOHjyosrIylZWVSTp5M29ZWZmqqqrkcrk0d+5c/fznP9drr72mLVu26I477lBCQoLzBNPll1+ujIwMzZw5U++//77effddZWdna+rUqUpISJAk3XbbbYqOjtaMGTO0detWvfjii3r88ceVk5PTaoUDAAC7NftrBzZt2qTrr7/eed0QLKZPn64VK1bo/vvv16FDhzRr1izV1tbqmmuu0dq1a9WzZ0/nPStXrlR2drZSUlLUrVs3TZkyRU888YRz3Ov16s0331RWVpbGjh2rfv36adGiRWFryaBz4/FpAEBb+1rrxHRmrBPTsQgxiCSsEwO0nw5bJwYAAKC9EGIAAICVmn1PDAB0NU25PMolJ6D9MRMDAACsRIgBAABWIsQAAAArEWIAAICVCDEAAMBKhBgAAGAlQgwAALASIQYAAFiJEAMAAKzEir0A0ApY1Rdof8zEAAAAKxFiAACAlQgxAADASoQYAABgJUIMAACwEiEGAABYiRADAACsRIgBAABWIsQAAAArEWIAAICVCDEAAMBKhBgAAGAlQgwAALAS32INAO2Eb7oGWhczMQAAwEqEGAAAYCVCDAAAsBIhBgAAWIkQAwAArESIAQAAViLEAAAAKxFiAACAlVjsDgA6ERbEA5qOmRgAAGAlQgwAALASIQYAAFiJEAMAAKxEiAEAAFYixAAAACvxiDUAWIbHsIGTmIkBAABWIsQAAAArEWIAAICVCDEAAMBKhBgAAGAlQgwAALASIQYAAFiJEAMAAKxEiAEAAFYixAAAACsRYgAAgJUIMQAAwEqEGAAAYCVCDAAAsFJUR3cA9rlkYX5HdwEAAGZiAACAnQgxAADASoQYAABgJUIMAACwUquHmIcfflgulytsGz58uHP8yJEjysrK0kUXXaQ+ffpoypQpqq6uDjtHVVWVMjMz1bt3b8XFxWn+/Pk6fvx4a3cVAABYrE2eTvrmN7+pt95663+/JOp/v2bevHnKz8/Xyy+/LK/Xq+zsbN1yyy169913JUknTpxQZmamfD6f3nvvPe3Zs0d33HGHevTooV/+8pdt0V0AAGChNgkxUVFR8vl8Z+wPBoP64x//qOeff17f/va3JUnLly/X5Zdfrg0bNmjChAl688039cknn+itt95SfHy8rrjiCv3sZz/TggUL9PDDDys6OrotugwAACzTJiHm888/V0JCgnr27Cm/36+8vDwNHDhQpaWlOnbsmFJTU522w4cP18CBA1VSUqIJEyaopKREI0eOVHx8vNMmPT1dc+bM0datWzVmzJhGf2ddXZ3q6uqc16FQqC1Ki3isAQNEhqb8W96xOLMdegK0nVa/JyY5OVkrVqzQ2rVrtWzZMlVWVuraa6/VgQMHFAgEFB0drZiYmLD3xMfHKxAISJICgUBYgGk43nDsbPLy8uT1ep0tMTGxdQsDAACdSqvPxEyaNMn5edSoUUpOTtagQYP00ksvqVevXq396xy5ubnKyclxXodCIYIMAAARrM0fsY6JidE3vvENbdu2TT6fT0ePHlVtbW1Ym+rqauceGp/Pd8bTSg2vG7vPpoHb7ZbH4wnbAABA5Grz7046ePCgtm/frttvv11jx45Vjx49VFhYqClTpkiSKioqVFVVJb/fL0ny+/36xS9+oZqaGsXFxUmSCgoK5PF4lJSU1NbdjVjc6wIAiDStHmLuu+8+TZ48WYMGDdLu3bv10EMPqXv37rr11lvl9Xo1Y8YM5eTkKDY2Vh6PR3fffbf8fr8mTJggSUpLS1NSUpJuv/12LVmyRIFAQA8++KCysrLkdrtbu7sAAMBSrR5idu3apVtvvVX79u1T//79dc0112jDhg3q37+/JOl3v/udunXrpilTpqiurk7p6el66qmnnPd3795da9as0Zw5c+T3+3XBBRdo+vTpevTRR1u7qwAAwGIuY4zp6E60hVAoJK/Xq2AwyP0x4nISgDPxiDU6o+Z8fvPdSQAAwEqEGAAAYCVCDAAAsBIhBgAAWIkQAwAArESIAQAAVmrzFXsBAJ0T33QN2zETAwAArESIAQAAViLEAAAAKxFiAACAlQgxAADASoQYAABgJR6xBgCcFY9hozMjxESApvwnAwBApOFyEgAAsBIhBgAAWIkQAwAArESIAQAAViLEAAAAKxFiAACAlQgxAADASoQYAABgJUIMAACwEiEGAABYiRADAACsRIgBAABWIsQAAAArEWIAAICVCDEAAMBKUR3dAQCA3S5ZmH/eNjsWZ7ZDT9DVMBMDAACsRIgBAABWIsQAAAArcU9MJ9eUa80AAHRFzMQAAAArEWIAAICVCDEAAMBKhBgAAGAlQgwAALASIQYAAFiJEAMAAKxEiAEAAFZisTsAQJvjSyLRFpiJAQAAVmImpgPxlQIAALQcMzEAAMBKhBgAAGAlQgwAALASIQYAAFiJEAMAAKzE00kAgE6BtWTQXMzEAAAAKxFiAACAlQgxAADASoQYAABgJW7sbSN8pQAAAG2LEAMAsAZPMOFUXE4CAABWIsQAAAArcTkJABBRuOTUdXTqEPPkk09q6dKlCgQCGj16tH7/+9/rqquu6uhuAQAsR9CJDJ32ctKLL76onJwcPfTQQ/rwww81evRopaenq6ampqO7BgAAOgGXMcZ0dCcak5ycrPHjx+sPf/iDJKm+vl6JiYm6++67tXDhwvO+PxQKyev1KhgMyuPxtHV3z8Aj1gAQ+ZitaX3N+fzulJeTjh49qtLSUuXm5jr7unXrptTUVJWUlDT6nrq6OtXV1Tmvg8GgpJN/GK1txENvtPo5AQD2GTjv5VY5T/kj6a1ynkjQ8LndlDmWThli/vvf/+rEiROKj48P2x8fH6/PPvus0ffk5eXpkUceOWN/YmJim/QRAIDW4n2so3vQ+Rw4cEBer/ecbTpliGmJ3Nxc5eTkOK/r6+u1f/9+XXTRRXK5XB3Ys9YTCoWUmJionTt3dsglso7SFeum5q5Rs9Q16+6KNUtds+6W1GyM0YEDB5SQkHDetp0yxPTr10/du3dXdXV12P7q6mr5fL5G3+N2u+V2u8P2xcTEtFUXO5TH4+ky/wBO1RXrpuauoyvW3RVrlrpm3c2t+XwzMA065dNJ0dHRGjt2rAoLC5199fX1KiwslN/v78CeAQCAzqJTzsRIUk5OjqZPn65x48bpqquu0mOPPaZDhw7phz/8YUd3DQAAdAKdNsR8//vf1969e7Vo0SIFAgFdccUVWrt27Rk3+3YlbrdbDz300BmXzSJdV6ybmruOrlh3V6xZ6pp1t3XNnXadGAAAgHPplPfEAAAAnA8hBgAAWIkQAwAArESIAQAAViLEdLD169dr8uTJSkhIkMvl0urVq8OOG2O0aNEiDRgwQL169VJqaqo+//zzsDb79+/XtGnT5PF4FBMToxkzZujgwYPtWEXzna/uO++8Uy6XK2zLyMgIa2Nb3Xl5eRo/frz69u2ruLg43XzzzaqoqAhrc+TIEWVlZemiiy5Snz59NGXKlDMWfayqqlJmZqZ69+6tuLg4zZ8/X8ePH2/PUpqsKTVfd911Z4z17Nmzw9rYVLMkLVu2TKNGjXIW+PL7/Xr99ded45E2ztL5a47EcT7d4sWL5XK5NHfuXGdfJI716Rqru93G26BD/eMf/zA/+clPzCuvvGIkmVWrVoUdX7x4sfF6vWb16tXm448/Nt/5znfM4MGDzeHDh502GRkZZvTo0WbDhg3mn//8pxk6dKi59dZb27mS5jlf3dOnTzcZGRlmz549zrZ///6wNrbVnZ6ebpYvX27Ky8tNWVmZueGGG8zAgQPNwYMHnTazZ882iYmJprCw0GzatMlMmDDBfOtb33KOHz9+3IwYMcKkpqaajz76yPzjH/8w/fr1M7m5uR1R0nk1peb/+7//MzNnzgwb62Aw6By3rWZjjHnttddMfn6++de//mUqKirMAw88YHr06GHKy8uNMZE3zsacv+ZIHOdTvf/+++aSSy4xo0aNMvfcc4+zPxLH+lRnq7u9xpsQ04mc/mFeX19vfD6fWbp0qbOvtrbWuN1u89e//tUYY8wnn3xiJJkPPvjAafP6668bl8tl/vOf/7Rb37+Os4WYm2666azviYS6a2pqjCRTXFxsjDk5tj169DAvv/yy0+bTTz81kkxJSYkx5mT469atmwkEAk6bZcuWGY/HY+rq6tq3gBY4vWZjTv5nd+p/fqezveYGF154oXn22We7xDg3aKjZmMge5wMHDpjLLrvMFBQUhNUZ6WN9trqNab/x5nJSJ1ZZWalAIKDU1FRnn9frVXJyskpKSiRJJSUliomJ0bhx45w2qamp6tatmzZu3NjufW5NRUVFiouL07BhwzRnzhzt27fPORYJdQeDQUlSbGysJKm0tFTHjh0LG+/hw4dr4MCBYeM9cuTIsEUf09PTFQqFtHXr1nbsfcucXnODlStXql+/fhoxYoRyc3P11VdfOcdsr/nEiRN64YUXdOjQIfn9/i4xzqfX3CBSxzkrK0uZmZlhYypF/r/ps9XdoD3Gu9Ou2AspEAhI0hmrFMfHxzvHAoGA4uLiwo5HRUUpNjbWaWOjjIwM3XLLLRo8eLC2b9+uBx54QJMmTVJJSYm6d+9ufd319fWaO3eurr76ao0YMULSybGMjo4+44tLTx/vxv4+NBzrzBqrWZJuu+02DRo0SAkJCdq8ebMWLFigiooKvfLKK5LsrXnLli3y+/06cuSI+vTpo1WrVikpKUllZWURO85nq1mK3HF+4YUX9OGHH+qDDz4441gk/5s+V91S+403IQad0tSpU52fR44cqVGjRmnIkCEqKipSSkpKB/asdWRlZam8vFzvvPNOR3el3Zyt5lmzZjk/jxw5UgMGDFBKSoq2b9+uIUOGtHc3W82wYcNUVlamYDCov/3tb5o+fbqKi4s7ultt6mw1JyUlReQ479y5U/fcc48KCgrUs2fPju5Ou2lK3e013lxO6sR8Pp8knXEne3V1tXPM5/OppqYm7Pjx48e1f/9+p00kuPTSS9WvXz9t27ZNkt11Z2dna82aNXr77bd18cUXO/t9Pp+OHj2q2trasPanj3djfx8ajnVWZ6u5McnJyZIUNtY21hwdHa2hQ4dq7NixysvL0+jRo/X4449H9DifrebGRMI4l5aWqqamRldeeaWioqIUFRWl4uJiPfHEE4qKilJ8fHxEjvX56j5x4sQZ72mr8SbEdGKDBw+Wz+dTYWGhsy8UCmnjxo3OdWa/36/a2lqVlpY6bdatW6f6+nrnL00k2LVrl/bt26cBAwZIsrNuY4yys7O1atUqrVu3ToMHDw47PnbsWPXo0SNsvCsqKlRVVRU23lu2bAkLcAUFBfJ4PM60fWdyvpobU1ZWJklhY21TzWdTX1+vurq6iBzns2mouTGRMM4pKSnasmWLysrKnG3cuHGaNm2a83MkjvX56u7evfsZ72mz8W7+/choTQcOHDAfffSR+eijj4wk89vf/tZ89NFH5osvvjDGnHzEOiYmxrz66qtm8+bN5qabbmr0EesxY8aYjRs3mnfeecdcdtllnfpRY2POXfeBAwfMfffdZ0pKSkxlZaV56623zJVXXmkuu+wyc+TIEeccttU9Z84c4/V6TVFRUdhjh1999ZXTZvbs2WbgwIFm3bp1ZtOmTcbv9xu/3+8cb3gsMS0tzZSVlZm1a9ea/v37d9rHMc9X87Zt28yjjz5qNm3aZCorK82rr75qLr30UjNx4kTnHLbVbIwxCxcuNMXFxaaystJs3rzZLFy40LhcLvPmm28aYyJvnI05d82ROs6NOf2pnEgc68acWnd7jjchpoO9/fbbRtIZ2/Tp040xJx+z/ulPf2ri4+ON2+02KSkppqKiIuwc+/btM7feeqvp06eP8Xg85oc//KE5cOBAB1TTdOeq+6uvvjJpaWmmf//+pkePHmbQoEFm5syZYY/iGWNf3Y3VK8ksX77caXP48GHz4x//2Fx44YWmd+/e5rvf/a7Zs2dP2Hl27NhhJk2aZHr16mX69etn7r33XnPs2LF2rqZpzldzVVWVmThxoomNjTVut9sMHTrUzJ8/P2w9CWPsqtkYY370ox+ZQYMGmejoaNO/f3+TkpLiBBhjIm+cjTl3zZE6zo05PcRE4lg35tS623O8XcYY0/R5GwAAgM6Be2IAAICVCDEAAMBKhBgAAGAlQgwAALASIQYAAFiJEAMAAKxEiAEAAFYixAAAACsRYgAAgJUIMQAAwEqEGAAAYCVCDAAAsNL/AxzP0Gskw3TwAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(input_lengths, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meaning_representation': 'name[Blue Spice], eatType[coffee shop], area[city centre]',\n",
       " 'human_reference': 'A coffee shop in the city centre area called Blue Spice.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}\n",
      "{'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '<sep>', 'pad_token': '[PAD]'}\n",
      "[1, 2, 0, 32001, 32000]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.special_tokens_map)\n",
    "tokenizer.add_special_tokens({\"pad_token\":\"[PAD]\"})\n",
    "tokenizer.convert_tokens_to_ids('[PAD]')\n",
    "tokenizer.add_special_tokens({\"sep_token\":\"<sep>\"})\n",
    "tokenizer.convert_tokens_to_ids('<sep>')\n",
    "print(tokenizer.special_tokens_map)\n",
    "print(tokenizer.all_special_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32002, 2048)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LoRA_llama.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert LoRA_llama.lm_head.weight.shape == LoRA_llama.model.embed_tokens.weight.shape == (32002, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_fn(sample, tokenizer):\n",
    "#     input_text = sample[\"meaning_representation\"] + \"<sep>\" + sample[\"human_reference\"]\n",
    "#     preprocessed_sample = tokenizer(\n",
    "#         input_text,\n",
    "#         max_length=384, #maybe try 384\n",
    "#         truncation=True,\n",
    "#         padding=\"max_length\",\n",
    "#     )\n",
    "#     preprocessed_sample[\"labels\"] = tokenizer.encode(sample[\"human_reference\"])\n",
    "#     preprocessed_sample[\"cutoff\"] = len(sample[\"meaning_representation\"])\n",
    "#     return preprocessed_sample\n",
    "\n",
    "# preprocessed_train = dataset[\"train\"].map(preprocess_fn, fn_kwargs={\"tokenizer\":tokenizer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LoRA.data_utils import DataCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "data_collator = DataCollator(tokenizer=tokenizer, max_length=384, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(dataset[\"train\"], batch_size=16, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = batch[\"input_ids\"][batch[\"loss_mask\"]]\n",
    "targets = batch[\"labels\"][batch[\"loss_mask\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.randn(size=(461, 32001), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([461, 32001]) torch.Size([461])\n",
      "torch.float32 torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(pred.shape, targets.shape)\n",
    "print(pred.dtype, targets.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.8535)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn(pred, targets.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 384, 2048])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_proj = LoRA_llama.model.embed_tokens(batch[\"input_ids\"])\n",
    "emb_proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'labels', 'loss_mask'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"### Instruction:\\nDescribe the structure of an atom.\\n\\n### Response:\\n\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithPast(loss=None, logits=tensor([[[ -1.7340,   1.9886,   2.8448,  ...,  -3.0332,   0.0760,   2.2170],\n",
       "         [ -9.9306,  -9.8902,   6.2598,  ...,  -1.3404,   2.7176,  -0.4299],\n",
       "         [ -7.4265,  -7.5441,   2.2056,  ...,  -2.5291,   0.0341,  -0.1919],\n",
       "         ...,\n",
       "         [-11.4517, -11.7094,   2.0852,  ...,  -3.5456,   1.8316,   1.0591],\n",
       "         [-10.8050, -10.9598,   5.8787,  ...,  -2.9804,   2.1922,  -0.5307],\n",
       "         [ -8.6776,  -8.8169,   8.2351,  ...,   2.4877,  -1.0934,  -2.7130]]],\n",
       "       device='cuda:0', grad_fn=<UnsafeViewBackward0>), past_key_values=((tensor([[[[ 2.1541e-02, -3.6334e-02,  1.6648e-02,  ..., -1.9140e-02,\n",
       "           -4.5862e-04, -1.4910e-02],\n",
       "          [ 9.5936e-02, -9.9026e-02,  1.5491e-01,  ...,  9.9799e-02,\n",
       "            1.1202e-01,  1.0081e-01],\n",
       "          [ 2.7698e-01,  3.1118e-02,  6.6651e-02,  ..., -2.4216e-02,\n",
       "            3.6755e-02, -1.2002e-02],\n",
       "          ...,\n",
       "          [-2.5687e-01,  1.0254e-01, -3.8412e-02,  ...,  5.2203e-02,\n",
       "            1.0181e-01,  6.2644e-02],\n",
       "          [-1.2542e-01,  2.2727e-01, -5.7605e-01,  ..., -1.8561e-01,\n",
       "           -1.5386e-01, -1.8644e-01],\n",
       "          [ 6.0842e+00, -3.0826e+00, -3.9084e+00,  ..., -3.1459e+00,\n",
       "           -2.5877e+00, -3.0219e+00]],\n",
       "\n",
       "         [[-2.5226e-01, -2.5951e-01, -7.1101e-02,  ..., -8.7255e-02,\n",
       "            1.2257e-01, -1.6369e-01],\n",
       "          [-3.7949e-01, -1.1611e+00, -1.1450e+00,  ..., -7.4164e-01,\n",
       "            4.2483e-01, -9.5444e-01],\n",
       "          [ 5.4531e-01, -1.3878e-01, -8.2707e-01,  ..., -1.0956e+00,\n",
       "            4.2986e-01, -1.2391e+00],\n",
       "          ...,\n",
       "          [-5.4967e-01, -6.5763e-01,  8.3664e-01,  ..., -6.4018e-01,\n",
       "            3.4732e-01, -8.3883e-01],\n",
       "          [ 3.0755e+00,  1.0691e+00, -1.8157e+00,  ...,  3.0014e+00,\n",
       "           -2.0822e+00,  3.7367e+00],\n",
       "          [ 1.5491e+00, -1.0653e+00, -2.2012e+00,  ...,  1.9478e+00,\n",
       "           -4.0767e+00,  3.5562e+00]],\n",
       "\n",
       "         [[ 4.4582e-01, -9.1739e-02,  5.8041e-02,  ...,  3.3230e-01,\n",
       "           -1.3207e-01,  4.2009e-02],\n",
       "          [ 1.2788e+00,  4.7286e-01, -9.7846e-01,  ...,  1.5417e+00,\n",
       "           -8.6268e-01, -1.3588e+00],\n",
       "          [ 1.4990e+00, -8.4618e-01, -5.1785e-01,  ..., -4.5853e-01,\n",
       "            6.0150e-02, -1.6000e-01],\n",
       "          ...,\n",
       "          [-1.3055e+00, -1.8479e-01,  1.0868e+00,  ...,  4.3978e-01,\n",
       "           -1.3065e-01, -7.7359e-02],\n",
       "          [-6.7614e+00, -5.3056e+00,  4.2934e+00,  ..., -3.4019e+00,\n",
       "           -1.5865e+00, -9.4531e-01],\n",
       "          [-2.3879e+00, -4.5381e+00,  4.0785e+00,  ..., -2.9814e+00,\n",
       "           -2.2173e+00, -1.3461e+00]],\n",
       "\n",
       "         [[-1.1355e-01, -4.0242e-02, -8.6328e-02,  ...,  3.1909e-02,\n",
       "           -6.6031e-02, -6.2399e-02],\n",
       "          [-1.7175e+00, -5.9032e-01, -8.2179e-01,  ...,  5.4471e-01,\n",
       "           -9.2113e-01, -9.0122e-01],\n",
       "          [-1.4416e+00,  3.4069e-01,  6.9536e-02,  ...,  6.6290e-01,\n",
       "           -9.4025e-01, -9.1922e-01],\n",
       "          ...,\n",
       "          [ 7.3617e-01,  1.0063e-01,  2.3208e-01,  ...,  3.3604e-01,\n",
       "           -5.6197e-01, -5.4665e-01],\n",
       "          [ 1.2777e+00, -8.9115e-01, -5.2083e-02,  ..., -1.4311e+00,\n",
       "            2.9389e+00,  2.8573e+00],\n",
       "          [ 2.9509e+00, -1.8410e+00,  1.4672e+00,  ..., -1.1857e+00,\n",
       "            3.2745e+00,  3.2249e+00]]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>), tensor([[[[-9.8530e-04,  2.1956e-04,  1.2210e-03,  ..., -1.4191e-03,\n",
       "           -6.8247e-04, -9.1906e-04],\n",
       "          [-1.9568e-03,  2.5326e-03, -2.8827e-03,  ..., -4.0705e-03,\n",
       "            1.5995e-03,  3.8155e-04],\n",
       "          [-8.2788e-04, -7.7682e-04,  3.0739e-03,  ..., -6.6193e-04,\n",
       "            3.0275e-03, -1.7364e-03],\n",
       "          ...,\n",
       "          [-1.7014e-03, -1.3836e-03, -2.0946e-03,  ...,  5.1689e-03,\n",
       "            1.4651e-03,  1.3398e-03],\n",
       "          [ 2.2087e-04,  2.5360e-04, -1.4030e-03,  ..., -4.1832e-04,\n",
       "           -3.0066e-03,  1.8626e-03],\n",
       "          [ 2.4762e-03,  7.9513e-05, -1.3385e-03,  ...,  6.0084e-03,\n",
       "            1.8247e-03,  1.7911e-03]],\n",
       "\n",
       "         [[ 1.8673e-03, -6.7081e-04,  4.5459e-03,  ...,  9.6939e-04,\n",
       "           -2.1947e-03, -2.5923e-04],\n",
       "          [-3.6673e-04,  7.8002e-04, -2.3244e-03,  ..., -1.0725e-03,\n",
       "            2.5569e-03,  3.4398e-03],\n",
       "          [ 2.4441e-03,  2.7556e-03, -1.4959e-04,  ...,  1.7609e-03,\n",
       "           -5.8138e-03, -9.1913e-04],\n",
       "          ...,\n",
       "          [ 1.5900e-03,  3.4782e-03, -2.6452e-03,  ...,  9.2448e-04,\n",
       "            3.2768e-03, -9.5748e-04],\n",
       "          [-1.5238e-03, -1.5193e-03, -2.9053e-05,  ...,  1.8346e-03,\n",
       "           -7.8894e-04,  2.4002e-03],\n",
       "          [-1.2950e-03,  1.8505e-03,  1.8254e-03,  ..., -1.1160e-03,\n",
       "           -2.2264e-03,  8.0193e-04]],\n",
       "\n",
       "         [[-4.2523e-04,  4.5527e-03, -6.5769e-03,  ..., -8.8727e-03,\n",
       "           -1.5116e-03,  6.8686e-04],\n",
       "          [ 1.3150e-02, -1.0859e-02, -1.2273e-02,  ..., -8.8129e-03,\n",
       "            5.1009e-03,  5.4802e-03],\n",
       "          [-8.7990e-03, -9.5698e-03, -7.8328e-03,  ..., -4.8405e-03,\n",
       "           -1.7396e-03,  1.7534e-02],\n",
       "          ...,\n",
       "          [ 4.3423e-03,  6.6876e-03,  7.4313e-03,  ..., -7.5689e-03,\n",
       "            3.6706e-03, -3.5259e-02],\n",
       "          [ 9.9327e-03,  1.6696e-03,  1.0852e-03,  ...,  5.0539e-03,\n",
       "            3.6970e-03, -4.0775e-02],\n",
       "          [ 7.7987e-04,  4.6141e-04,  1.1282e-03,  ..., -4.6865e-03,\n",
       "            1.8514e-03,  2.1417e-02]],\n",
       "\n",
       "         [[ 1.9316e-03, -1.7401e-03,  3.0079e-04,  ...,  4.1452e-03,\n",
       "            1.0515e-03,  4.3974e-03],\n",
       "          [-1.1978e-03,  7.3207e-04,  2.4987e-03,  ..., -2.6630e-03,\n",
       "            4.4840e-02,  2.3776e-03],\n",
       "          [-4.0151e-03, -1.7373e-03,  2.4141e-03,  ..., -3.5332e-03,\n",
       "            3.5443e-02, -7.6169e-03],\n",
       "          ...,\n",
       "          [-1.5193e-03, -5.0187e-04,  6.5482e-03,  ..., -5.9034e-03,\n",
       "           -3.2355e-04, -2.8994e-03],\n",
       "          [ 2.0689e-03,  4.2640e-03, -1.8698e-03,  ..., -4.3510e-04,\n",
       "           -8.3789e-03,  1.8613e-05],\n",
       "          [-7.0592e-04, -2.9101e-03,  1.7596e-03,  ..., -5.4492e-03,\n",
       "           -1.6484e-02,  1.4908e-04]]]], device='cuda:0',\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[ 0.2371,  0.3984, -0.8682,  ..., -1.4335, -0.1377, -0.5296],\n",
       "          [ 6.9328, -1.0249,  2.4969,  ..., -5.3900, -0.9723, -3.3973],\n",
       "          [ 4.6367, -3.6865,  1.6841,  ..., -3.6078, -1.0247, -3.4497],\n",
       "          ...,\n",
       "          [-3.5950, -2.3743,  0.1663,  ..., -3.7201, -0.8218, -2.9570],\n",
       "          [ 2.4831, -3.1561, -4.0036,  ..., -5.0871, -1.0465, -4.3992],\n",
       "          [ 2.3482, -2.1378, -1.9617,  ..., -1.6588, -1.0556, -2.9939]],\n",
       "\n",
       "         [[-1.6020,  0.4088, -0.9544,  ...,  0.7585,  0.4798,  0.6053],\n",
       "          [-0.2407,  1.2746, -0.6036,  ...,  0.8125,  1.9755,  3.6589],\n",
       "          [ 1.7460,  1.7449,  0.1270,  ...,  0.6703,  1.9179,  3.3509],\n",
       "          ...,\n",
       "          [-2.7551,  2.2150,  0.6133,  ...,  1.0528,  1.9702,  3.0034],\n",
       "          [-0.1828,  0.1759, -0.1922,  ...,  2.8423,  2.9480,  2.3939],\n",
       "          [ 0.3478,  0.0629, -1.7622,  ...,  0.0552,  2.8443,  2.2270]],\n",
       "\n",
       "         [[ 4.0304,  0.4885, -1.2879,  ...,  0.0238, -0.8141, -0.8713],\n",
       "          [ 4.0543, -1.3062, -2.1081,  ...,  1.7150, -1.5482, -1.8777],\n",
       "          [-1.2554, -4.9749, -0.6559,  ...,  1.1926, -1.5737, -2.4728],\n",
       "          ...,\n",
       "          [ 4.3471, -3.2833,  3.2837,  ...,  2.9759, -1.5650, -2.5748],\n",
       "          [ 2.7252, -2.2728,  1.2479,  ...,  3.9788, -3.1251, -1.9606],\n",
       "          [ 1.1913, -1.1752, -0.1121,  ...,  4.2749, -3.5929, -1.4971]],\n",
       "\n",
       "         [[-1.3209, -1.8601,  0.3690,  ..., -1.0877,  0.0862, -0.3993],\n",
       "          [-7.1995, -2.4566, -2.2708,  ..., -2.9243, -0.2064,  2.0095],\n",
       "          [-4.2681,  1.9469, -3.4116,  ..., -3.3874, -0.9675, -1.3713],\n",
       "          ...,\n",
       "          [ 2.9582, -0.8679,  1.5239,  ..., -2.9894, -1.0817, -1.2456],\n",
       "          [-2.6507,  0.8645,  3.3531,  ..., -3.2466, -2.4305,  1.5504],\n",
       "          [-3.6607,  2.2193,  2.2961,  ..., -2.3706, -2.7280,  2.6202]]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[[[ 6.2718e-03,  1.4494e-02, -8.3834e-03,  ..., -6.8912e-03,\n",
       "            8.4585e-03,  1.3291e-02],\n",
       "          [-4.6381e-02,  4.6929e-02, -2.3454e-02,  ...,  7.1044e-02,\n",
       "           -2.4578e-02,  6.3360e-03],\n",
       "          [ 8.9029e-03,  2.5213e-02, -8.2074e-03,  ...,  4.5250e-02,\n",
       "           -1.4358e-02, -8.3805e-03],\n",
       "          ...,\n",
       "          [ 1.8711e-02, -4.4802e-03, -4.1525e-02,  ...,  2.4718e-03,\n",
       "            9.8019e-04, -4.2646e-02],\n",
       "          [-1.5230e-02,  2.6328e-02,  1.3096e-02,  ..., -2.9440e-02,\n",
       "           -2.3061e-02,  8.4952e-03],\n",
       "          [-1.7904e-02, -3.2658e-03, -1.5144e-02,  ..., -8.0308e-03,\n",
       "            6.3140e-03,  9.3679e-02]],\n",
       "\n",
       "         [[ 4.3183e-02, -1.9766e-02,  3.1505e-02,  ...,  1.3007e-02,\n",
       "            1.5826e-02,  3.0660e-02],\n",
       "          [ 1.8780e-02,  7.2072e-03, -2.8615e-02,  ..., -3.9318e-03,\n",
       "           -1.0963e-02,  4.1516e-03],\n",
       "          [ 2.1492e-02,  3.1098e-03, -2.4601e-03,  ..., -8.4789e-03,\n",
       "            8.5447e-03,  1.5648e-03],\n",
       "          ...,\n",
       "          [-9.6098e-03, -1.3449e-02, -3.4428e-02,  ...,  1.5422e-02,\n",
       "           -1.0084e-02,  1.6949e-02],\n",
       "          [-9.1514e-04, -1.4531e-02,  1.6876e-05,  ..., -1.3414e-02,\n",
       "            1.3974e-02,  6.4219e-03],\n",
       "          [-1.6511e-02, -2.0039e-02, -3.1021e-02,  ...,  8.1512e-03,\n",
       "           -1.4626e-02, -1.0593e-02]],\n",
       "\n",
       "         [[-8.7931e-03,  4.2360e-03, -1.9653e-02,  ..., -2.6188e-04,\n",
       "           -2.0443e-02, -5.1355e-02],\n",
       "          [-4.4244e-02, -8.3440e-03,  9.2552e-03,  ...,  2.6891e-02,\n",
       "           -9.1691e-03,  7.6139e-02],\n",
       "          [ 9.1666e-03,  1.4786e-02, -3.2744e-02,  ...,  7.8170e-02,\n",
       "            4.9942e-02,  2.6514e-02],\n",
       "          ...,\n",
       "          [-2.8618e-02,  2.5174e-02, -5.8070e-02,  ...,  3.4943e-02,\n",
       "           -3.9423e-03, -2.2633e-02],\n",
       "          [ 2.2286e-03, -2.8472e-03, -5.5522e-03,  ...,  8.8575e-03,\n",
       "           -4.8479e-03,  4.8882e-03],\n",
       "          [-3.2819e-03, -4.9682e-05, -1.4863e-04,  ...,  4.6528e-03,\n",
       "            3.6136e-03,  1.5940e-03]],\n",
       "\n",
       "         [[ 1.2264e-02,  4.4054e-03, -1.4733e-02,  ...,  1.0242e-02,\n",
       "           -2.5896e-02,  4.4407e-04],\n",
       "          [-1.0146e-02,  2.4703e-02,  1.3667e-02,  ...,  8.1728e-03,\n",
       "           -9.8260e-03,  7.4966e-02],\n",
       "          [-1.4385e-03,  7.6993e-03,  7.5896e-03,  ...,  3.9155e-02,\n",
       "            1.3428e-02,  3.5850e-02],\n",
       "          ...,\n",
       "          [-4.4907e-03,  1.3344e-02, -2.7295e-02,  ..., -4.3951e-02,\n",
       "            4.6219e-02, -5.2588e-02],\n",
       "          [-1.9701e-02, -1.1324e-02,  9.3782e-03,  ..., -1.0786e-02,\n",
       "           -7.8619e-03,  4.5553e-03],\n",
       "          [ 4.8263e-03,  4.4026e-03, -1.3719e-03,  ..., -2.8903e-03,\n",
       "           -1.1727e-03, -1.0288e-03]]]], device='cuda:0',\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[ 0.6215, -1.9262, -1.4280,  ...,  2.7713,  3.5930, -2.8474],\n",
       "          [ 5.6782, -2.0966, -2.9337,  ...,  1.6523,  1.1377, -1.9651],\n",
       "          [ 2.4856,  0.2920,  0.2262,  ...,  2.3633,  0.9181, -1.7602],\n",
       "          ...,\n",
       "          [-2.7973, -2.9933,  1.3544,  ...,  2.2484,  1.8984, -1.8143],\n",
       "          [ 2.5635,  0.2009,  2.9001,  ...,  2.0441,  1.2766, -2.5462],\n",
       "          [ 2.2185,  0.6952,  1.0510,  ...,  2.9155,  1.3434, -2.2557]],\n",
       "\n",
       "         [[-0.2699, -1.5793, -2.6391,  ..., -0.1216, -0.4073,  0.5704],\n",
       "          [ 5.8967, -4.6336,  0.0576,  ...,  0.3692,  1.7488, -1.7003],\n",
       "          [ 1.5327, -0.2624,  0.2903,  ...,  0.9028,  3.4279, -2.5406],\n",
       "          ...,\n",
       "          [-1.1222, -1.3998,  0.2854,  ...,  0.0753,  1.8468, -1.7444],\n",
       "          [ 1.5642,  0.0392, -0.9431,  ...,  0.0963,  1.1228, -0.8363],\n",
       "          [ 1.2025,  1.0895, -1.3575,  ...,  0.4391,  2.8847,  0.0332]],\n",
       "\n",
       "         [[ 0.1890, -1.8741,  1.9536,  ...,  0.8730, -1.3731,  0.4893],\n",
       "          [-5.1925, -0.4516, -0.2325,  ...,  0.5443,  0.1673,  1.8823],\n",
       "          [-3.8900,  4.6897, -1.7827,  ...,  2.2476,  0.8062,  2.6980],\n",
       "          ...,\n",
       "          [ 3.2232,  1.0813,  1.1426,  ...,  2.0345,  1.2066,  3.0268],\n",
       "          [-1.1711,  0.3867,  0.8601,  ...,  1.7751, -0.2298,  2.9273],\n",
       "          [-0.8633,  0.6702,  0.7414,  ...,  0.7355, -0.2135,  1.6944]],\n",
       "\n",
       "         [[ 0.9684,  2.2017, -1.3203,  ...,  0.8351, -0.2120,  0.0293],\n",
       "          [-6.7610, -0.4729, -1.6204,  ...,  3.7881, -1.3179, -1.7727],\n",
       "          [-3.5944, -3.1762, -3.1647,  ...,  3.1978, -1.2993, -1.7755],\n",
       "          ...,\n",
       "          [ 4.6383,  0.0430,  4.9435,  ...,  2.5954, -1.0139, -1.7294],\n",
       "          [-0.5660, -3.1794,  2.6781,  ...,  3.6631, -1.3375, -2.4534],\n",
       "          [-1.4200, -1.2608,  0.9260,  ...,  4.3991, -1.0540, -1.3862]]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[[[-0.0229, -0.0456,  0.0292,  ...,  0.0135, -0.0110,  0.0238],\n",
       "          [-0.0454,  0.0528, -0.0502,  ...,  0.0364, -0.0107, -0.0350],\n",
       "          [-0.0183, -0.0126,  0.0996,  ..., -0.0101,  0.0403, -0.0396],\n",
       "          ...,\n",
       "          [-0.0316,  0.0108,  0.0686,  ...,  0.0334,  0.0331, -0.0342],\n",
       "          [-0.0458, -0.0030, -0.0356,  ...,  0.0062,  0.0630,  0.0347],\n",
       "          [ 0.0034, -0.0059,  0.0091,  ..., -0.0118,  0.0031,  0.0094]],\n",
       "\n",
       "         [[-0.0008, -0.0028, -0.0021,  ..., -0.0062, -0.0100,  0.0323],\n",
       "          [-0.0125,  0.1147, -0.0172,  ..., -0.1008, -0.0968, -0.0125],\n",
       "          [-0.0443, -0.0061, -0.0324,  ...,  0.0285, -0.0072,  0.0320],\n",
       "          ...,\n",
       "          [ 0.0307, -0.0159,  0.0076,  ...,  0.0193, -0.0165,  0.0229],\n",
       "          [ 0.0991,  0.0083,  0.0027,  ...,  0.0651,  0.0390,  0.0319],\n",
       "          [ 0.0042,  0.0107,  0.0121,  ...,  0.0221,  0.0006, -0.0048]],\n",
       "\n",
       "         [[ 0.0440, -0.0583,  0.0352,  ...,  0.0270, -0.0024, -0.0229],\n",
       "          [ 0.0522, -0.0227,  0.0156,  ..., -0.0356,  0.0600, -0.0505],\n",
       "          [ 0.0163, -0.0702, -0.0090,  ..., -0.0354, -0.0186,  0.0038],\n",
       "          ...,\n",
       "          [ 0.0007, -0.1064, -0.0016,  ..., -0.0196, -0.0192, -0.1273],\n",
       "          [-0.0003, -0.0286, -0.0537,  ...,  0.0062, -0.0122, -0.0123],\n",
       "          [-0.0216,  0.0202,  0.0281,  ...,  0.0235, -0.0099,  0.0276]],\n",
       "\n",
       "         [[-0.0448,  0.0054,  0.0692,  ...,  0.0188,  0.0230,  0.0169],\n",
       "          [ 0.1093, -0.0224,  0.0277,  ..., -0.0238,  0.0077,  0.1022],\n",
       "          [-0.0527, -0.0028,  0.0369,  ..., -0.0264, -0.0126, -0.0486],\n",
       "          ...,\n",
       "          [ 0.0389,  0.1128, -0.0390,  ...,  0.0073, -0.0107,  0.0076],\n",
       "          [ 0.0792, -0.0259, -0.0595,  ...,  0.0152,  0.0064, -0.0636],\n",
       "          [-0.0259,  0.0045, -0.0032,  ...,  0.0117, -0.0008, -0.0103]]]],\n",
       "       device='cuda:0', grad_fn=<TransposeBackward0>)), (tensor([[[[ 6.1239e-03, -2.2936e-02, -1.6481e-02,  ...,  1.0226e+00,\n",
       "           -1.2857e-01, -1.0319e+00],\n",
       "          [ 1.3594e-01,  1.0918e+00, -5.9069e-01,  ..., -9.9714e-01,\n",
       "            3.8296e+00,  2.7780e+00],\n",
       "          [-3.3933e+00,  3.2064e+00, -2.0965e+00,  ..., -3.9234e+00,\n",
       "            1.9177e+00,  1.2551e+00],\n",
       "          ...,\n",
       "          [ 3.0863e+00,  8.7538e-02,  9.3974e-01,  ..., -3.7957e+00,\n",
       "            6.4726e-01,  2.0818e+00],\n",
       "          [ 2.5129e+00,  1.6341e+00,  1.1620e+00,  ..., -4.2215e+00,\n",
       "            3.9102e+00,  5.8701e+00],\n",
       "          [ 2.6371e-01,  1.8596e+00,  1.1735e+00,  ..., -3.0861e+00,\n",
       "            1.9337e+00,  3.4745e+00]],\n",
       "\n",
       "         [[ 4.6644e-03, -2.3052e-03, -5.1650e-03,  ..., -5.8537e-01,\n",
       "           -1.2535e-01, -6.2067e-01],\n",
       "          [ 3.3341e+00, -2.3136e+00, -2.0557e+00,  ...,  2.0576e+00,\n",
       "            4.4114e-01,  3.3327e+00],\n",
       "          [ 2.4551e+00, -2.5627e+00, -1.5708e+00,  ...,  1.3028e+00,\n",
       "            5.9739e-01,  2.7427e+00],\n",
       "          ...,\n",
       "          [-2.1328e+00, -2.8438e+00,  1.9171e+00,  ...,  1.3325e+00,\n",
       "           -4.6608e-02,  1.8631e+00],\n",
       "          [ 1.9578e+00, -2.4674e+00,  2.3165e+00,  ...,  2.4243e+00,\n",
       "           -1.1462e-01,  2.0488e+00],\n",
       "          [ 1.6747e+00, -1.3275e+00,  1.3384e+00,  ...,  2.9306e+00,\n",
       "           -2.2174e-01,  2.3920e-02]],\n",
       "\n",
       "         [[ 4.3808e-04,  1.1686e-02, -5.7792e-03,  ...,  6.2559e-01,\n",
       "           -1.0116e+00, -8.4888e-01],\n",
       "          [-2.0746e+00, -1.2323e-01, -7.7971e-01,  ...,  3.7637e-01,\n",
       "            2.0952e+00,  3.2913e+00],\n",
       "          [-1.0388e+00,  6.8162e-01, -1.9384e+00,  ..., -2.0609e+00,\n",
       "            3.0122e+00,  1.0999e+00],\n",
       "          ...,\n",
       "          [ 1.4597e-01, -1.0379e+00,  1.5390e+00,  ..., -2.0893e+00,\n",
       "            2.3903e+00,  4.6506e-01],\n",
       "          [-2.0257e+00,  2.0982e+00,  5.2097e-01,  ..., -1.4359e+00,\n",
       "            2.4654e+00,  2.9367e+00],\n",
       "          [-1.0181e+00,  2.2658e+00, -1.7076e+00,  ...,  7.0953e-01,\n",
       "            2.3266e+00,  3.8863e+00]],\n",
       "\n",
       "         [[-1.3111e-02,  1.4834e-02, -2.3796e-02,  ..., -3.9326e-01,\n",
       "            3.6678e-01, -3.6051e-01],\n",
       "          [ 4.6619e+00, -1.0595e+00,  4.1025e+00,  ...,  1.9437e+00,\n",
       "           -1.7597e-01, -7.3630e-01],\n",
       "          [-3.2091e-01, -1.2387e-01,  1.1719e+00,  ...,  1.6533e+00,\n",
       "           -1.6144e-01, -8.6732e-01],\n",
       "          ...,\n",
       "          [ 1.0278e+00, -2.8443e-01, -1.0534e+00,  ..., -6.1348e-01,\n",
       "           -4.3445e-01, -5.9842e-01],\n",
       "          [ 1.5762e+00,  8.0473e-01, -1.2309e+00,  ...,  1.4519e+00,\n",
       "            1.0334e-01,  6.1249e-02],\n",
       "          [-2.0712e-01,  1.3708e-03, -1.9305e-01,  ..., -1.7217e+00,\n",
       "            1.9869e+00, -8.9651e-02]]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>), tensor([[[[ 1.4128e-03, -1.0793e-03,  1.4725e-03,  ...,  1.3058e-04,\n",
       "           -1.7140e-03,  1.8315e-03],\n",
       "          [-5.6690e-02, -1.4131e-01,  1.6212e-02,  ..., -5.9946e-02,\n",
       "           -1.2148e-02,  3.2250e-02],\n",
       "          [-1.8172e-02, -8.9214e-03,  7.9589e-03,  ..., -5.0986e-02,\n",
       "            1.3010e-01, -6.1780e-02],\n",
       "          ...,\n",
       "          [ 1.1258e-02,  5.3555e-02, -5.4084e-02,  ..., -3.5281e-02,\n",
       "            1.2864e-02, -2.2574e-01],\n",
       "          [-1.6995e-02,  1.2478e-01, -7.2429e-02,  ...,  4.1787e-03,\n",
       "           -1.4712e-01,  2.7341e-02],\n",
       "          [-7.2792e-02,  3.5587e-02, -3.7982e-02,  ...,  1.3697e-01,\n",
       "            4.7512e-02,  9.1045e-02]],\n",
       "\n",
       "         [[ 4.3206e-02,  7.5958e-05, -2.5582e-04,  ...,  6.5912e-04,\n",
       "            3.1622e-04,  3.3353e-04],\n",
       "          [-3.2744e-01,  3.7715e-03,  2.4960e-01,  ...,  4.8160e-02,\n",
       "           -1.1852e-01,  1.0568e-01],\n",
       "          [-2.4167e-01,  8.9121e-02,  1.4501e-01,  ..., -2.0461e-01,\n",
       "           -2.6334e-02, -7.6632e-02],\n",
       "          ...,\n",
       "          [-2.7544e-01, -4.1759e-02, -1.3937e-02,  ...,  9.4721e-03,\n",
       "            4.3874e-02, -1.5004e-01],\n",
       "          [-2.1991e-01,  2.6316e-04,  1.0002e-01,  ...,  3.2969e-02,\n",
       "            1.4683e-02,  1.5944e-01],\n",
       "          [-2.9395e-01,  5.7384e-02, -2.3324e-01,  ..., -1.1082e-01,\n",
       "           -1.7805e-01, -1.1036e-01]],\n",
       "\n",
       "         [[-7.2910e-05,  6.8008e-03, -1.6479e-04,  ..., -1.7664e-03,\n",
       "           -8.3313e-04,  1.0218e-03],\n",
       "          [-6.8283e-02, -2.5838e-01, -3.9044e-02,  ...,  7.1132e-02,\n",
       "            1.2665e-01,  3.8804e-02],\n",
       "          [ 9.7515e-02, -1.9317e-01, -3.9866e-02,  ...,  1.4611e-01,\n",
       "            1.9435e-01,  1.1386e-01],\n",
       "          ...,\n",
       "          [-1.0572e-01, -1.5365e-02, -2.0681e-02,  ..., -6.3863e-02,\n",
       "            6.5886e-02,  3.6256e-02],\n",
       "          [-2.0045e-01, -1.9354e-01, -7.4978e-02,  ..., -9.6946e-02,\n",
       "           -1.9467e-03, -9.3623e-02],\n",
       "          [-5.2492e-02,  1.6540e-02, -2.3546e-02,  ...,  2.1612e-01,\n",
       "            2.3301e-02,  1.4668e-01]],\n",
       "\n",
       "         [[ 1.9950e-03, -1.3852e-02, -1.9574e-03,  ..., -1.5802e-03,\n",
       "            2.8613e-04, -5.8623e-03],\n",
       "          [-1.4370e-01,  2.6107e-01, -1.7974e-02,  ..., -3.1374e-02,\n",
       "            5.6627e-02, -9.2105e-02],\n",
       "          [-1.2876e-01,  2.3086e-01, -4.1231e-02,  ...,  5.6640e-02,\n",
       "           -1.5973e-01, -1.6816e-02],\n",
       "          ...,\n",
       "          [-1.7892e-01,  2.6800e-01, -6.3617e-02,  ...,  7.9950e-02,\n",
       "            5.3496e-02,  2.2710e-01],\n",
       "          [-1.2063e-01,  1.4647e-01,  6.3151e-02,  ...,  9.0973e-03,\n",
       "           -2.2053e-02,  1.5302e-01],\n",
       "          [ 3.9885e-02, -1.0152e-01, -1.0909e-01,  ...,  8.9406e-02,\n",
       "           -9.0028e-02, -1.0044e-01]]]], device='cuda:0',\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[ 1.2247e-02,  1.3163e-02,  8.1962e-03,  ...,  1.9597e-01,\n",
       "            5.1974e-01, -1.5290e+00],\n",
       "          [-1.8173e+00, -2.3939e+00,  6.7721e-01,  ...,  8.3181e-01,\n",
       "           -4.3347e-01,  3.3294e+00],\n",
       "          [-3.9454e+00,  9.3219e-01,  9.0734e-01,  ..., -1.3050e-01,\n",
       "           -1.7705e+00,  5.1341e+00],\n",
       "          ...,\n",
       "          [ 2.4688e+00, -1.1799e+00, -1.4662e+00,  ...,  1.0546e+00,\n",
       "           -9.3410e-01,  4.4000e+00],\n",
       "          [ 4.4921e-01, -9.0027e-01,  8.4559e-01,  ...,  2.1067e+00,\n",
       "           -7.4471e-01,  3.2230e+00],\n",
       "          [ 1.7425e-01, -4.5457e-01,  6.5780e-01,  ...,  1.2154e+00,\n",
       "           -9.2670e-01,  2.6372e+00]],\n",
       "\n",
       "         [[ 2.5596e-02, -7.7332e-03, -1.6848e-02,  ...,  4.2527e-01,\n",
       "           -1.3503e+00,  4.3388e-01],\n",
       "          [-2.9619e+00,  4.9332e-01,  4.7280e-01,  ..., -8.3461e-01,\n",
       "            3.3326e+00, -1.0445e+00],\n",
       "          [ 2.9205e+00,  2.7959e+00, -1.2783e+00,  ..., -2.0200e+00,\n",
       "            3.8865e+00, -1.1638e+00],\n",
       "          ...,\n",
       "          [-2.0319e+00,  9.7741e-01, -5.5303e-01,  ...,  2.6756e-02,\n",
       "            2.7312e+00, -1.5716e+00],\n",
       "          [-2.5146e+00,  2.2456e+00,  4.2671e-01,  ..., -1.1981e+00,\n",
       "            4.1354e+00, -5.1937e-01],\n",
       "          [-1.3891e+00,  2.5522e+00,  2.0754e+00,  ..., -2.5468e+00,\n",
       "            4.0643e+00, -1.8347e-01]],\n",
       "\n",
       "         [[-2.7917e-02,  1.7670e-02, -2.6039e-02,  ..., -5.4157e-01,\n",
       "            5.6415e-01,  5.3919e-01],\n",
       "          [ 1.1029e+00, -4.0704e-01,  1.0528e+00,  ..., -9.5167e-01,\n",
       "            2.5431e+00, -2.7527e+00],\n",
       "          [ 1.5749e+00,  8.0058e-01,  1.5187e+00,  ..., -1.7975e-02,\n",
       "            9.4361e-01, -1.4565e+00],\n",
       "          ...,\n",
       "          [-2.0255e-01,  4.7162e-01, -2.1524e+00,  ..., -1.5545e-01,\n",
       "            7.9678e-01, -8.4970e-01],\n",
       "          [ 8.4828e-01,  8.7434e-01,  1.7471e-01,  ...,  1.9108e+00,\n",
       "            2.4570e+00,  2.9786e-01],\n",
       "          [-4.8077e-01, -4.9975e-01, -3.1747e-01,  ...,  1.4791e+00,\n",
       "            1.0420e+00,  1.0873e+00]],\n",
       "\n",
       "         [[-3.1609e-03,  5.8437e-03,  2.5457e-02,  ...,  1.1112e+00,\n",
       "           -1.8788e-01,  1.1692e+00],\n",
       "          [ 1.1995e+00,  9.2381e-01, -5.7927e-01,  ..., -3.7710e+00,\n",
       "           -3.2789e+00, -1.8796e+00],\n",
       "          [ 3.8843e+00,  9.7476e-01,  2.6936e+00,  ..., -4.1305e+00,\n",
       "           -2.7310e+00, -1.8198e+00],\n",
       "          ...,\n",
       "          [-2.8826e+00,  2.2092e+00, -1.1895e+00,  ..., -3.6045e+00,\n",
       "            4.4226e-01, -3.5738e+00],\n",
       "          [-9.9614e-01,  1.0301e-01, -1.1103e+00,  ..., -5.3434e+00,\n",
       "           -6.4696e-01, -1.1807e+00],\n",
       "          [ 4.7450e-01,  2.9347e-02, -1.1522e+00,  ..., -3.1681e+00,\n",
       "           -2.5700e+00, -2.0483e+00]]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>), tensor([[[[ 2.3552e-03,  1.4539e-03, -6.0774e-04,  ...,  8.9456e-04,\n",
       "           -6.7187e-04, -6.1322e-04],\n",
       "          [ 4.6186e-02, -8.6654e-04,  6.8849e-02,  ..., -1.4035e-01,\n",
       "           -2.5768e-02, -4.4206e-02],\n",
       "          [ 1.7835e-02,  1.2687e-01,  1.3541e-01,  ..., -9.8355e-02,\n",
       "            3.2299e-02, -9.5448e-02],\n",
       "          ...,\n",
       "          [-1.5426e-01, -8.3352e-02, -1.3999e-02,  ...,  2.4894e-02,\n",
       "           -1.2980e-01, -5.0341e-02],\n",
       "          [-1.8494e-01,  1.5412e-01, -1.3327e-01,  ...,  6.3317e-02,\n",
       "           -9.8578e-02, -4.6497e-02],\n",
       "          [-1.6991e-01,  1.6846e-01,  1.4986e-01,  ..., -2.2535e-02,\n",
       "            1.1004e-01, -2.0155e-01]],\n",
       "\n",
       "         [[-3.8724e-03, -5.0347e-04, -1.2531e-03,  ..., -9.8836e-05,\n",
       "           -3.8942e-04,  1.9392e-03],\n",
       "          [ 1.5514e-02, -2.9983e-02, -3.2350e-02,  ...,  4.6061e-02,\n",
       "           -1.5120e-01,  6.3383e-02],\n",
       "          [-2.6134e-01, -1.9277e-01,  1.1926e-01,  ...,  1.0094e-02,\n",
       "            1.2975e-01, -2.6160e-01],\n",
       "          ...,\n",
       "          [ 9.4603e-02,  9.2873e-02, -2.0793e-01,  ..., -2.3269e-02,\n",
       "            7.5216e-03, -3.2092e-01],\n",
       "          [-5.0911e-03, -6.0727e-02, -1.3802e-03,  ...,  1.5455e-01,\n",
       "            6.0071e-02,  4.3269e-02],\n",
       "          [-7.9095e-02,  3.7854e-03,  4.8875e-02,  ...,  8.6382e-02,\n",
       "           -2.9899e-01, -8.2627e-02]],\n",
       "\n",
       "         [[-3.2659e-03, -3.5237e-04,  1.0087e-03,  ..., -1.0837e-03,\n",
       "            3.1299e-04, -1.2211e-03],\n",
       "          [ 3.7384e-02, -6.0992e-02,  2.0575e-01,  ..., -3.2083e-02,\n",
       "            2.2283e-01, -2.8863e-02],\n",
       "          [ 6.5669e-02, -1.5695e-01,  1.5283e-01,  ...,  1.4266e-01,\n",
       "            1.7283e-01,  5.8783e-02],\n",
       "          ...,\n",
       "          [-3.4691e-02,  1.4573e-01,  7.4390e-02,  ..., -2.5252e-01,\n",
       "           -1.8340e-01, -1.5255e-01],\n",
       "          [-3.3060e-02, -6.7331e-02, -3.6614e-02,  ...,  6.9603e-02,\n",
       "            1.4115e-01, -1.1588e-02],\n",
       "          [-1.0868e-01,  2.2841e-02, -5.2110e-02,  ..., -2.4321e-02,\n",
       "           -2.2477e-01, -1.8784e-01]],\n",
       "\n",
       "         [[-1.5420e-03, -2.3428e-03,  2.7805e-04,  ..., -6.1170e-04,\n",
       "           -8.9143e-04, -1.4510e-03],\n",
       "          [ 1.2460e-01,  1.2401e-01, -8.9258e-02,  ...,  2.0988e-01,\n",
       "            1.7625e-01, -5.6152e-02],\n",
       "          [ 1.0829e-01,  2.2250e-01,  2.6917e-02,  ...,  1.4308e-01,\n",
       "           -6.1658e-02, -3.0349e-02],\n",
       "          ...,\n",
       "          [-4.2771e-02,  2.2277e-01,  5.8922e-02,  ..., -8.1693e-02,\n",
       "           -1.4331e-01, -1.3805e-01],\n",
       "          [-2.0114e-02,  2.1919e-01,  1.7170e-01,  ..., -1.3622e-01,\n",
       "           -2.3522e-03,  8.6551e-02],\n",
       "          [ 3.0495e-02, -7.8455e-02, -2.2994e-02,  ...,  9.8201e-02,\n",
       "            2.0431e-01,  4.2838e-02]]]], device='cuda:0',\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[ 4.5941e-03, -7.6582e-03, -2.8074e-04,  ...,  2.8754e-02,\n",
       "           -1.2697e+00,  1.4714e+00],\n",
       "          [-1.7754e+00,  2.4254e+00,  1.6889e+00,  ...,  2.2244e+00,\n",
       "            3.0659e+00, -2.4986e+00],\n",
       "          [-3.7009e+00,  2.2691e+00, -4.3261e-01,  ...,  1.9574e+00,\n",
       "            3.8885e+00, -4.1512e+00],\n",
       "          ...,\n",
       "          [ 1.5969e+00,  1.6899e+00,  3.3870e-01,  ...,  1.1322e+00,\n",
       "            2.8615e+00, -3.5589e+00],\n",
       "          [-1.3033e+00,  9.9760e-01, -9.0369e-01,  ..., -7.2677e-01,\n",
       "            4.5649e+00, -3.2551e+00],\n",
       "          [-6.3692e-01,  2.2842e-02, -8.4947e-01,  ..., -2.0800e-01,\n",
       "            3.8011e+00, -2.8361e+00]],\n",
       "\n",
       "         [[-1.4821e-02, -8.0882e-03,  1.0038e-02,  ...,  1.2013e-01,\n",
       "            2.1319e-01,  1.5457e-01],\n",
       "          [-1.5071e+00,  6.2864e-01,  2.5050e+00,  ..., -1.5026e+00,\n",
       "            1.3872e+00, -1.5159e+00],\n",
       "          [ 4.2055e+00, -4.9223e+00, -7.6031e-01,  ..., -1.5030e+00,\n",
       "           -1.1876e+00, -1.1385e+00],\n",
       "          ...,\n",
       "          [-2.9908e+00,  9.2821e-01, -5.6132e-01,  ..., -2.7954e-01,\n",
       "           -9.1419e-01, -1.0661e-01],\n",
       "          [-5.7807e-01,  5.5774e-01, -6.3073e-02,  ..., -1.2269e+00,\n",
       "           -6.7622e-01, -5.4073e-01],\n",
       "          [ 5.9970e-01, -1.2052e-01, -6.1475e-02,  ...,  3.5475e-01,\n",
       "            1.6283e-01,  1.0042e+00]],\n",
       "\n",
       "         [[ 3.9473e-03, -1.3314e-02,  6.2181e-03,  ..., -1.2933e+00,\n",
       "           -1.3089e-02, -6.4582e-02],\n",
       "          [-5.1364e+00,  3.0438e+00,  4.2065e+00,  ...,  2.9913e+00,\n",
       "           -6.3656e-01,  6.6396e-02],\n",
       "          [-4.8306e+00,  1.7308e+00,  2.5176e+00,  ...,  4.1279e+00,\n",
       "           -2.3340e-02,  5.8662e-01],\n",
       "          ...,\n",
       "          [ 2.9898e+00,  3.5453e+00,  4.7547e-02,  ...,  3.5463e+00,\n",
       "           -1.0453e+00,  5.0279e-01],\n",
       "          [-1.4270e+00,  2.5471e+00, -2.8845e+00,  ...,  3.9960e+00,\n",
       "           -1.4945e+00,  6.6078e-01],\n",
       "          [-1.4277e+00,  9.2345e-01, -1.2045e+00,  ...,  4.1927e+00,\n",
       "           -1.8032e+00,  1.5773e-01]],\n",
       "\n",
       "         [[-2.1998e-02, -2.1935e-02, -6.9957e-03,  ...,  2.6271e-01,\n",
       "           -1.3771e+00, -7.6766e-01],\n",
       "          [-1.1688e+00, -6.8631e-02, -2.3279e+00,  ...,  9.1715e-01,\n",
       "            1.3790e+00,  3.5084e+00],\n",
       "          [ 3.8230e+00,  3.2573e+00, -3.7079e+00,  ...,  2.0196e-01,\n",
       "            1.6840e+00,  4.3438e+00],\n",
       "          ...,\n",
       "          [-2.5857e+00,  3.1017e-01,  2.7426e+00,  ...,  1.2440e+00,\n",
       "            9.7167e-01,  1.5460e+00],\n",
       "          [-7.9198e-01,  1.2481e+00,  1.5969e+00,  ...,  1.2673e+00,\n",
       "            1.4030e+00,  2.7118e+00],\n",
       "          [-3.1779e-01,  4.6492e-02,  1.6494e-02,  ...,  1.2398e-01,\n",
       "            3.8279e+00,  1.4626e+00]]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>), tensor([[[[-8.6129e-04,  1.0483e-03,  9.2213e-04,  ..., -5.3647e-04,\n",
       "           -4.1786e-03, -1.8414e-03],\n",
       "          [ 7.3052e-02,  9.1257e-02,  5.5343e-02,  ..., -1.4052e-01,\n",
       "            3.0699e-01,  2.8930e-02],\n",
       "          [-4.7780e-02,  2.8703e-02,  7.4629e-03,  ..., -7.0851e-02,\n",
       "            2.1633e-01, -1.4452e-02],\n",
       "          ...,\n",
       "          [ 7.2473e-02, -9.5697e-02, -1.6500e-01,  ...,  4.5589e-03,\n",
       "           -7.1987e-02, -1.6431e-01],\n",
       "          [ 3.4583e-02, -1.8412e-01, -3.0449e-02,  ..., -3.9794e-02,\n",
       "           -2.1159e-01, -6.8227e-02],\n",
       "          [ 1.1355e-01, -9.6067e-02, -3.4204e-02,  ..., -4.5383e-03,\n",
       "            1.1150e-01, -1.1550e-01]],\n",
       "\n",
       "         [[ 5.0149e-03, -1.9523e-03,  8.1388e-04,  ...,  4.2745e-03,\n",
       "           -7.5231e-03, -2.2397e-03],\n",
       "          [ 3.2158e-02,  2.6174e-01, -2.0136e-01,  ..., -7.5110e-02,\n",
       "            1.1914e-01,  2.2363e-01],\n",
       "          [ 1.1677e-01, -3.0462e-01,  1.9347e-01,  ...,  1.2906e-03,\n",
       "           -1.9005e-03, -9.3345e-02],\n",
       "          ...,\n",
       "          [ 1.2413e-01, -9.3959e-02,  4.7458e-02,  ..., -4.7930e-02,\n",
       "           -3.2021e-01,  1.9576e-02],\n",
       "          [ 1.3958e-02, -2.4105e-02,  3.9648e-02,  ..., -4.9273e-02,\n",
       "            2.6169e-02,  2.2993e-01],\n",
       "          [-4.6386e-01,  2.1195e-01, -1.2998e-02,  ..., -1.8111e-01,\n",
       "            3.7726e-01, -9.4687e-02]],\n",
       "\n",
       "         [[-3.3683e-03,  4.0477e-03,  4.1843e-03,  ..., -2.9689e-02,\n",
       "            2.0840e-03, -2.1540e-03],\n",
       "          [-5.1909e-01, -1.1326e-01,  5.5883e-02,  ...,  1.2105e-01,\n",
       "           -1.2919e-02, -1.4891e-01],\n",
       "          [-4.8254e-03, -2.4252e-02, -5.9131e-02,  ...,  1.7701e-01,\n",
       "            1.8149e-02, -1.8126e-02],\n",
       "          ...,\n",
       "          [-1.6638e-01,  2.0031e-01, -1.3008e-01,  ...,  3.0673e-01,\n",
       "           -2.2137e-01, -2.8800e-03],\n",
       "          [-1.6552e-01, -9.9870e-02, -1.5507e-02,  ...,  4.7543e-01,\n",
       "           -1.2230e-01,  2.2082e-01],\n",
       "          [ 1.5381e-01,  1.1205e-01, -9.9133e-02,  ...,  5.4811e-01,\n",
       "           -1.7437e-01,  1.9852e-01]],\n",
       "\n",
       "         [[-3.8767e-04, -1.2653e-03, -1.3083e-03,  ...,  3.3240e-04,\n",
       "           -3.5571e-04,  4.1968e-03],\n",
       "          [ 1.6970e-01, -4.4038e-02,  5.5669e-02,  ...,  5.4618e-02,\n",
       "           -1.3031e-02,  3.9678e-02],\n",
       "          [ 2.1902e-01,  1.8187e-01,  2.3834e-03,  ..., -8.0880e-02,\n",
       "            2.3807e-01,  1.1634e-01],\n",
       "          ...,\n",
       "          [ 2.1624e-01,  2.7197e-01, -3.5208e-01,  ..., -1.6221e-01,\n",
       "           -3.1606e-01,  9.4557e-02],\n",
       "          [ 1.6607e-03, -6.9886e-02, -2.2848e-01,  ..., -1.2149e-01,\n",
       "            2.2599e-02,  2.0891e-01],\n",
       "          [-1.2240e-01, -1.7203e-02, -8.1171e-02,  ...,  1.7390e-01,\n",
       "            1.2051e-02, -2.9716e-01]]]], device='cuda:0',\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[ 1.5692e-02,  5.5516e-03,  7.0507e-03,  ...,  4.4828e-01,\n",
       "            6.8328e-01,  7.4644e-01],\n",
       "          [-2.0534e+00, -2.2989e+00,  2.7980e-03,  ..., -1.3133e-01,\n",
       "           -1.4330e+00, -1.6519e+00],\n",
       "          [-4.2361e+00, -3.0062e+00,  2.1084e+00,  ...,  1.1650e+00,\n",
       "           -2.6062e+00, -2.3801e+00],\n",
       "          ...,\n",
       "          [ 1.1609e+00, -2.3035e+00, -1.4374e+00,  ..., -3.5293e-01,\n",
       "           -3.2685e+00, -7.1070e-01],\n",
       "          [-3.7297e-01, -1.7244e+00, -2.9297e-01,  ...,  1.0180e+00,\n",
       "           -7.8580e-01, -1.4539e+00],\n",
       "          [-6.7033e-01, -2.5970e-01,  2.5833e-01,  ...,  1.4385e+00,\n",
       "            2.2438e-01,  8.3189e-01]],\n",
       "\n",
       "         [[-4.9446e-03, -1.2094e-02, -1.6133e-02,  ..., -1.1322e-01,\n",
       "           -2.6944e-02,  3.5436e-01],\n",
       "          [ 1.4241e+00,  1.9707e-01, -1.7573e+00,  ...,  3.8778e+00,\n",
       "           -4.5303e-02,  1.8481e+00],\n",
       "          [ 2.0876e+00, -1.2954e+00, -1.3368e-01,  ...,  1.2138e+00,\n",
       "           -2.9570e-01,  1.1104e+00],\n",
       "          ...,\n",
       "          [-1.8775e+00, -1.8945e+00,  1.5900e+00,  ...,  8.2625e-01,\n",
       "            5.5278e-01,  1.6542e-01],\n",
       "          [ 2.4038e-01, -1.3028e+00,  7.2024e-01,  ...,  3.1625e+00,\n",
       "           -1.1782e+00,  1.6583e-01],\n",
       "          [ 1.0869e+00,  5.6561e-02,  2.1968e-01,  ...,  2.6665e+00,\n",
       "           -1.5205e+00, -2.0044e+00]],\n",
       "\n",
       "         [[ 5.1373e-03,  6.1314e-03, -4.7955e-03,  ...,  1.3818e-01,\n",
       "           -1.2072e-02, -9.7741e-02],\n",
       "          [ 6.8769e+00,  3.3614e+00, -3.2889e+00,  ..., -1.4976e+00,\n",
       "            8.2653e-01,  5.8311e-01],\n",
       "          [ 5.9173e+00,  3.1419e+00, -5.3809e+00,  ...,  1.0013e+00,\n",
       "           -5.1564e-01,  1.4557e-01],\n",
       "          ...,\n",
       "          [-3.6696e+00,  2.9202e+00,  3.8411e+00,  ...,  6.7012e-01,\n",
       "           -2.5237e-01,  3.0803e-01],\n",
       "          [ 1.5585e+00,  3.6711e+00,  2.4423e+00,  ..., -5.5205e-01,\n",
       "           -4.0832e-01,  1.6748e+00],\n",
       "          [ 5.6266e+00,  7.0183e-01,  2.4380e+00,  ..., -2.6901e-01,\n",
       "           -3.7105e-01,  9.5724e-01]],\n",
       "\n",
       "         [[ 9.1783e-03,  1.8218e-02,  1.2733e-03,  ...,  1.2699e+00,\n",
       "           -1.5587e+00, -8.7187e-02],\n",
       "          [-1.6741e+00, -2.6594e+00,  6.5001e-01,  ...,  4.3242e-01,\n",
       "            5.9267e+00,  1.7100e+00],\n",
       "          [ 2.5135e+00, -1.1460e+00, -1.3505e+00,  ..., -1.8838e+00,\n",
       "            2.1949e+00, -2.3949e+00],\n",
       "          ...,\n",
       "          [-2.0811e+00, -2.7402e+00, -4.9237e-01,  ..., -6.5883e+00,\n",
       "            5.5613e+00, -4.8708e+00],\n",
       "          [-2.4695e+00, -9.8742e-01,  1.1637e+00,  ..., -2.8047e+00,\n",
       "            3.7885e+00, -2.4673e+00],\n",
       "          [-2.8405e-01,  5.3672e-01,  1.3149e+00,  ..., -2.5139e+00,\n",
       "            4.3600e+00, -1.8792e+00]]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>), tensor([[[[ 1.8551e-03,  9.0555e-04, -1.6796e-03,  ..., -1.5048e-03,\n",
       "           -1.1477e-04, -4.2515e-03],\n",
       "          [ 1.3931e-01, -3.0729e-02,  1.6027e-01,  ...,  9.0289e-02,\n",
       "           -1.0953e-01, -3.9378e-02],\n",
       "          [ 5.4715e-02, -6.5263e-02, -3.1411e-02,  ...,  2.2477e-02,\n",
       "           -1.1162e-01, -8.8245e-02],\n",
       "          ...,\n",
       "          [ 3.9858e-01, -1.3142e-01, -2.5010e-02,  ...,  8.7807e-02,\n",
       "            1.1061e-01,  3.5062e-02],\n",
       "          [ 1.0964e-01,  7.8177e-02,  2.3922e-01,  ...,  2.3889e-01,\n",
       "            6.0517e-02,  3.0744e-01],\n",
       "          [ 4.0145e-01, -9.3793e-02, -2.5888e-02,  ...,  1.8365e-01,\n",
       "           -3.3063e-02,  1.0615e-01]],\n",
       "\n",
       "         [[ 2.7628e-03,  9.4756e-04, -2.7735e-03,  ..., -1.2101e-03,\n",
       "            2.7578e-03,  2.4503e-03],\n",
       "          [ 8.6288e-02,  2.3416e-01,  1.2427e-01,  ...,  1.2773e-01,\n",
       "            9.6728e-02, -1.5333e-02],\n",
       "          [ 1.5749e-01,  2.4183e-01, -9.2293e-02,  ..., -1.1108e-01,\n",
       "            2.4564e-01, -4.5260e-03],\n",
       "          ...,\n",
       "          [-3.6484e-02,  4.8945e-02,  1.4824e-01,  ..., -1.7352e-01,\n",
       "            5.5668e-02,  2.4593e-02],\n",
       "          [ 2.4195e-01, -3.4366e-02,  9.3405e-02,  ...,  8.8064e-02,\n",
       "            1.9246e-02, -2.3320e-01],\n",
       "          [-2.7796e-02, -1.4969e-03,  3.7769e-02,  ...,  4.9134e-02,\n",
       "           -4.1370e-02,  3.2461e-01]],\n",
       "\n",
       "         [[-1.6814e-02, -1.9886e-04,  2.2836e-03,  ...,  1.1997e-03,\n",
       "            3.1127e-03, -5.5456e-04],\n",
       "          [ 8.9325e-02, -3.5287e-02, -4.7218e-02,  ..., -1.0970e-02,\n",
       "           -1.0852e-01, -1.9140e-02],\n",
       "          [-3.6419e-01, -2.7890e-02,  1.5409e-01,  ...,  4.6680e-02,\n",
       "           -8.0855e-02, -1.4474e-01],\n",
       "          ...,\n",
       "          [-1.6451e-01, -6.4760e-02, -1.2235e-01,  ..., -1.4430e-01,\n",
       "            1.2202e-01, -9.3784e-02],\n",
       "          [ 5.4916e-01, -1.9295e-01, -1.3375e-01,  ..., -2.1422e-01,\n",
       "            3.5624e-03, -1.1691e-01],\n",
       "          [ 7.8484e-01, -1.0521e-02,  2.9678e-01,  ..., -2.6605e-02,\n",
       "            5.1267e-02, -1.4778e-01]],\n",
       "\n",
       "         [[-1.5039e-03, -2.8248e-04, -1.2671e-03,  ..., -2.1891e-03,\n",
       "            1.2333e-03,  1.0945e-03],\n",
       "          [ 7.1136e-02, -1.1460e-01,  6.9477e-02,  ...,  9.8404e-02,\n",
       "           -5.9763e-03, -2.5918e-02],\n",
       "          [ 8.2051e-02, -8.3312e-02,  1.5182e-01,  ..., -1.9803e-01,\n",
       "            9.7455e-02, -1.2217e-01],\n",
       "          ...,\n",
       "          [ 6.9906e-02, -9.1934e-04,  7.7311e-03,  ..., -5.8994e-02,\n",
       "            1.0061e-01, -1.4578e-01],\n",
       "          [ 6.1100e-02, -4.4166e-02, -2.5747e-02,  ..., -1.9009e-01,\n",
       "            1.8440e-01, -1.1205e-01],\n",
       "          [ 1.5764e-02, -5.9575e-02,  3.0936e-03,  ..., -1.0122e-02,\n",
       "           -2.1870e-02, -1.6270e-01]]]], device='cuda:0',\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[-7.3987e-04, -4.3722e-03, -1.6239e-02,  ..., -1.5853e-01,\n",
       "            3.8946e-01, -1.8658e+00],\n",
       "          [ 1.1983e+00,  5.7200e-01,  1.0679e+00,  ...,  6.5601e-01,\n",
       "           -3.0687e-01,  1.1503e+00],\n",
       "          [ 1.1444e+00, -1.1904e+00, -1.1931e-01,  ...,  1.7909e+00,\n",
       "           -2.9385e-01,  1.3559e+00],\n",
       "          ...,\n",
       "          [-3.1464e-01, -9.8298e-02, -1.7577e+00,  ...,  1.4571e+00,\n",
       "           -1.5195e+00,  1.0309e+00],\n",
       "          [ 1.2084e+00, -9.0706e-01, -8.7875e-01,  ...,  7.9985e-01,\n",
       "           -1.3104e+00,  1.6459e+00],\n",
       "          [ 4.5394e-01, -9.3216e-01, -1.3794e-01,  ...,  1.2834e+00,\n",
       "            1.2019e+00,  1.6376e+00]],\n",
       "\n",
       "         [[-7.9508e-04, -1.3108e-02, -1.2561e-03,  ...,  3.1516e-01,\n",
       "            3.5199e-02, -2.3916e+00],\n",
       "          [ 1.6003e+00,  4.1820e-01,  8.5423e-01,  ..., -2.1715e-02,\n",
       "            1.5560e+00,  2.8031e+00],\n",
       "          [ 1.1035e+00, -2.5115e+00,  1.8115e+00,  ..., -3.3985e-02,\n",
       "           -7.2683e-01,  4.1342e+00],\n",
       "          ...,\n",
       "          [ 2.3887e-01, -8.6554e-01, -8.1740e-01,  ...,  1.0377e-01,\n",
       "            1.2942e+00,  2.2194e+00],\n",
       "          [ 4.3120e-01, -6.9920e-01, -6.8191e-01,  ..., -1.1885e+00,\n",
       "            1.7468e+00,  3.4671e+00],\n",
       "          [-2.1217e-01, -1.2359e+00,  3.2997e-02,  ..., -1.9342e+00,\n",
       "            5.5638e-01,  2.9359e+00]],\n",
       "\n",
       "         [[-3.8978e-03, -3.7423e-02, -2.7849e-02,  ...,  1.1196e+00,\n",
       "           -5.2517e-01,  1.5611e+00],\n",
       "          [-2.1139e-01, -8.5210e-01,  1.7803e+00,  ...,  1.9058e+00,\n",
       "           -1.0063e+00, -2.4308e+00],\n",
       "          [-1.4263e+00, -1.4298e+00,  7.2706e-01,  ...,  1.3269e+00,\n",
       "            3.1880e+00, -4.3818e+00],\n",
       "          ...,\n",
       "          [ 9.4948e-01,  4.4101e-01, -8.1402e-01,  ...,  2.2432e+00,\n",
       "            2.5761e+00, -2.5095e+00],\n",
       "          [-1.2245e+00, -1.7321e+00, -1.2865e+00,  ...,  2.1888e+00,\n",
       "            4.5945e+00, -2.9033e+00],\n",
       "          [-1.2008e+00, -9.0263e-01, -7.4149e-01,  ...,  4.7608e-01,\n",
       "            5.9400e+00, -3.2776e+00]],\n",
       "\n",
       "         [[ 2.1910e-02, -9.1649e-03,  1.8551e-02,  ...,  7.4143e-01,\n",
       "           -2.8701e+00, -1.3363e+00],\n",
       "          [-7.2248e-01,  9.7355e-01,  3.1701e-01,  ..., -3.5272e+00,\n",
       "            1.4813e+00,  1.0931e+00],\n",
       "          [ 1.3394e+00, -4.7933e-02, -9.0930e-01,  ..., -2.0073e+00,\n",
       "            3.3012e+00,  2.1122e+00],\n",
       "          ...,\n",
       "          [-1.5817e+00,  1.0550e+00,  9.5187e-01,  ..., -1.3510e-01,\n",
       "            3.5920e+00,  1.6366e+00],\n",
       "          [-1.2648e+00, -1.0095e+00,  5.1576e-01,  ..., -1.9359e+00,\n",
       "            2.2240e+00,  4.2116e+00],\n",
       "          [ 1.6538e-02, -1.2453e+00,  8.6193e-01,  ..., -1.3813e+00,\n",
       "            2.9874e+00,  2.8265e+00]]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>), tensor([[[[-6.3808e-04,  2.3457e-03,  6.0856e-03,  ...,  5.6652e-03,\n",
       "            2.6644e-03,  2.7790e-03],\n",
       "          [ 1.2245e-02, -2.6509e-02, -3.4488e-02,  ...,  4.2925e-01,\n",
       "           -1.9687e-01,  2.1222e-01],\n",
       "          [-1.0137e-02, -1.1671e-01,  7.0428e-02,  ...,  4.1573e-02,\n",
       "           -9.3493e-02, -1.1502e-01],\n",
       "          ...,\n",
       "          [-2.6640e-01, -4.4869e-03,  4.6178e-03,  ..., -2.0365e-01,\n",
       "            7.2664e-02, -1.0089e-01],\n",
       "          [-9.6907e-02,  4.0122e-01, -1.7606e-01,  ...,  3.1876e-02,\n",
       "           -1.3462e-01, -1.3788e-01],\n",
       "          [-1.5319e-01,  2.4403e-02, -4.1066e-02,  ...,  1.3230e-01,\n",
       "           -4.2698e-01, -1.3149e-01]],\n",
       "\n",
       "         [[ 1.0880e-03, -8.3212e-04, -7.1307e-04,  ...,  1.9279e-03,\n",
       "           -2.0786e-03, -5.7800e-05],\n",
       "          [ 2.5760e-01, -5.7510e-02,  1.1044e-01,  ..., -1.3431e-01,\n",
       "            2.4881e-02, -1.0884e-01],\n",
       "          [-1.0262e-03, -2.8809e-01,  2.0752e-01,  ...,  1.8563e-01,\n",
       "            1.7095e-01, -3.5273e-02],\n",
       "          ...,\n",
       "          [ 1.0572e-01, -2.7697e-02,  5.9215e-02,  ...,  1.0749e-01,\n",
       "            1.5063e-01, -4.0458e-01],\n",
       "          [-1.7521e-02, -4.9827e-03, -2.6987e-01,  ...,  1.1340e-01,\n",
       "            1.1339e-01, -2.8678e-01],\n",
       "          [ 1.6513e-01, -1.0887e-01, -6.5021e-02,  ...,  3.4396e-02,\n",
       "            3.9311e-02,  5.5712e-02]],\n",
       "\n",
       "         [[-2.9147e-03, -2.3981e-03, -5.3369e-05,  ...,  2.8874e-03,\n",
       "           -9.4303e-03,  4.3207e-03],\n",
       "          [-2.8563e-01, -8.5148e-02, -1.7893e-01,  ...,  1.4519e-02,\n",
       "            5.1843e-01, -2.9871e-01],\n",
       "          [-1.1188e-01, -1.0529e-01, -7.4745e-02,  ...,  5.9426e-02,\n",
       "            3.5385e-01,  9.7102e-02],\n",
       "          ...,\n",
       "          [-2.0600e-02, -2.9980e-02, -1.5759e-01,  ...,  5.1931e-02,\n",
       "            5.5394e-02,  1.8542e-01],\n",
       "          [ 4.6451e-02, -4.2419e-02,  3.4470e-02,  ...,  1.9742e-01,\n",
       "           -1.0394e-01,  1.1542e-01],\n",
       "          [ 1.5786e-01, -4.2286e-02, -3.5444e-02,  ..., -1.9135e-01,\n",
       "            2.4253e-02,  5.5231e-02]],\n",
       "\n",
       "         [[-1.4188e-03, -1.2459e-03,  7.9105e-02,  ...,  1.7094e-03,\n",
       "           -4.3568e-04,  1.6371e-04],\n",
       "          [-1.7828e-01,  1.5224e-01, -8.4099e-02,  ..., -1.0395e-01,\n",
       "           -5.2659e-03,  1.3889e-02],\n",
       "          [-6.3001e-02,  3.8713e-03, -1.1978e-01,  ...,  1.5398e-01,\n",
       "            4.4301e-02,  7.0335e-03],\n",
       "          ...,\n",
       "          [ 1.5254e-01,  1.0187e-01, -1.3821e-01,  ..., -6.6757e-02,\n",
       "            9.7845e-02, -8.6099e-02],\n",
       "          [ 7.5317e-02, -6.3362e-02,  9.3415e-03,  ...,  1.0919e-01,\n",
       "            1.6896e-01,  6.0660e-02],\n",
       "          [ 7.3791e-02,  1.1387e-01,  1.0150e-01,  ..., -7.5488e-02,\n",
       "            9.5928e-02,  1.5374e-01]]]], device='cuda:0',\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[-9.0656e-03,  1.4728e-02, -1.0316e-02,  ..., -5.0694e-02,\n",
       "            5.1329e-02, -1.5783e-01],\n",
       "          [ 3.1738e+00,  7.8146e-02, -3.4429e+00,  ...,  2.1167e+00,\n",
       "            1.7813e-01, -1.7243e+00],\n",
       "          [ 4.4526e+00, -2.7117e+00, -3.3968e+00,  ...,  1.5071e-01,\n",
       "            8.9065e-01, -1.1743e+00],\n",
       "          ...,\n",
       "          [-2.4972e+00, -2.0921e+00,  2.1438e+00,  ..., -2.1739e-01,\n",
       "            3.2648e-01, -9.6221e-01],\n",
       "          [ 1.0365e+00, -9.2473e-01,  2.9740e+00,  ..., -8.8688e-01,\n",
       "            2.0670e-01, -6.4899e-01],\n",
       "          [ 1.4074e+00, -1.8984e+00,  1.4773e+00,  ..., -7.4526e-01,\n",
       "            9.7229e-01, -6.1723e-01]],\n",
       "\n",
       "         [[ 3.7768e-03, -8.3691e-03,  8.1640e-04,  ...,  4.6771e-01,\n",
       "            1.5315e+00,  1.5497e+00],\n",
       "          [-2.1070e-01, -2.8664e-01, -9.3191e-01,  ..., -2.3323e+00,\n",
       "           -6.8594e+00, -7.4368e+00],\n",
       "          [-1.1762e+00,  7.8703e-01, -8.7110e-01,  ...,  1.4465e+00,\n",
       "           -9.7103e+00, -6.7235e+00],\n",
       "          ...,\n",
       "          [ 8.3709e-01,  3.2086e-01,  9.3631e-01,  ...,  3.0793e+00,\n",
       "           -9.4086e+00, -1.0351e+01],\n",
       "          [-2.1030e-01,  3.6028e-01,  2.4701e-01,  ..., -3.6995e-01,\n",
       "            1.2518e+00, -1.4682e+01],\n",
       "          [-9.7776e-02,  5.7099e-01, -4.7531e-02,  ..., -4.5305e-02,\n",
       "           -2.3175e+00, -1.4967e+01]],\n",
       "\n",
       "         [[-1.5541e-02,  7.2343e-03,  3.2326e-02,  ...,  1.1345e+00,\n",
       "           -3.2809e-01,  6.7781e-01],\n",
       "          [-2.1135e+00,  3.1571e+00,  5.0296e-01,  ..., -3.3172e+00,\n",
       "            1.1820e+00,  3.4321e+00],\n",
       "          [-4.7196e+00,  2.4137e+00,  4.0453e+00,  ..., -4.0304e+00,\n",
       "           -1.0615e-01,  1.2060e+00],\n",
       "          ...,\n",
       "          [ 3.2891e+00,  3.1148e+00, -2.2066e+00,  ..., -4.1404e+00,\n",
       "            2.8181e-01, -5.5575e-01],\n",
       "          [-1.0142e+00,  1.4427e+00, -9.3853e-02,  ..., -3.6810e+00,\n",
       "            1.7610e+00,  1.1046e-01],\n",
       "          [-1.5455e+00,  3.0306e-01,  1.3351e-01,  ..., -3.5446e+00,\n",
       "            3.0029e+00,  3.3623e+00]],\n",
       "\n",
       "         [[ 5.6538e-03,  2.2066e-03,  2.2076e-02,  ...,  2.8817e-02,\n",
       "           -9.0223e-02,  2.2924e-01],\n",
       "          [ 1.5351e+00, -1.2930e+00, -9.0819e-01,  ..., -1.5917e-01,\n",
       "           -2.9708e+00,  3.9891e+00],\n",
       "          [ 2.5357e+00, -2.8992e+00,  1.6972e+00,  ...,  1.1492e+00,\n",
       "           -1.4674e+00, -2.8178e-01],\n",
       "          ...,\n",
       "          [-2.2247e+00, -1.1693e+00, -1.9418e+00,  ..., -9.8588e-01,\n",
       "           -4.8343e-01, -1.9079e+00],\n",
       "          [ 3.0908e-01, -3.4263e-01, -1.2315e+00,  ..., -5.4591e-01,\n",
       "           -1.8971e+00,  7.1834e-01],\n",
       "          [ 1.5311e-01, -3.1644e-01, -8.6674e-01,  ..., -2.4725e-01,\n",
       "           -3.1461e-01, -2.2290e-01]]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>), tensor([[[[ 3.4875e-03, -3.6159e-03,  2.6548e-03,  ...,  5.5758e-03,\n",
       "            3.3672e-04, -2.9282e-04],\n",
       "          [-8.3695e-02, -1.2396e-01,  2.3903e-02,  ..., -1.9224e-01,\n",
       "           -7.0740e-02,  1.8562e-01],\n",
       "          [-1.4484e-01, -5.0831e-02, -2.7901e-02,  ...,  5.9613e-02,\n",
       "            1.7337e-02,  1.1155e-02],\n",
       "          ...,\n",
       "          [-1.5728e-01, -9.9763e-02, -1.5028e-01,  ...,  1.5323e-01,\n",
       "           -9.1922e-02,  7.9135e-02],\n",
       "          [-1.1440e-01,  2.0354e-01,  9.9437e-02,  ...,  6.6737e-02,\n",
       "           -2.8877e-01, -9.3280e-02],\n",
       "          [-2.4385e-01,  1.5613e-01,  1.7825e-02,  ..., -1.3296e-01,\n",
       "            4.3132e-02,  2.5667e-02]],\n",
       "\n",
       "         [[-1.7850e-03, -1.0359e-03, -5.6666e-04,  ...,  1.6498e-03,\n",
       "            1.0112e-03, -2.1551e-03],\n",
       "          [-7.6741e-02, -3.0349e-01,  9.7807e-02,  ...,  3.4678e-01,\n",
       "           -1.3524e-01,  1.3507e-01],\n",
       "          [ 1.3205e-01, -1.7703e-01, -7.1272e-02,  ...,  2.8630e-01,\n",
       "           -2.7019e-01, -1.3468e-01],\n",
       "          ...,\n",
       "          [ 4.5536e-01, -9.2871e-02,  1.6242e-01,  ...,  2.9636e-01,\n",
       "           -1.5725e-01,  1.6130e-01],\n",
       "          [-1.3801e-01, -7.9391e-02,  7.6465e-02,  ...,  1.2016e-01,\n",
       "           -8.7644e-02, -7.6284e-03],\n",
       "          [ 2.4773e-02, -2.0121e-01,  1.0017e-01,  ..., -1.0716e-01,\n",
       "           -4.8935e-02,  1.4106e-02]],\n",
       "\n",
       "         [[ 1.0226e-03,  6.9512e-04, -3.2171e-03,  ..., -2.7678e-03,\n",
       "           -2.4902e-03,  4.5527e-03],\n",
       "          [ 1.4591e-01, -1.2007e-01, -1.2478e-02,  ..., -4.7144e-01,\n",
       "           -8.1253e-02, -3.8898e-02],\n",
       "          [ 1.2180e-01, -1.9098e-01,  1.6847e-01,  ...,  4.6853e-02,\n",
       "           -1.3299e-01, -1.5436e-01],\n",
       "          ...,\n",
       "          [ 4.3049e-02,  9.8639e-02, -8.6958e-03,  ...,  7.5460e-02,\n",
       "            2.1651e-02,  3.3663e-01],\n",
       "          [ 1.0539e-01, -2.1065e-02, -1.2296e-02,  ...,  8.1493e-02,\n",
       "           -1.4692e-01,  1.0479e-01],\n",
       "          [-1.0346e-01,  6.0793e-02,  8.0025e-02,  ...,  1.8134e-01,\n",
       "            7.9502e-02, -1.8394e-01]],\n",
       "\n",
       "         [[ 3.1888e-03, -4.7682e-03, -1.7669e-03,  ..., -1.1733e-03,\n",
       "           -5.3700e-03,  1.5553e-03],\n",
       "          [ 1.6364e-02,  1.9459e-01, -8.3360e-02,  ...,  1.2170e-01,\n",
       "           -7.1142e-02, -5.2106e-02],\n",
       "          [-1.3952e-01,  2.5059e-01, -9.5777e-02,  ...,  6.1281e-02,\n",
       "            2.3005e-01,  1.9098e-01],\n",
       "          ...,\n",
       "          [ 1.5147e-01,  2.6372e-01, -1.7996e-01,  ..., -8.5393e-02,\n",
       "           -4.5178e-02,  4.0691e-01],\n",
       "          [-2.3040e-01,  3.4473e-01, -3.5777e-01,  ...,  1.2210e-02,\n",
       "            1.1149e-01, -1.3595e-02],\n",
       "          [-3.1064e-02,  4.3633e-01,  8.4396e-02,  ..., -4.3407e-02,\n",
       "           -1.5964e-01, -1.0061e-01]]]], device='cuda:0',\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[-2.8863e-02,  1.0712e-02, -9.2087e-03,  ..., -2.5061e-01,\n",
       "           -4.7218e-02,  4.5379e-01],\n",
       "          [-4.1975e-01, -2.1947e+00,  5.7298e-01,  ..., -2.3099e-01,\n",
       "           -4.6084e-01,  1.9135e+00],\n",
       "          [ 6.9048e-01, -7.4818e-01, -3.1295e-02,  ..., -2.0289e+00,\n",
       "            1.0218e+00,  2.2467e+00],\n",
       "          ...,\n",
       "          [-9.4994e-01, -1.2127e+00,  1.9259e+00,  ..., -2.7332e-01,\n",
       "            1.8627e+00,  2.7554e+00],\n",
       "          [-1.4650e-01, -1.1470e+00, -8.8733e-01,  ...,  6.2712e-01,\n",
       "            3.5501e+00,  3.6330e+00],\n",
       "          [ 9.1798e-01, -1.9090e-01, -1.4576e+00,  ..., -6.3701e-01,\n",
       "            3.9167e+00,  2.6400e+00]],\n",
       "\n",
       "         [[-2.1075e-02,  1.3024e-03,  3.4200e-03,  ...,  7.5801e-02,\n",
       "           -8.2298e-01,  1.3739e-01],\n",
       "          [ 2.5239e+00,  2.5983e+00, -7.6076e-01,  ..., -2.7899e+00,\n",
       "            1.4570e+00,  4.5934e-01],\n",
       "          [-9.5319e-01,  2.5473e+00, -2.0244e+00,  ..., -2.1973e+00,\n",
       "           -3.4647e-01,  1.9982e+00],\n",
       "          ...,\n",
       "          [ 1.1847e+00,  2.0394e+00,  1.8374e+00,  ..., -8.8956e-01,\n",
       "           -2.2954e+00,  1.9597e+00],\n",
       "          [ 1.4906e+00,  1.6383e+00,  1.6314e+00,  ...,  7.5891e-01,\n",
       "            6.5433e-01,  1.5082e+00],\n",
       "          [ 1.0560e+00, -4.1878e-01,  1.9378e+00,  ...,  1.1133e-02,\n",
       "           -1.5957e-01,  1.6088e+00]],\n",
       "\n",
       "         [[-5.2564e-03,  3.5968e-03, -2.8349e-02,  ..., -4.9405e-02,\n",
       "           -1.9467e-02, -6.8965e-02],\n",
       "          [-3.5206e+00,  2.8713e+00, -2.2055e-01,  ...,  9.5602e-01,\n",
       "            5.3953e-01, -1.4810e+00],\n",
       "          [-5.0892e+00, -1.9812e-01,  3.4358e+00,  ..., -1.0419e+00,\n",
       "            9.1902e-01, -2.2437e-01],\n",
       "          ...,\n",
       "          [ 3.0418e+00,  3.6753e+00, -3.8150e+00,  ..., -1.6160e+00,\n",
       "            1.3080e+00,  6.6938e-01],\n",
       "          [ 4.2107e-01,  1.9556e+00, -2.4327e+00,  ...,  8.4049e-01,\n",
       "            4.2854e-01, -6.2167e-01],\n",
       "          [-1.7287e+00, -1.1436e+00, -2.6253e+00,  ..., -6.6951e-02,\n",
       "           -3.1206e-01, -2.6796e-01]],\n",
       "\n",
       "         [[-1.1223e-02, -2.1251e-02,  1.2524e-02,  ..., -4.6451e-01,\n",
       "            3.2714e-01,  2.1220e-01],\n",
       "          [ 1.1948e+00,  1.4490e+00,  1.4295e+00,  ..., -2.9588e+00,\n",
       "            1.9050e+00, -5.9886e-01],\n",
       "          [-5.4427e+00, -1.2174e+00,  2.5836e+00,  ..., -1.6991e+00,\n",
       "           -3.7884e-01, -7.2701e-01],\n",
       "          ...,\n",
       "          [ 2.8961e+00,  1.3785e+00, -1.7574e+00,  ...,  1.0842e-01,\n",
       "           -7.3918e-01,  2.5333e-01],\n",
       "          [ 1.6616e+00, -3.5930e-01, -1.8167e+00,  ..., -2.0986e+00,\n",
       "           -2.2821e+00, -6.0765e-01],\n",
       "          [ 2.9893e-01, -1.3461e-01, -7.0400e-01,  ..., -2.5463e+00,\n",
       "            1.0195e+00, -2.6727e+00]]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>), tensor([[[[ 3.6472e-04,  1.0110e-03, -1.9667e-04,  ...,  1.3076e-03,\n",
       "            4.8548e-04,  5.4444e-03],\n",
       "          [ 7.8602e-02,  4.1541e-02,  1.0500e-01,  ...,  3.0027e-02,\n",
       "           -1.7625e-01, -1.6383e-01],\n",
       "          [-2.2715e-01, -1.2884e-01, -5.0624e-02,  ...,  1.2941e-01,\n",
       "           -1.2625e-01, -1.5238e-01],\n",
       "          ...,\n",
       "          [ 1.4005e-01,  1.1521e-01, -4.1291e-01,  ...,  2.8599e-02,\n",
       "           -4.8184e-01,  7.5931e-02],\n",
       "          [-3.1607e-03, -6.5436e-02, -2.5230e-01,  ..., -2.1881e-01,\n",
       "           -1.6753e-01,  1.0587e-01],\n",
       "          [-9.0003e-04,  1.5788e-02, -3.4751e-02,  ..., -2.6518e-01,\n",
       "           -2.5165e-01,  2.2033e-02]],\n",
       "\n",
       "         [[-5.1726e-03,  1.5767e-02, -7.1275e-03,  ..., -9.3829e-03,\n",
       "           -2.5039e-03,  8.7367e-04],\n",
       "          [ 2.3539e-01,  2.5772e-01, -1.4046e-01,  ..., -1.8374e-01,\n",
       "            2.2347e-01, -5.9158e-02],\n",
       "          [-3.4720e-03, -7.5815e-02, -1.6191e-01,  ...,  1.1906e-01,\n",
       "            1.6179e-01,  6.3658e-02],\n",
       "          ...,\n",
       "          [-1.1835e-01, -5.8255e-02,  3.6617e-02,  ..., -1.3269e-01,\n",
       "           -1.4750e-01,  5.0856e-02],\n",
       "          [-1.5668e-01,  9.8982e-02,  1.4739e-02,  ..., -3.6432e-01,\n",
       "           -3.0201e-01, -2.7989e-01],\n",
       "          [-1.8127e-02, -1.3669e-01, -1.3310e-01,  ..., -2.6610e-01,\n",
       "           -1.9424e-01,  2.3390e-02]],\n",
       "\n",
       "         [[ 1.1322e-03,  1.6666e-03,  2.9928e-05,  ...,  4.1000e-04,\n",
       "            2.6996e-03,  5.9554e-02],\n",
       "          [-2.3999e-02, -9.5991e-02,  5.3169e-02,  ..., -1.8123e-01,\n",
       "           -5.3848e-02, -2.4097e-01],\n",
       "          [ 2.0565e-02,  9.9836e-02, -1.2309e-01,  ..., -4.5779e-02,\n",
       "            3.1665e-02, -3.6247e-01],\n",
       "          ...,\n",
       "          [ 2.0729e-02, -2.2871e-01, -3.4335e-02,  ..., -5.2349e-02,\n",
       "           -5.9443e-02, -7.3491e-01],\n",
       "          [ 8.6215e-02, -7.2408e-02,  1.0628e-01,  ..., -6.1033e-02,\n",
       "            9.4371e-02, -4.0531e-01],\n",
       "          [ 6.5992e-02, -3.3706e-02, -2.9118e-02,  ..., -1.2919e-01,\n",
       "            1.2117e-01,  2.7137e-02]],\n",
       "\n",
       "         [[-2.0449e-03,  6.1979e-03,  6.0320e-03,  ...,  1.9219e-03,\n",
       "           -5.7339e-03,  3.1039e-03],\n",
       "          [-4.3331e-01,  2.3078e-01, -1.6631e-01,  ..., -1.0389e-01,\n",
       "           -1.0070e-01,  2.1739e-01],\n",
       "          [ 2.6999e-01, -1.2825e-04, -1.4808e-01,  ..., -1.2032e-02,\n",
       "            2.1494e-01, -1.1990e-01],\n",
       "          ...,\n",
       "          [ 1.5686e-01,  3.8201e-01, -3.8576e-01,  ...,  3.0598e-01,\n",
       "            2.4559e-01, -2.2224e-01],\n",
       "          [ 3.6882e-02,  6.7337e-02, -1.9637e-01,  ...,  3.5058e-02,\n",
       "            1.8655e-01, -1.5228e-01],\n",
       "          [ 2.1480e-01,  1.7084e-01, -4.7904e-02,  ...,  1.2630e-02,\n",
       "            1.1952e-01, -1.1476e-01]]]], device='cuda:0',\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[-1.6864e-02, -3.2869e-02,  1.8557e-02,  ...,  9.0265e-01,\n",
       "           -1.4903e+00, -7.3819e-01],\n",
       "          [-7.7696e-01, -2.4182e+00, -4.1466e-01,  ..., -4.5532e-01,\n",
       "            3.1219e+00,  8.3586e-01],\n",
       "          [-4.4246e+00, -1.5691e+00, -1.0086e+00,  ...,  1.5407e-01,\n",
       "            2.2481e+00,  2.4541e+00],\n",
       "          ...,\n",
       "          [ 1.0213e+00, -2.3694e+00,  1.2155e+00,  ...,  3.5624e+00,\n",
       "            1.4895e+00,  2.3396e+00],\n",
       "          [-1.0389e-01, -3.9465e-01,  1.4442e+00,  ...,  2.0482e+00,\n",
       "            3.5908e+00,  3.1536e+00],\n",
       "          [-5.3948e-01,  6.8933e-01,  9.6770e-01,  ...,  1.1724e+00,\n",
       "            5.1041e+00,  3.3321e+00]],\n",
       "\n",
       "         [[-2.6228e-02,  1.9282e-02,  1.6998e-04,  ...,  3.4378e-01,\n",
       "           -1.7408e+00,  1.8836e-01],\n",
       "          [-2.2030e+00,  2.7726e+00,  2.7427e+00,  ..., -5.2497e-01,\n",
       "            2.9791e+00,  8.7837e-01],\n",
       "          [ 3.6660e+00, -3.1372e+00, -3.0395e-01,  ...,  8.7009e-01,\n",
       "            2.7885e+00,  2.5077e-01],\n",
       "          ...,\n",
       "          [-1.4005e+00,  1.9796e+00, -8.7838e-01,  ...,  2.0808e+00,\n",
       "            2.4525e+00, -7.8671e-01],\n",
       "          [-1.8003e+00,  1.4971e+00, -2.3366e+00,  ...,  7.9275e-01,\n",
       "            3.6852e+00,  1.7154e-01],\n",
       "          [-6.3411e-01, -4.9870e-01, -9.0679e-01,  ..., -1.2310e-01,\n",
       "            3.2076e+00, -7.1022e-01]],\n",
       "\n",
       "         [[ 6.9093e-03,  4.3373e-03, -2.3312e-02,  ...,  6.0312e-01,\n",
       "           -3.6481e-01,  5.6902e-01],\n",
       "          [ 2.1880e+00,  8.1408e-02,  1.2893e+00,  ..., -9.2210e-01,\n",
       "           -1.2065e+00, -2.8523e+00],\n",
       "          [-7.2178e-01, -2.0976e+00,  2.3324e+00,  ..., -1.1071e+00,\n",
       "            6.7496e-01, -3.6989e-01],\n",
       "          ...,\n",
       "          [ 8.4578e-01,  3.1619e-01, -2.8156e+00,  ..., -1.4282e+00,\n",
       "           -9.8188e-01, -7.6626e-01],\n",
       "          [ 1.1071e+00, -1.2799e+00, -1.2611e+00,  ..., -6.3983e-01,\n",
       "           -1.3861e-01, -1.4758e+00],\n",
       "          [ 4.3545e-01, -1.0649e+00, -9.4656e-01,  ..., -2.1464e+00,\n",
       "            3.8146e-01, -1.6796e+00]],\n",
       "\n",
       "         [[ 6.4876e-03, -8.2803e-03,  1.5174e-03,  ...,  5.7037e-01,\n",
       "            3.0311e-01, -8.5590e-02],\n",
       "          [-2.1543e+00,  2.6881e-01,  1.9358e+00,  ...,  1.7991e+00,\n",
       "           -1.4218e+00, -1.2651e+00],\n",
       "          [-1.1738e-01,  2.9025e+00,  5.5876e-01,  ...,  1.1355e+00,\n",
       "           -1.2397e+00, -1.4041e+00],\n",
       "          ...,\n",
       "          [-1.2388e+00,  1.7956e+00, -2.1830e+00,  ...,  1.2472e+00,\n",
       "           -1.7757e+00,  7.1834e-02],\n",
       "          [-1.8405e+00,  1.4955e+00,  1.3081e-01,  ...,  1.1431e+00,\n",
       "           -2.3734e+00, -7.1882e-01],\n",
       "          [-8.7074e-01,  1.7183e+00,  4.5932e-01,  ...,  1.4470e+00,\n",
       "           -2.5241e+00, -6.7894e-01]]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>), tensor([[[[-3.4101e-03, -7.7930e-03, -3.2110e-05,  ..., -2.2301e-03,\n",
       "            4.4538e-04,  8.3276e-03],\n",
       "          [ 1.5861e-01, -2.5699e-01,  9.2234e-02,  ...,  2.1275e-01,\n",
       "           -1.2943e-01,  3.9071e-02],\n",
       "          [ 2.3227e-01, -1.7612e-01, -1.7178e-01,  ...,  1.8133e-01,\n",
       "            1.0521e-02, -2.2172e-02],\n",
       "          ...,\n",
       "          [ 8.2984e-02, -2.3291e-01,  4.5114e-01,  ..., -1.3923e-01,\n",
       "            3.2884e-01, -2.9817e-01],\n",
       "          [-7.6171e-02, -2.5674e-01,  4.9265e-01,  ..., -2.1786e-01,\n",
       "            2.6547e-01, -2.3812e-01],\n",
       "          [-9.2353e-02, -3.7042e-01,  2.6653e-01,  ..., -6.4973e-02,\n",
       "            5.2903e-01, -2.8214e-01]],\n",
       "\n",
       "         [[-3.0944e-03, -5.7445e-04,  1.6152e-03,  ..., -4.9281e-03,\n",
       "           -4.3438e-03, -3.6362e-03],\n",
       "          [-9.3556e-02,  7.0472e-02, -1.4834e-02,  ...,  6.3496e-02,\n",
       "            4.3345e-03,  1.3262e-01],\n",
       "          [-9.1307e-02, -2.3373e-01,  1.2856e-01,  ...,  4.0529e-02,\n",
       "           -3.8538e-01,  5.7460e-02],\n",
       "          ...,\n",
       "          [ 8.5995e-02, -1.0244e-01, -1.1394e-01,  ...,  2.0363e-01,\n",
       "            4.4986e-02,  2.2635e-01],\n",
       "          [ 2.3675e-01,  3.7074e-02, -7.6698e-02,  ...,  9.9828e-02,\n",
       "           -2.7339e-01,  1.6168e-01],\n",
       "          [ 2.1990e-01,  1.0659e-02,  4.9079e-02,  ...,  6.7503e-02,\n",
       "           -2.5556e-01,  1.4153e-01]],\n",
       "\n",
       "         [[-8.6951e-03,  1.1083e-02, -5.7363e-03,  ..., -2.4420e-03,\n",
       "            6.0868e-03, -2.7929e-03],\n",
       "          [ 1.4850e-01,  1.0327e-01,  1.2068e-03,  ..., -6.4040e-02,\n",
       "            5.9690e-02, -1.4751e-01],\n",
       "          [ 1.0240e-01, -1.9712e-02, -1.9822e-01,  ..., -1.8250e-01,\n",
       "            1.0221e-01,  1.3045e-02],\n",
       "          ...,\n",
       "          [-1.0215e-01, -2.8686e-02, -9.0704e-02,  ..., -2.1545e-01,\n",
       "           -8.1919e-02,  9.1904e-02],\n",
       "          [-1.2184e-01, -2.3699e-01,  4.9109e-02,  ..., -2.2992e-01,\n",
       "           -1.0349e-01,  3.1906e-01],\n",
       "          [-3.5266e-01, -1.3445e-01, -1.1948e-02,  ...,  5.3638e-02,\n",
       "           -2.2163e-01,  2.7083e-01]],\n",
       "\n",
       "         [[-4.0674e-04, -2.8978e-03,  2.2426e-03,  ...,  1.1773e-02,\n",
       "           -3.8058e-03,  8.5992e-04],\n",
       "          [-5.2767e-02, -1.6919e-01,  8.2018e-02,  ...,  1.1644e-01,\n",
       "            4.4692e-03,  8.7001e-02],\n",
       "          [ 3.9447e-03, -2.3344e-02,  1.1094e-01,  ...,  2.6116e-02,\n",
       "            6.7785e-03,  3.7870e-02],\n",
       "          ...,\n",
       "          [-1.5721e-01,  1.3862e-01,  6.7686e-03,  ...,  1.3846e-01,\n",
       "           -1.7257e-01,  6.2901e-02],\n",
       "          [-2.8346e-01,  3.0473e-01, -2.9352e-01,  ...,  4.4644e-01,\n",
       "           -3.2553e-01,  1.4320e-01],\n",
       "          [-1.5056e-01,  3.5872e-02, -3.0698e-01,  ...,  5.1945e-02,\n",
       "           -3.8756e-01,  1.2624e-01]]]], device='cuda:0',\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[ 8.2276e-03,  2.8788e-03,  2.6830e-02,  ..., -3.4262e-01,\n",
       "           -4.1794e-01,  1.5350e-01],\n",
       "          [-6.8788e-01, -1.4129e-01,  9.0685e-02,  ...,  2.2258e-01,\n",
       "            2.0391e+00,  6.4104e-01],\n",
       "          [ 1.3454e-01,  3.4264e-01, -1.0051e+00,  ...,  1.5415e+00,\n",
       "            1.8430e+00, -2.2619e-01],\n",
       "          ...,\n",
       "          [-9.6263e-01,  1.4441e+00,  4.9434e-01,  ...,  1.4632e+00,\n",
       "            1.6764e+00, -2.2850e+00],\n",
       "          [ 1.5429e-01, -3.5613e-01,  5.0508e-01,  ...,  2.5578e+00,\n",
       "            1.4291e+00, -5.4979e-01],\n",
       "          [ 1.0988e-01, -5.8391e-02,  3.5228e-01,  ...,  2.3082e+00,\n",
       "            1.8251e+00,  6.3283e-02]],\n",
       "\n",
       "         [[-1.4450e-02, -4.6735e-03,  2.4771e-02,  ..., -2.5115e-01,\n",
       "           -2.0870e+00,  1.8843e+00],\n",
       "          [-8.8865e-01, -8.4516e-01, -7.5532e-01,  ...,  1.2919e+00,\n",
       "            5.6098e+00, -5.4489e+00],\n",
       "          [-1.4769e+00,  7.2119e-01, -1.0686e+00,  ..., -1.2112e+00,\n",
       "            6.5148e+00, -8.1200e+00],\n",
       "          ...,\n",
       "          [ 1.2136e+00, -8.5323e-01,  1.4231e+00,  ...,  2.5606e+00,\n",
       "            5.2753e+00, -7.6938e+00],\n",
       "          [ 1.5609e-01,  1.8086e-03,  9.2606e-01,  ...,  4.6388e+00,\n",
       "            6.2348e+00, -5.8952e+00],\n",
       "          [-4.2902e-01,  5.1917e-01,  5.1880e-01,  ...,  2.9444e+00,\n",
       "            6.3090e+00, -4.0583e+00]],\n",
       "\n",
       "         [[-5.8898e-03,  2.6315e-02, -3.3771e-03,  ..., -1.2671e-01,\n",
       "           -7.5977e-01, -3.2178e+00],\n",
       "          [ 3.7438e+00,  1.3255e+00,  1.3216e+00,  ..., -1.1935e+00,\n",
       "            1.2969e+00,  3.5511e+00],\n",
       "          [ 1.9635e+00,  3.0003e+00,  1.1384e+00,  ..., -1.4170e-01,\n",
       "            3.0579e+00,  3.5305e+00],\n",
       "          ...,\n",
       "          [-7.0599e-01,  1.0728e+00,  3.8013e-01,  ..., -1.4531e+00,\n",
       "            3.2523e+00,  4.0996e+00],\n",
       "          [ 1.1471e+00,  9.0250e-01, -8.1061e-01,  ...,  4.9580e-01,\n",
       "            4.4174e+00,  5.5891e+00],\n",
       "          [ 6.0837e-01,  6.3492e-01, -6.3451e-01,  ...,  2.0475e-01,\n",
       "            3.2169e+00,  5.2595e+00]],\n",
       "\n",
       "         [[ 1.8119e-02, -1.2156e-02,  5.7448e-02,  ...,  4.6990e-01,\n",
       "            1.8006e+00, -2.4369e-01],\n",
       "          [-1.9662e+00, -2.8105e-01, -1.4643e-01,  ..., -8.8357e-01,\n",
       "           -3.1941e+00, -5.8705e-01],\n",
       "          [-5.9172e+00, -2.3645e+00, -2.2940e+00,  ..., -3.3424e-01,\n",
       "           -4.9878e+00, -2.4790e-01],\n",
       "          ...,\n",
       "          [ 4.2543e+00,  4.7111e-01,  2.7526e+00,  ..., -9.9880e-01,\n",
       "           -1.8314e+00, -5.2409e-01],\n",
       "          [ 1.2386e-01, -1.7276e+00, -4.2698e-02,  ..., -1.5416e+00,\n",
       "           -1.3643e+00, -1.1208e-02],\n",
       "          [-1.7356e+00, -3.2067e+00, -2.6997e-01,  ..., -1.3708e+00,\n",
       "           -1.8899e+00,  3.9954e-02]]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>), tensor([[[[ 1.2273e-02,  5.8736e-03,  3.4521e-03,  ..., -2.6093e-03,\n",
       "           -1.9191e-03,  1.2748e-03],\n",
       "          [ 3.5289e-01,  1.6684e-01, -1.5692e-02,  ...,  2.3534e-01,\n",
       "            1.4010e-01,  3.9122e-02],\n",
       "          [ 3.5972e-01, -2.4114e-01,  1.1757e-01,  ..., -2.9446e-02,\n",
       "            4.3687e-01, -1.1518e-01],\n",
       "          ...,\n",
       "          [-2.3294e-02,  2.6851e-01,  1.8015e-02,  ...,  1.0221e-01,\n",
       "           -1.0491e-01,  2.1011e-01],\n",
       "          [ 1.2876e-01,  1.4317e-02, -5.0129e-01,  ..., -8.5491e-02,\n",
       "            5.3838e-01,  2.3302e-01],\n",
       "          [ 4.0434e-01, -1.0776e-01, -2.8309e-01,  ..., -2.6678e-01,\n",
       "            5.2713e-02, -1.7151e-01]],\n",
       "\n",
       "         [[ 4.1235e-03,  1.7171e-02,  4.8440e-03,  ...,  5.7918e-04,\n",
       "            2.3993e-03, -3.1752e-04],\n",
       "          [ 9.4866e-02, -4.4692e-01,  1.2745e-01,  ...,  9.3836e-02,\n",
       "           -6.4369e-02,  5.2149e-02],\n",
       "          [ 2.7739e-01, -2.5820e-01, -4.1647e-02,  ..., -7.5209e-04,\n",
       "           -8.9541e-02,  1.9012e-01],\n",
       "          ...,\n",
       "          [ 4.1410e-01, -1.1001e-01, -3.2920e-01,  ...,  2.6198e-02,\n",
       "           -8.2444e-02,  7.0030e-02],\n",
       "          [ 4.2145e-01, -1.0084e-01, -3.4798e-01,  ..., -6.2561e-02,\n",
       "            1.6689e-01,  2.4451e-01],\n",
       "          [ 3.0987e-01, -9.3595e-02, -1.2039e-01,  ..., -3.3961e-02,\n",
       "            1.0660e-02,  2.0815e-01]],\n",
       "\n",
       "         [[ 2.7460e-03, -3.3183e-03,  5.1721e-03,  ...,  2.2862e-03,\n",
       "           -7.3146e-05,  4.6565e-04],\n",
       "          [-1.9927e-01, -7.8724e-02, -6.5294e-02,  ..., -1.5178e-02,\n",
       "            3.9020e-02,  3.1183e-03],\n",
       "          [-1.7581e-01, -7.8490e-02,  3.2765e-01,  ..., -1.9325e-02,\n",
       "           -1.1484e-02,  1.3337e-01],\n",
       "          ...,\n",
       "          [ 2.3402e-02,  1.3551e-01, -1.2214e-01,  ...,  1.0400e-01,\n",
       "            4.3186e-02,  5.7598e-02],\n",
       "          [-1.0212e-01,  7.5327e-02,  4.3516e-02,  ..., -9.9592e-03,\n",
       "           -1.4405e-01,  9.3815e-02],\n",
       "          [ 1.1498e-01,  1.1325e-01, -1.9188e-01,  ...,  8.6734e-02,\n",
       "            6.9101e-02,  5.7165e-02]],\n",
       "\n",
       "         [[ 2.7084e-03, -1.7053e-03, -2.3805e-03,  ...,  1.1866e-02,\n",
       "            2.6716e-03,  1.8889e-03],\n",
       "          [-4.2580e-02, -3.4971e-02, -1.5167e-01,  ..., -2.1880e-01,\n",
       "            2.3624e-01,  1.7103e-02],\n",
       "          [ 9.5953e-03,  1.1530e-01, -2.9616e-02,  ..., -4.7248e-03,\n",
       "            1.9734e-01, -3.6662e-01],\n",
       "          ...,\n",
       "          [-4.8610e-01,  2.1616e-01, -1.5494e-02,  ..., -1.2460e-01,\n",
       "            6.7164e-02, -4.2579e-01],\n",
       "          [ 6.2049e-03,  3.1394e-01,  1.4110e-01,  ...,  4.7658e-03,\n",
       "            3.3298e-01, -6.9998e-01],\n",
       "          [-2.0038e-01,  9.7828e-02,  5.4624e-02,  ...,  3.9551e-02,\n",
       "            3.5042e-01, -7.7754e-01]]]], device='cuda:0',\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[ 1.9760e-02,  8.9818e-03,  1.8771e-02,  ...,  1.6675e+00,\n",
       "            1.7136e+00,  2.4885e-01],\n",
       "          [-2.1582e+00,  6.8668e-01,  5.2071e-01,  ..., -2.1064e-01,\n",
       "           -2.1790e+00, -3.6620e-01],\n",
       "          [-2.4105e+00,  1.4774e+00,  1.7826e+00,  ..., -7.9158e-01,\n",
       "           -2.8134e+00,  1.0094e+00],\n",
       "          ...,\n",
       "          [ 1.0101e+00,  7.2270e-01, -1.5570e+00,  ..., -1.4955e-01,\n",
       "           -4.2591e+00,  6.5281e-01],\n",
       "          [-5.1725e-01,  7.3192e-01, -5.0069e-01,  ..., -8.7301e-01,\n",
       "           -6.6138e+00,  2.1315e-01],\n",
       "          [-6.5772e-01,  1.0503e+00,  4.4551e-01,  ..., -1.3196e+00,\n",
       "           -4.6068e+00, -1.2644e+00]],\n",
       "\n",
       "         [[ 2.4594e-03,  1.9607e-02,  1.2012e-02,  ..., -6.9696e-01,\n",
       "            2.0438e+00,  1.7022e+00],\n",
       "          [-1.7343e+00,  1.5623e-01,  1.7127e+00,  ...,  3.5659e+00,\n",
       "           -4.9650e+00, -1.3273e+00],\n",
       "          [-1.3027e+00,  6.7295e-01,  1.8463e+00,  ...,  6.5902e-01,\n",
       "           -5.1888e+00, -1.3801e+00],\n",
       "          ...,\n",
       "          [ 3.4854e-01,  1.2439e+00, -1.7495e+00,  ...,  1.9546e+00,\n",
       "           -5.4710e+00, -4.1831e+00],\n",
       "          [-1.0911e+00, -1.4112e+00, -9.3560e-01,  ...,  4.0795e+00,\n",
       "           -7.6411e+00, -4.5139e+00],\n",
       "          [-1.3614e+00, -1.2234e+00, -1.1394e+00,  ...,  3.5154e+00,\n",
       "           -5.7473e+00, -5.5908e+00]],\n",
       "\n",
       "         [[ 2.1753e-03, -6.0279e-04,  2.0143e-03,  ..., -3.9379e-01,\n",
       "            2.2144e-01, -1.0678e+00],\n",
       "          [ 2.5928e+00,  9.3505e-01,  3.0477e+00,  ...,  9.8698e-01,\n",
       "            2.3726e+00,  2.1376e-01],\n",
       "          [ 3.6227e+00, -4.7902e-01,  3.6474e-01,  ...,  1.2907e+00,\n",
       "            1.2920e+00,  7.2588e-01],\n",
       "          ...,\n",
       "          [-2.1063e+00, -1.2188e-01, -1.5095e+00,  ..., -2.2828e-01,\n",
       "            1.0328e+00, -1.3205e+00],\n",
       "          [-3.6931e-01, -1.3923e+00, -1.1961e+00,  ...,  5.7802e-01,\n",
       "            2.6929e-01, -2.2957e+00],\n",
       "          [ 9.7563e-01, -1.5872e+00, -4.9086e-01,  ...,  1.1142e-01,\n",
       "            3.7160e-01, -2.0480e+00]],\n",
       "\n",
       "         [[-2.6217e-02, -2.7159e-03, -1.3319e-02,  ..., -1.9442e+00,\n",
       "            3.5028e-01,  1.6185e+00],\n",
       "          [ 3.4319e-01, -7.7248e-01, -6.1578e-01,  ...,  1.1063e+00,\n",
       "            4.8934e-01,  4.0530e-01],\n",
       "          [-1.0778e+00,  3.9363e-01, -8.9630e-01,  ...,  2.7008e+00,\n",
       "           -1.0240e-01,  7.5109e-02],\n",
       "          ...,\n",
       "          [ 7.5614e-01, -6.8347e-01,  1.8743e-03,  ...,  3.2387e+00,\n",
       "           -6.2973e-01, -4.4108e-01],\n",
       "          [ 8.4433e-02,  4.0753e-01,  4.5427e-01,  ...,  2.6876e+00,\n",
       "           -1.4544e+00, -1.9256e+00],\n",
       "          [ 7.0190e-01,  9.0507e-01, -5.6589e-01,  ...,  1.8322e+00,\n",
       "           -1.0462e+00, -2.3067e+00]]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>), tensor([[[[ 1.3822e-03, -3.7972e-04, -1.0364e-04,  ..., -2.6939e-03,\n",
       "            3.1675e-03, -2.8682e-04],\n",
       "          [-3.5674e-01, -3.0288e-01,  5.7052e-01,  ..., -1.9982e-01,\n",
       "            7.8614e-02, -3.4382e-02],\n",
       "          [-1.7037e-01, -1.1894e-01,  5.3493e-02,  ..., -4.2897e-02,\n",
       "            2.9449e-01, -1.6857e-02],\n",
       "          ...,\n",
       "          [-2.8617e-01, -5.6684e-03, -1.7410e-01,  ..., -9.9251e-02,\n",
       "            1.9679e-01, -1.0737e-01],\n",
       "          [-2.1360e-01, -9.7154e-02, -4.6677e-01,  ..., -7.3302e-02,\n",
       "            1.5559e-01, -1.5306e-01],\n",
       "          [ 2.2144e-01, -1.4296e-01, -1.3036e-01,  ...,  1.5158e-01,\n",
       "            1.1841e-01, -8.7985e-02]],\n",
       "\n",
       "         [[ 9.2512e-03, -8.4352e-03, -9.2688e-03,  ...,  9.4593e-03,\n",
       "           -1.1846e-02,  6.9612e-03],\n",
       "          [-9.6441e-02,  1.0610e-01, -1.9164e-02,  ...,  2.0137e-01,\n",
       "            1.4479e-01,  3.1938e-02],\n",
       "          [-5.1476e-02,  1.4453e-01, -3.5685e-01,  ...,  9.2008e-03,\n",
       "           -8.9094e-02,  6.4186e-02],\n",
       "          ...,\n",
       "          [ 1.9850e-02, -2.3661e-01,  3.6698e-02,  ...,  5.4275e-03,\n",
       "            1.9082e-02,  1.9807e-01],\n",
       "          [ 1.7575e-01, -3.6326e-01,  1.3807e-01,  ..., -4.8319e-02,\n",
       "            2.9668e-02,  2.1911e-01],\n",
       "          [ 2.4007e-01, -3.2186e-01,  6.3031e-02,  ..., -3.5698e-02,\n",
       "            5.5934e-02, -5.8280e-02]],\n",
       "\n",
       "         [[ 2.9463e-04,  6.3844e-03,  4.7478e-03,  ...,  6.3309e-03,\n",
       "           -3.8343e-03,  8.2211e-03],\n",
       "          [ 1.7504e-01, -1.3093e-01,  8.6409e-02,  ..., -3.1241e-02,\n",
       "           -1.4204e-01, -1.6396e-01],\n",
       "          [ 1.6487e-01, -1.2572e-01,  4.4770e-03,  ...,  7.0446e-02,\n",
       "           -2.6702e-03,  6.2278e-02],\n",
       "          ...,\n",
       "          [-1.5108e-01, -2.1874e-02,  1.3325e-01,  ...,  2.6116e-01,\n",
       "            1.8201e-01, -1.0108e-01],\n",
       "          [ 1.3202e-02,  6.6121e-02,  2.2073e-02,  ...,  1.5170e-01,\n",
       "            1.1795e-01, -7.1828e-02],\n",
       "          [-2.1270e-01, -2.7046e-01,  4.0113e-02,  ...,  2.2520e-01,\n",
       "            1.9307e-01,  2.7646e-02]],\n",
       "\n",
       "         [[-1.5483e-02,  2.6247e-03,  3.0424e-02,  ..., -6.4211e-03,\n",
       "           -1.1470e-02, -6.1948e-04],\n",
       "          [ 2.5106e-01, -4.0943e-01,  3.6683e-01,  ...,  2.3751e-01,\n",
       "           -3.1517e-01, -1.3431e-02],\n",
       "          [ 1.9812e-01,  7.6198e-02,  1.9626e-01,  ..., -3.3990e-02,\n",
       "           -3.0928e-01,  9.5415e-03],\n",
       "          ...,\n",
       "          [-2.6433e-02,  9.0638e-02, -7.1192e-01,  ...,  1.9086e-01,\n",
       "           -2.2587e-01, -3.9553e-01],\n",
       "          [-8.4463e-02, -1.2135e-01, -2.6542e-01,  ..., -1.5595e-01,\n",
       "           -2.5687e-01, -1.4538e-01],\n",
       "          [-2.3957e-01, -2.6014e-01, -2.3914e-01,  ..., -1.5671e-01,\n",
       "           -1.4081e-01, -3.1412e-01]]]], device='cuda:0',\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[-2.4244e-02,  7.5434e-03, -5.9986e-03,  ...,  1.4506e-01,\n",
       "            4.6774e-01,  2.1983e-01],\n",
       "          [ 2.5430e+00, -1.0395e+00,  1.9169e+00,  ...,  3.1893e-01,\n",
       "            1.8066e+00,  1.0095e+00],\n",
       "          [-4.2973e+00, -1.7639e+00, -1.1466e+00,  ...,  6.6061e-02,\n",
       "            1.4350e+00,  1.8276e+00],\n",
       "          ...,\n",
       "          [ 3.0420e+00, -1.8519e+00, -7.3017e-01,  ...,  3.3712e-01,\n",
       "            7.7721e-01,  2.8141e+00],\n",
       "          [ 2.8052e+00, -3.1032e+00, -6.9886e-01,  ..., -9.2742e-01,\n",
       "            1.3800e+00,  5.1919e-01],\n",
       "          [ 1.9831e+00, -1.4597e+00, -9.0968e-01,  ..., -5.2148e-01,\n",
       "            1.0654e+00,  9.8789e-01]],\n",
       "\n",
       "         [[ 3.2410e-03, -1.2071e-02, -6.1924e-03,  ..., -1.4722e+00,\n",
       "           -7.0846e-01, -5.8729e-01],\n",
       "          [ 1.1142e+00,  2.9003e-01,  1.2339e+00,  ...,  3.3383e+00,\n",
       "            2.1009e+00, -9.5505e-01],\n",
       "          [-1.2298e-01,  1.9432e+00,  9.7791e-01,  ...,  2.6904e+00,\n",
       "            1.7459e+00,  3.1838e-01],\n",
       "          ...,\n",
       "          [-1.2805e-02,  6.7832e-01, -1.7143e+00,  ...,  2.8731e+00,\n",
       "            1.8654e+00,  1.7426e+00],\n",
       "          [ 8.7992e-01, -1.4858e-01, -9.2185e-01,  ...,  4.9444e+00,\n",
       "            9.5457e-01,  1.1251e+00],\n",
       "          [-2.1119e-01,  7.1747e-01, -2.1419e-01,  ...,  5.5513e+00,\n",
       "           -9.7352e-01, -4.7374e-01]],\n",
       "\n",
       "         [[ 1.3741e-02,  2.4220e-02,  2.4893e-02,  ..., -4.6227e-01,\n",
       "            1.9305e+00, -1.3661e+00],\n",
       "          [-3.6108e-01, -9.6928e-01,  1.7017e-01,  ...,  7.1395e-01,\n",
       "           -4.7296e-01, -1.7865e+00],\n",
       "          [-1.5764e+00, -1.9461e+00, -1.7465e-01,  ...,  2.5887e+00,\n",
       "           -8.0534e-01,  1.3223e+00],\n",
       "          ...,\n",
       "          [ 6.1880e-01, -6.7158e-01,  6.5232e-01,  ...,  4.9463e+00,\n",
       "           -3.8252e-01, -9.7759e-01],\n",
       "          [-1.2184e+00,  2.5591e-01, -8.1105e-01,  ...,  4.9860e+00,\n",
       "           -1.9121e+00, -1.0479e+00],\n",
       "          [-5.6087e-01, -2.7684e-01, -7.5554e-01,  ...,  5.0335e+00,\n",
       "           -3.0770e+00, -7.2800e-01]],\n",
       "\n",
       "         [[-1.8215e-02,  1.2055e-02, -1.6402e-02,  ...,  2.0157e-01,\n",
       "           -1.7814e+00, -1.6634e+00],\n",
       "          [ 6.5243e-01,  6.6774e-01,  6.7929e-01,  ...,  1.7299e+00,\n",
       "            2.6332e+00,  2.6958e+00],\n",
       "          [-2.7268e-01, -9.0824e-01,  1.2318e-01,  ...,  1.1830e-01,\n",
       "            2.3653e+00,  3.0486e+00],\n",
       "          ...,\n",
       "          [ 5.7904e-01, -1.3467e-01, -2.4560e-01,  ...,  1.1930e+00,\n",
       "            3.4705e+00,  4.8237e+00],\n",
       "          [ 2.1453e-01, -5.7631e-01,  3.8463e-01,  ...,  1.9945e+00,\n",
       "            5.3126e+00,  7.0408e+00],\n",
       "          [-5.7019e-03, -1.6778e-01,  7.8608e-02,  ...,  2.9871e+00,\n",
       "            3.4148e+00,  6.1006e+00]]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>), tensor([[[[-1.0127e-02, -4.5965e-02, -9.9388e-03,  ..., -1.3184e-01,\n",
       "           -7.9690e-04, -8.5444e-04],\n",
       "          [ 3.8075e-01,  1.8747e-01, -3.5885e-02,  ...,  9.0982e-02,\n",
       "           -1.8108e-01, -7.0468e-02],\n",
       "          [-2.1870e-01,  4.6313e-01,  2.0578e-01,  ...,  7.7999e-02,\n",
       "           -1.7064e-01,  6.8935e-02],\n",
       "          ...,\n",
       "          [ 9.2875e-02,  4.9769e-01,  1.0438e-01,  ..., -3.5267e-01,\n",
       "           -7.3295e-02, -2.6942e-01],\n",
       "          [ 4.1470e-01,  4.2634e-02, -1.3787e-02,  ..., -2.7312e-01,\n",
       "           -1.6880e-01, -5.7914e-02],\n",
       "          [ 2.7266e-01, -1.4170e-01,  2.0150e-01,  ..., -1.2178e-01,\n",
       "            1.5837e-01,  1.3562e-01]],\n",
       "\n",
       "         [[-1.7488e-03,  7.9335e-03,  2.0062e-02,  ...,  1.4732e-03,\n",
       "           -3.3790e-04,  1.5026e-02],\n",
       "          [ 1.4859e-01,  1.8537e-01,  9.5338e-02,  ...,  1.6590e-01,\n",
       "            1.1735e-01, -1.6814e-01],\n",
       "          [-1.0058e-01,  1.0257e-01, -1.1714e-01,  ...,  9.1002e-02,\n",
       "            6.2236e-02, -4.2052e-02],\n",
       "          ...,\n",
       "          [ 1.6228e-01, -7.7594e-02, -3.8675e-01,  ...,  2.4504e-02,\n",
       "            1.6433e-02,  1.2384e-01],\n",
       "          [ 2.6144e-01,  1.0265e-01, -2.5721e-01,  ..., -9.3016e-02,\n",
       "            1.3841e-01,  9.2624e-02],\n",
       "          [ 3.1717e-01,  5.0752e-02, -4.4879e-01,  ..., -2.1202e-01,\n",
       "            2.9570e-01,  1.2624e-01]],\n",
       "\n",
       "         [[-1.5439e-03, -9.5626e-03,  1.1582e-02,  ...,  2.6206e-03,\n",
       "            1.7267e-02, -3.4969e-03],\n",
       "          [ 1.7942e-01,  2.8641e-02, -2.5680e-02,  ...,  4.9348e-02,\n",
       "           -1.6526e-01,  1.4150e-02],\n",
       "          [-1.5010e-01, -9.1414e-03,  9.5680e-02,  ...,  1.0122e-01,\n",
       "           -6.9176e-02,  1.0326e-01],\n",
       "          ...,\n",
       "          [ 2.1668e-01,  2.5576e-01, -6.0409e-01,  ...,  1.6411e-01,\n",
       "           -4.7750e-01, -2.1476e-01],\n",
       "          [ 2.8752e-01,  1.0111e-01, -1.1370e-01,  ...,  1.8672e-01,\n",
       "           -2.7949e-01, -1.0309e-03],\n",
       "          [ 1.2227e-01,  1.6259e-01, -1.2648e-01,  ...,  3.4384e-01,\n",
       "           -4.6421e-01, -1.1896e-01]],\n",
       "\n",
       "         [[-2.8204e-03,  2.6512e-03,  5.4369e-05,  ..., -8.9912e-04,\n",
       "            7.5715e-03,  1.0273e-02],\n",
       "          [-2.4403e-01, -6.1421e-03, -6.1184e-02,  ...,  3.9792e-02,\n",
       "           -1.3401e-02,  8.9866e-02],\n",
       "          [-1.0323e-02,  2.2815e-02, -1.2795e-03,  ...,  2.2154e-01,\n",
       "           -1.4802e-01, -1.9425e-01],\n",
       "          ...,\n",
       "          [ 3.0160e-01, -1.0820e-01, -1.1369e-01,  ..., -5.1971e-01,\n",
       "           -3.2842e-01, -1.2276e-01],\n",
       "          [-4.6679e-02, -3.4554e-02, -2.1521e-01,  ..., -1.8536e-01,\n",
       "           -4.5755e-02, -2.2902e-01],\n",
       "          [ 4.3727e-02, -4.2651e-02, -2.9310e-01,  ...,  1.8037e-02,\n",
       "           -2.1813e-01, -1.9543e-01]]]], device='cuda:0',\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[-1.5235e-02, -7.5493e-03,  1.0627e-02,  ..., -1.6749e-02,\n",
       "           -1.7463e+00, -1.4105e+00],\n",
       "          [ 1.1895e+00, -1.1437e+00, -6.6119e-01,  ...,  5.9008e-01,\n",
       "            1.7640e+00,  1.2634e+00],\n",
       "          [ 2.0720e+00,  7.6071e-01, -1.1384e+00,  ..., -1.1637e+00,\n",
       "            2.0959e+00,  2.4145e+00],\n",
       "          ...,\n",
       "          [-1.1926e-01,  1.2906e-01,  8.1815e-01,  ..., -5.5878e-01,\n",
       "            7.7476e+00, -2.4133e-01],\n",
       "          [ 8.7652e-01,  2.6068e-01,  1.4881e+00,  ..., -1.2498e+00,\n",
       "            8.7281e+00,  3.4888e-01],\n",
       "          [ 1.6998e+00,  9.7382e-01, -1.0274e-01,  ..., -6.5642e-01,\n",
       "            8.1108e+00, -3.5335e-01]],\n",
       "\n",
       "         [[ 8.2748e-03,  6.7602e-03, -7.6111e-03,  ..., -3.4542e-01,\n",
       "           -1.4159e+00,  3.0554e+00],\n",
       "          [-7.9961e-02,  5.7135e-01,  6.4611e-01,  ..., -4.3269e-01,\n",
       "            3.8026e+00, -3.6969e+00],\n",
       "          [ 7.8444e-01,  1.1560e+00,  9.0869e-01,  ...,  1.6987e+00,\n",
       "            3.5650e+00, -5.5725e+00],\n",
       "          ...,\n",
       "          [-6.8402e-01,  9.8305e-01, -8.2874e-01,  ..., -5.0648e-01,\n",
       "            6.2727e+00, -5.2170e+00],\n",
       "          [-7.9107e-01,  1.0073e+00, -1.1879e+00,  ...,  5.4237e-01,\n",
       "            6.2464e+00, -7.3403e+00],\n",
       "          [ 1.8101e-01,  7.5465e-01, -1.0591e+00,  ...,  2.0878e+00,\n",
       "            5.7053e+00, -7.8972e+00]],\n",
       "\n",
       "         [[-1.5576e-02, -3.0237e-03,  9.2165e-03,  ..., -1.5188e-02,\n",
       "           -3.6476e-01, -7.6420e-01],\n",
       "          [ 3.2347e+00, -5.0393e-01, -1.9593e+00,  ...,  6.2837e-01,\n",
       "           -8.7864e-01,  1.0362e+00],\n",
       "          [ 2.6572e+00, -9.9960e-01, -2.6587e+00,  ...,  1.4666e+00,\n",
       "           -1.1295e+00,  1.1265e+00],\n",
       "          ...,\n",
       "          [-1.4747e+00,  7.9823e-02,  2.2811e+00,  ...,  2.8785e+00,\n",
       "           -1.0300e+00,  1.3716e+00],\n",
       "          [ 7.0801e-01, -1.2445e+00,  1.9082e+00,  ...,  3.1111e+00,\n",
       "           -2.2047e-01,  1.5371e+00],\n",
       "          [ 2.0424e+00, -3.0371e+00,  1.1094e+00,  ...,  3.3085e+00,\n",
       "           -2.3593e-01,  1.4142e+00]],\n",
       "\n",
       "         [[ 4.5729e-03,  1.2481e-02, -1.4983e-02,  ..., -7.5039e-01,\n",
       "            4.4361e-01, -3.4080e-02],\n",
       "          [-4.0481e+00,  2.3356e+00,  2.0529e+00,  ...,  1.9195e+00,\n",
       "           -3.1048e+00, -8.2158e-02],\n",
       "          [-5.6379e+00,  3.2889e+00, -5.1399e-01,  ...,  3.3814e-01,\n",
       "           -3.0513e+00, -7.7335e-01],\n",
       "          ...,\n",
       "          [ 5.3483e+00,  3.3110e+00, -1.4479e+00,  ...,  2.0412e-01,\n",
       "           -4.4016e+00,  9.7456e-01],\n",
       "          [ 1.3379e+00,  2.4162e+00, -1.5309e-01,  ...,  3.2676e+00,\n",
       "           -4.0416e+00, -2.5620e-01],\n",
       "          [-3.6193e+00,  1.0110e+00, -1.5216e-01,  ...,  3.4764e+00,\n",
       "           -4.0589e+00,  4.9394e-01]]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>), tensor([[[[ 4.2113e-03, -1.0629e-02, -1.4760e-03,  ..., -1.4987e-04,\n",
       "            2.1954e-03, -4.6770e-03],\n",
       "          [-1.8195e-01, -1.8326e-02,  2.4277e-02,  ...,  2.6375e-01,\n",
       "            8.5669e-02, -2.3297e-02],\n",
       "          [ 1.8179e-01, -1.0294e-01,  3.0934e-02,  ..., -1.2932e-01,\n",
       "            3.4430e-01, -2.9944e-02],\n",
       "          ...,\n",
       "          [ 1.0684e-01, -2.3682e-01,  2.1688e-01,  ...,  2.4788e-01,\n",
       "           -3.6685e-02,  3.8936e-02],\n",
       "          [ 8.0035e-02, -2.5557e-01,  1.9653e-01,  ...,  1.1357e-01,\n",
       "           -2.3108e-01,  2.9097e-01],\n",
       "          [ 7.2134e-02, -1.4648e-01,  1.7494e-01,  ..., -8.0497e-03,\n",
       "           -1.3562e-01,  2.7772e-01]],\n",
       "\n",
       "         [[ 2.7362e-03,  2.0854e-03, -8.0592e-03,  ..., -7.2357e-03,\n",
       "            5.1652e-04,  6.2994e-04],\n",
       "          [ 1.0082e-01, -1.7137e-01, -4.4758e-02,  ...,  1.3046e-02,\n",
       "            7.6975e-02,  4.0956e-02],\n",
       "          [-2.7848e-01, -3.6025e-01, -1.0068e-01,  ...,  1.1119e-01,\n",
       "            1.7873e-01,  1.6771e-01],\n",
       "          ...,\n",
       "          [-2.3008e-01, -7.9559e-02, -6.2802e-02,  ..., -4.7219e-02,\n",
       "           -9.1654e-03, -1.7161e-01],\n",
       "          [-1.1632e-01,  3.9744e-02, -1.4955e-01,  ..., -8.5695e-02,\n",
       "           -5.2202e-02, -1.1884e-01],\n",
       "          [ 7.1164e-02, -3.4277e-02,  6.4943e-02,  ...,  1.4164e-01,\n",
       "            1.2666e-01,  2.9799e-02]],\n",
       "\n",
       "         [[ 2.2037e-01, -2.9853e-02, -2.7741e-02,  ..., -7.7192e-03,\n",
       "            1.3908e-02,  3.2888e-03],\n",
       "          [-7.9068e-02, -5.8127e-02,  1.1607e-01,  ..., -5.7254e-02,\n",
       "            2.8291e-01,  2.2165e-01],\n",
       "          [-3.7118e-02,  8.1546e-02,  2.7304e-02,  ...,  1.4354e-01,\n",
       "            1.5631e-01,  1.0086e-01],\n",
       "          ...,\n",
       "          [-3.2114e-01,  4.2841e-02,  2.5715e-01,  ...,  2.3694e-01,\n",
       "            4.5266e-02,  1.4004e-02],\n",
       "          [-3.8391e-01,  1.1793e-02,  1.8824e-01,  ...,  9.1873e-03,\n",
       "           -3.9794e-02, -2.3292e-01],\n",
       "          [-6.0289e-01, -5.7252e-02,  7.7532e-02,  ...,  1.3510e-01,\n",
       "           -6.3145e-02, -7.6394e-02]],\n",
       "\n",
       "         [[-5.3966e-03,  8.0120e-03, -8.1167e-03,  ..., -4.4313e-03,\n",
       "            9.7715e-03,  1.9600e-02],\n",
       "          [-4.2187e-01,  7.0190e-02,  1.9664e-01,  ..., -3.1560e-02,\n",
       "            4.3849e-01, -4.3741e-01],\n",
       "          [-9.1374e-02,  1.5790e-01, -3.2075e-01,  ...,  4.0624e-01,\n",
       "            2.8282e-01,  6.4570e-02],\n",
       "          ...,\n",
       "          [-1.4121e-01,  3.5640e-02, -2.1401e-01,  ..., -1.4404e-01,\n",
       "           -1.3092e-01,  2.2910e-02],\n",
       "          [ 2.1936e-01,  5.1762e-01, -1.6930e-01,  ..., -6.5122e-01,\n",
       "            5.7275e-03, -3.7045e-01],\n",
       "          [ 1.3073e-01, -2.1508e-01, -1.5762e-01,  ...,  2.8813e-01,\n",
       "           -2.1199e-01, -2.5813e-01]]]], device='cuda:0',\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[-1.6668e-02,  1.4239e-02,  1.0524e-02,  ...,  2.4304e-01,\n",
       "            3.5329e-02,  5.0125e-01],\n",
       "          [ 1.0858e+00,  1.6322e+00, -1.8041e-03,  ...,  1.0703e+00,\n",
       "            3.3669e-02, -1.3434e+00],\n",
       "          [ 2.2799e+00,  2.7237e+00, -5.6769e-01,  ...,  5.7369e-01,\n",
       "           -8.7614e-01, -1.1940e+00],\n",
       "          ...,\n",
       "          [-1.6580e+00,  1.3740e+00, -7.0235e-01,  ..., -2.1174e+00,\n",
       "            7.7004e-01, -3.8010e-01],\n",
       "          [ 1.0214e+00,  1.6065e+00, -2.0401e-02,  ..., -1.1943e+00,\n",
       "            7.9380e-03, -1.4241e+00],\n",
       "          [ 5.0658e-01,  1.0034e+00, -1.6266e+00,  ..., -8.1323e-01,\n",
       "           -4.0244e-01, -1.4682e+00]],\n",
       "\n",
       "         [[-1.9614e-02,  1.7558e-02, -2.4708e-06,  ...,  1.9665e-01,\n",
       "           -8.1663e-02,  8.9916e-02],\n",
       "          [-8.9845e-01, -4.9157e-01,  1.5430e+00,  ..., -1.8501e+00,\n",
       "           -2.4922e-01,  4.2861e-01],\n",
       "          [-5.3882e-01,  1.3777e+00,  1.5402e+00,  ..., -7.7692e-01,\n",
       "            1.6269e+00, -2.1854e+00],\n",
       "          ...,\n",
       "          [-2.4483e-01, -1.0543e+00, -1.4152e+00,  ..., -2.0551e+00,\n",
       "            9.9357e-01,  1.5290e+00],\n",
       "          [-9.4433e-01,  1.1146e+00, -7.1872e-01,  ..., -1.6204e+00,\n",
       "           -4.7316e-01,  1.8264e+00],\n",
       "          [-5.1095e-01,  2.0895e+00,  8.0320e-01,  ..., -2.6416e+00,\n",
       "           -1.1176e+00,  9.3817e-01]],\n",
       "\n",
       "         [[-5.8428e-03, -2.1359e-02, -9.9968e-03,  ...,  8.4969e-03,\n",
       "            8.4808e-01, -1.2761e+00],\n",
       "          [-6.4516e-01,  1.8141e-01,  3.9105e-01,  ..., -2.9140e-01,\n",
       "           -2.6047e+00,  2.9484e+00],\n",
       "          [-1.8706e-01, -5.0793e-02,  1.7688e-01,  ...,  3.3398e-01,\n",
       "           -2.4914e+00,  8.5805e+00],\n",
       "          ...,\n",
       "          [ 1.5215e-02,  7.5800e-04,  2.5719e-02,  ..., -2.1127e+00,\n",
       "           -5.6057e+00,  7.5749e+00],\n",
       "          [-2.1618e-01, -4.4601e-01,  4.2799e-01,  ..., -1.3700e+00,\n",
       "           -5.9039e+00,  3.5780e+00],\n",
       "          [-2.5946e-01, -4.3994e-01,  3.5317e-01,  ..., -5.4889e+00,\n",
       "           -1.9973e+00,  1.0773e+01]],\n",
       "\n",
       "         [[-1.0660e-02, -3.3307e-03,  1.8028e-02,  ...,  8.3776e-02,\n",
       "            6.3980e-01, -9.9280e-01],\n",
       "          [-6.2799e-01, -9.0696e-01, -8.3474e-01,  ...,  9.3342e-01,\n",
       "           -1.3183e+00,  2.4412e+00],\n",
       "          [ 2.1739e+00, -7.4067e-01,  9.0629e-01,  ..., -3.1740e-01,\n",
       "           -9.7105e-01,  2.1761e+00],\n",
       "          ...,\n",
       "          [-7.2463e-01,  2.4996e-02,  5.0313e-01,  ...,  1.4756e+00,\n",
       "           -1.0654e+00,  4.7796e+00],\n",
       "          [-3.1420e-01, -7.3816e-01,  3.2917e-01,  ...,  1.9677e+00,\n",
       "           -7.2165e-01,  6.3454e+00],\n",
       "          [-1.1266e+00, -9.3878e-01,  1.3889e+00,  ...,  2.5417e+00,\n",
       "           -5.2740e-01,  6.7278e+00]]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>), tensor([[[[ 7.1731e-03,  1.3491e-02,  5.6878e-03,  ...,  2.9284e-03,\n",
       "           -5.4455e-03,  1.9823e-02],\n",
       "          [ 4.2986e-01, -3.1973e-01, -3.0254e-03,  ...,  8.8276e-02,\n",
       "           -3.1251e-01,  3.7410e-01],\n",
       "          [-2.7789e-01, -4.8823e-01, -1.2430e-01,  ..., -1.4483e-01,\n",
       "           -4.6602e-01,  1.5328e-01],\n",
       "          ...,\n",
       "          [-4.8642e-01,  1.3945e-01,  3.2595e-01,  ..., -3.0452e-02,\n",
       "           -2.6119e-01,  8.4185e-02],\n",
       "          [-3.5954e-01, -1.8676e-01,  5.1233e-01,  ..., -2.5287e-03,\n",
       "            5.3800e-01, -2.0380e-02],\n",
       "          [-2.9693e-01, -5.1723e-01,  3.4106e-01,  ..., -1.1194e-02,\n",
       "            1.5943e-01, -2.8082e-01]],\n",
       "\n",
       "         [[ 1.1560e-02,  8.5366e-04,  7.8070e-04,  ..., -4.3875e-03,\n",
       "           -2.6889e-03,  6.8234e-04],\n",
       "          [-3.5268e-01,  1.6692e-01, -6.8844e-02,  ..., -1.6340e-01,\n",
       "           -1.9549e-01, -1.7196e-01],\n",
       "          [ 1.0927e-01, -6.5300e-01, -4.0112e-01,  ..., -6.4803e-02,\n",
       "           -3.7369e-01,  2.2033e-01],\n",
       "          ...,\n",
       "          [-4.7912e-02,  3.1103e-01,  3.2019e-01,  ...,  3.6481e-01,\n",
       "            5.3497e-01, -3.2163e-01],\n",
       "          [-2.1806e-02,  7.8612e-02,  6.2636e-02,  ..., -7.2964e-02,\n",
       "            2.5768e-01, -8.2049e-02],\n",
       "          [-3.8545e-01, -4.0389e-02,  8.6620e-02,  ..., -8.1459e-02,\n",
       "            1.0723e-01,  7.9811e-02]],\n",
       "\n",
       "         [[ 4.1642e-03, -2.8479e-03, -2.3844e-03,  ...,  1.3302e-03,\n",
       "           -5.7205e-03,  1.6556e-04],\n",
       "          [ 3.5791e-01, -1.0880e-02,  2.8874e-01,  ...,  1.5060e-01,\n",
       "           -3.8833e-01,  8.0918e-01],\n",
       "          [ 4.9497e-01, -3.5791e-01,  3.0856e-01,  ...,  2.3943e-01,\n",
       "            4.2922e-02,  2.5653e-01],\n",
       "          ...,\n",
       "          [ 5.6735e-01, -5.0094e-01, -8.0892e-02,  ..., -9.2435e-02,\n",
       "           -3.9596e-02,  1.2040e-01],\n",
       "          [ 1.3514e-01, -3.2464e-01,  1.8321e-01,  ...,  1.2151e-01,\n",
       "            3.0316e-01, -7.3734e-02],\n",
       "          [ 5.0910e-04,  1.8320e-01,  3.7757e-02,  ...,  9.9708e-02,\n",
       "           -4.1913e-02, -1.9459e-01]],\n",
       "\n",
       "         [[ 5.2882e-03, -9.3971e-03, -5.6007e-03,  ..., -2.9403e-03,\n",
       "            5.4739e-03,  2.8744e-02],\n",
       "          [-9.6147e-02, -5.3553e-02, -7.2415e-03,  ..., -7.4018e-03,\n",
       "            1.6549e-02,  6.6422e-02],\n",
       "          [ 1.4633e-01, -1.2091e-01, -2.1571e-01,  ...,  1.1152e-02,\n",
       "            1.5795e-01, -1.3334e-01],\n",
       "          ...,\n",
       "          [-1.7524e-01, -3.0258e-01, -1.3713e-01,  ..., -2.7338e-02,\n",
       "           -1.4153e-01, -2.0215e-01],\n",
       "          [ 3.9884e-02, -5.5757e-01, -2.1009e-02,  ...,  4.5788e-02,\n",
       "           -2.7132e-01, -1.3214e-01],\n",
       "          [ 2.8193e-02, -5.3371e-01, -8.6785e-02,  ...,  2.0396e-01,\n",
       "           -2.2818e-01, -7.0119e-03]]]], device='cuda:0',\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[ 2.3303e-02, -3.6703e-03,  2.9925e-02,  ..., -3.8207e-01,\n",
       "            6.3443e-01,  2.1921e+00],\n",
       "          [-1.7956e+00, -1.6373e+00,  1.3717e+00,  ..., -3.4514e-01,\n",
       "            1.0072e+00, -3.2947e+00],\n",
       "          [-2.6000e+00, -2.3603e+00,  2.0857e+00,  ..., -1.0108e+00,\n",
       "            5.8408e-01, -3.8834e+00],\n",
       "          ...,\n",
       "          [ 1.3837e+00, -2.0492e+00, -2.6777e+00,  ..., -3.3114e-01,\n",
       "           -4.3354e-01, -3.2617e+00],\n",
       "          [-4.9651e-02, -5.7094e-01, -6.9172e-01,  ...,  1.2490e+00,\n",
       "           -1.1574e-01, -3.2046e+00],\n",
       "          [-7.6697e-01, -6.4933e-01, -2.3216e-01,  ...,  4.8966e+00,\n",
       "            4.1236e-02, -2.7725e+00]],\n",
       "\n",
       "         [[ 1.1642e-02,  4.2810e-02, -3.7819e-02,  ..., -1.7938e-02,\n",
       "           -6.2139e-01, -1.4307e+00],\n",
       "          [ 9.5994e-02, -9.0196e-01, -8.1551e-01,  ...,  2.2058e+00,\n",
       "            2.1769e+00,  1.5063e+00],\n",
       "          [-1.5309e+00, -8.6783e-01, -1.2065e-01,  ...,  8.2293e-01,\n",
       "            1.1822e+00,  2.1321e+00],\n",
       "          ...,\n",
       "          [ 5.8413e-01, -1.5710e+00, -8.4898e-02,  ...,  2.2580e+00,\n",
       "           -2.0052e+00,  4.7102e+00],\n",
       "          [ 6.5315e-01, -3.4597e-01,  1.2690e-01,  ...,  1.4289e+00,\n",
       "           -8.9787e-01,  5.7229e+00],\n",
       "          [ 6.5892e-01,  8.6856e-01, -6.5860e-02,  ...,  1.6993e+00,\n",
       "           -1.1689e+00,  5.9771e+00]],\n",
       "\n",
       "         [[ 6.1868e-03, -1.7850e-02,  4.9882e-02,  ...,  5.1531e-01,\n",
       "           -2.4187e-01, -6.3889e-01],\n",
       "          [ 2.8658e+00,  1.2208e-01,  8.8478e-01,  ..., -2.4731e-01,\n",
       "            5.5486e-01, -3.9054e+00],\n",
       "          [ 6.6968e+00,  1.8614e+00,  2.3084e+00,  ..., -1.7578e+00,\n",
       "           -8.6897e-01, -3.6245e+00],\n",
       "          ...,\n",
       "          [-4.6909e+00, -8.6154e-01, -2.7784e+00,  ..., -3.1452e+00,\n",
       "           -1.6848e+00, -2.3216e+00],\n",
       "          [-1.5748e+00,  1.5916e+00, -2.2171e+00,  ..., -3.8996e+00,\n",
       "           -3.4737e-01, -7.4073e-01],\n",
       "          [ 2.3876e+00,  2.6182e+00, -1.0281e+00,  ..., -2.2855e+00,\n",
       "           -4.5749e-01, -4.4666e-01]],\n",
       "\n",
       "         [[-9.0854e-03, -6.0505e-03,  7.2666e-03,  ...,  4.0061e-02,\n",
       "            5.6371e-01, -1.7832e+00],\n",
       "          [ 1.7340e-01, -3.3147e-01,  3.8068e-01,  ...,  1.7160e+00,\n",
       "           -3.5501e+00,  7.1002e+00],\n",
       "          [ 3.0188e-01,  3.2775e-01,  7.1074e-01,  ..., -8.2248e-01,\n",
       "           -2.6588e+00,  7.6783e+00],\n",
       "          ...,\n",
       "          [-1.2342e-02,  5.2751e-01, -4.5793e-02,  ..., -2.4181e+00,\n",
       "           -4.8934e+00,  5.8410e+00],\n",
       "          [ 4.8898e-01,  2.0320e-01, -5.5646e-01,  ..., -9.4789e-01,\n",
       "           -4.0852e+00,  9.9426e+00],\n",
       "          [ 1.7231e-01,  4.0003e-02, -5.3203e-01,  ...,  5.0302e-02,\n",
       "           -5.4684e+00,  9.7238e+00]]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>), tensor([[[[-4.2990e-03,  2.7713e-03, -1.6543e-02,  ...,  8.3821e-03,\n",
       "            1.1845e-02, -1.9322e-03],\n",
       "          [-2.5078e-01,  1.3718e-01, -5.2826e-02,  ..., -1.4546e-01,\n",
       "           -6.0656e-02,  2.3517e-02],\n",
       "          [ 1.2181e-01,  1.5966e-01, -1.1470e-01,  ..., -1.6453e-02,\n",
       "           -1.1240e-01,  3.8308e-02],\n",
       "          ...,\n",
       "          [-1.6174e-01, -3.8296e-02, -2.5160e-01,  ..., -3.7043e-01,\n",
       "           -4.5939e-02, -4.7872e-03],\n",
       "          [-1.1960e-01, -2.9297e-01, -8.2341e-02,  ..., -7.6695e-01,\n",
       "           -1.2043e-01,  6.5002e-02],\n",
       "          [-1.3689e-01, -2.4028e-01, -1.9739e-01,  ..., -6.6723e-01,\n",
       "           -2.3392e-02, -1.6775e-02]],\n",
       "\n",
       "         [[ 1.7121e-03, -9.0836e-03,  3.4705e-03,  ..., -3.7863e-03,\n",
       "            7.2628e-03, -7.4652e-03],\n",
       "          [-9.0612e-02, -6.8618e-02, -1.3827e-01,  ..., -1.9227e-01,\n",
       "           -1.7040e-02,  3.3751e-01],\n",
       "          [-8.9921e-02, -2.0234e-01, -2.2181e-01,  ..., -1.4822e-01,\n",
       "            1.7640e-02,  5.9328e-02],\n",
       "          ...,\n",
       "          [-1.5778e-01,  3.8777e-01, -2.6643e-01,  ...,  3.3953e-01,\n",
       "           -1.6458e-01,  3.8843e-02],\n",
       "          [-3.2086e-01, -5.7878e-02,  4.1505e-02,  ...,  5.1522e-02,\n",
       "           -1.7780e-01, -3.0197e-02],\n",
       "          [-3.4820e-01, -1.8390e-02, -7.9690e-02,  ..., -2.3944e-01,\n",
       "           -2.5426e-01, -7.9899e-03]],\n",
       "\n",
       "         [[-1.2006e-03, -1.3409e-03,  4.9250e-04,  ...,  2.4183e-03,\n",
       "            3.6165e-03, -5.8778e-03],\n",
       "          [-7.3533e-02, -2.2628e-01, -1.6117e-01,  ...,  1.9027e-01,\n",
       "            9.5479e-02, -2.1345e-02],\n",
       "          [-8.6813e-02, -2.1950e-01, -3.3614e-02,  ...,  2.7954e-01,\n",
       "           -3.0289e-01, -1.5379e-01],\n",
       "          ...,\n",
       "          [-1.0713e-01, -8.4878e-02, -5.3872e-01,  ...,  2.3559e-01,\n",
       "            5.3590e-02, -1.1413e-01],\n",
       "          [-3.4529e-01, -2.6130e-01, -3.9897e-01,  ...,  1.0108e-02,\n",
       "           -8.9980e-02, -6.5848e-02],\n",
       "          [-2.5182e-01, -2.1641e-01, -4.8328e-01,  ..., -2.9566e-01,\n",
       "           -3.8737e-03, -2.5785e-01]],\n",
       "\n",
       "         [[ 7.2113e-03, -1.8158e-04,  1.4222e-02,  ...,  1.3473e-03,\n",
       "           -1.4321e-03, -5.7954e-03],\n",
       "          [-6.3400e-01,  6.1833e-02,  6.6782e-02,  ...,  6.2978e-02,\n",
       "            2.7448e-01,  2.6611e-01],\n",
       "          [-6.6708e-02, -1.4043e-01,  3.0528e-01,  ...,  2.0557e-01,\n",
       "           -1.4910e-01, -5.3095e-03],\n",
       "          ...,\n",
       "          [ 3.4866e-01,  2.6756e-01,  4.5689e-01,  ...,  3.0096e-02,\n",
       "           -1.2580e-01,  1.8770e-01],\n",
       "          [ 5.1828e-01, -3.8701e-01,  1.4169e-02,  ...,  1.9874e-01,\n",
       "            1.2076e-01,  4.6901e-01],\n",
       "          [ 5.1067e-01,  2.2859e-01, -6.2908e-02,  ...,  1.8485e-01,\n",
       "           -1.1581e-01,  1.5487e-01]]]], device='cuda:0',\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[ 1.5472e-03, -2.0081e-02,  5.6683e-03,  ..., -8.9928e-01,\n",
       "            1.8418e+00,  9.7450e-01],\n",
       "          [-6.8363e-01, -4.9723e-01,  1.7115e-01,  ...,  8.5164e-01,\n",
       "           -2.2775e+00, -1.8646e+00],\n",
       "          [ 2.2374e-01, -5.7651e-01,  1.1650e+00,  ...,  1.0002e+00,\n",
       "           -1.3361e+00, -2.7972e+00],\n",
       "          ...,\n",
       "          [-1.8871e-01, -2.1191e-01, -2.6682e-01,  ...,  9.4808e-01,\n",
       "           -8.9702e-01, -6.7090e+00],\n",
       "          [-4.7186e-01, -5.5513e-01, -3.5129e-01,  ...,  2.1843e+00,\n",
       "           -4.4713e+00, -3.8623e+00],\n",
       "          [-4.4518e-02, -2.6258e-01, -5.0588e-01,  ...,  2.2183e+00,\n",
       "           -4.4803e+00, -3.4075e+00]],\n",
       "\n",
       "         [[-6.4373e-03, -1.3227e-02,  1.5662e-02,  ..., -1.1841e+00,\n",
       "           -4.6260e-01, -1.6565e+00],\n",
       "          [ 1.3059e+00, -7.1863e-01, -1.3416e+00,  ...,  4.3765e+00,\n",
       "           -2.0433e+00,  2.9679e+00],\n",
       "          [-1.2724e+00, -3.6762e-01, -1.1124e-01,  ...,  3.1568e+00,\n",
       "            1.7180e-01,  4.1248e+00],\n",
       "          ...,\n",
       "          [ 1.2355e+00, -7.6978e-01,  5.6003e-01,  ...,  2.6775e+00,\n",
       "            1.4112e+00,  6.5871e+00],\n",
       "          [ 2.3811e+00,  1.1345e+00,  4.1580e-01,  ...,  4.9042e+00,\n",
       "            4.3532e-02,  5.4226e+00],\n",
       "          [ 2.4009e+00,  2.1778e+00, -1.5879e-01,  ...,  2.0225e+00,\n",
       "            1.9380e-01,  4.0421e+00]],\n",
       "\n",
       "         [[-5.9401e-03,  5.8265e-03, -2.3244e-02,  ...,  2.1332e-01,\n",
       "            4.4300e-01, -9.1663e-01],\n",
       "          [-4.2681e-01,  6.6949e-01, -4.7138e-01,  ..., -1.5897e+00,\n",
       "           -1.2740e+00,  2.1036e+00],\n",
       "          [-1.6171e+00, -1.0382e+00, -3.3472e-01,  ...,  4.5626e-01,\n",
       "           -1.5171e+00,  1.3594e+00],\n",
       "          ...,\n",
       "          [ 9.2404e-01,  3.8747e-01,  9.0949e-01,  ..., -9.4001e-01,\n",
       "           -1.1833e+00,  2.8514e+00],\n",
       "          [ 5.4733e-02, -1.3527e+00,  1.7454e+00,  ..., -2.5931e+00,\n",
       "           -1.0376e+00,  4.7150e+00],\n",
       "          [ 1.6346e-01, -1.2913e+00,  1.4645e+00,  ..., -2.0489e+00,\n",
       "           -5.2434e-01,  3.8611e+00]],\n",
       "\n",
       "         [[ 2.4806e-02, -3.9219e-02,  3.6371e-02,  ...,  3.0631e-01,\n",
       "           -1.6936e-01, -1.7186e+00],\n",
       "          [-3.0036e+00,  1.2035e+00,  1.0825e+00,  ...,  5.9442e-01,\n",
       "           -1.6670e+00,  6.3283e+00],\n",
       "          [-4.1716e+00, -1.9479e+00, -3.0685e-02,  ...,  1.3894e+00,\n",
       "           -1.6661e+00,  6.0822e+00],\n",
       "          ...,\n",
       "          [ 3.3227e+00, -1.2204e+00, -1.8977e+00,  ...,  3.0726e-02,\n",
       "           -2.1727e+00,  4.4706e+00],\n",
       "          [ 7.4741e-01, -1.6879e-01, -8.4996e-05,  ...,  7.4941e-01,\n",
       "           -4.7486e-01,  5.3390e+00],\n",
       "          [-6.5679e-01, -1.4078e+00,  8.1496e-01,  ...,  1.2601e+00,\n",
       "           -4.4138e-01,  3.9115e+00]]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>), tensor([[[[ 9.3200e-03,  1.2169e-02,  7.5670e-03,  ...,  7.4894e-03,\n",
       "           -1.4579e-02,  4.8961e-03],\n",
       "          [ 3.0507e-02, -3.9190e-02, -6.2048e-02,  ...,  8.6160e-02,\n",
       "            2.9936e-01,  2.5786e-01],\n",
       "          [ 1.7722e+00, -4.8260e-01,  5.8324e-01,  ..., -8.4013e-01,\n",
       "            6.7485e-01,  5.8945e-01],\n",
       "          ...,\n",
       "          [-2.6406e-01, -1.2113e+00,  8.0316e-01,  ..., -8.8113e-02,\n",
       "           -7.1054e-01, -5.9832e-01],\n",
       "          [ 1.4853e-01, -2.1977e-01,  6.7991e-02,  ...,  6.7634e-02,\n",
       "           -4.4069e-01, -2.1342e-01],\n",
       "          [ 3.9244e-01,  2.4129e-01,  2.8351e-01,  ...,  3.6932e-02,\n",
       "           -3.6139e-01, -3.1901e-01]],\n",
       "\n",
       "         [[ 1.2865e-02, -3.5199e-03, -6.6526e-03,  ...,  1.4873e-04,\n",
       "           -6.9255e-03, -9.8085e-03],\n",
       "          [ 2.8883e-01, -3.3256e-01, -5.1872e-01,  ...,  2.9271e-01,\n",
       "           -3.3548e-02, -5.8955e-02],\n",
       "          [-6.5949e-02, -4.4371e-01, -1.7837e-01,  ...,  1.7117e-02,\n",
       "            4.1974e-01, -5.0084e-01],\n",
       "          ...,\n",
       "          [ 1.8035e-02,  3.8597e-01,  3.0503e-01,  ...,  4.8389e-02,\n",
       "            1.9684e-01,  2.1497e-01],\n",
       "          [-8.1944e-02,  1.8198e-01,  1.5572e-01,  ...,  1.4868e-01,\n",
       "            2.6669e-01,  6.3035e-02],\n",
       "          [ 1.6546e-01,  1.2088e-02,  3.3105e-01,  ..., -7.6948e-02,\n",
       "            2.8086e-01, -1.3395e-01]],\n",
       "\n",
       "         [[ 4.1414e-03, -1.9330e-03,  6.8297e-03,  ...,  6.3223e-03,\n",
       "            3.1343e-03, -9.5626e-04],\n",
       "          [-7.5474e-01, -1.0054e-01, -1.5489e-01,  ...,  6.8250e-02,\n",
       "            2.5287e-01, -2.3678e-02],\n",
       "          [ 6.4989e-01,  4.0478e-01,  5.0916e-01,  ..., -4.3036e-01,\n",
       "            6.3644e-02,  1.4410e-01],\n",
       "          ...,\n",
       "          [-6.7639e-01,  5.8583e-01, -7.0845e-01,  ..., -1.0299e-01,\n",
       "            3.1263e-01,  2.0487e-01],\n",
       "          [-2.7173e-01,  7.9639e-02,  1.1070e-01,  ...,  1.0131e-02,\n",
       "            3.7540e-01,  1.3555e-01],\n",
       "          [ 1.8597e-02,  1.0537e-01, -1.4879e-01,  ...,  9.9019e-02,\n",
       "            4.7822e-01,  1.9870e-01]],\n",
       "\n",
       "         [[-8.8801e-03, -1.1200e-03,  5.1999e-03,  ..., -8.7053e-03,\n",
       "            3.2505e-03,  4.3970e-03],\n",
       "          [-6.4418e-01,  2.4446e-01,  2.8826e-01,  ..., -2.1200e-01,\n",
       "           -6.8357e-02,  4.2688e-01],\n",
       "          [-8.3674e-02, -1.0539e-01, -8.8138e-02,  ...,  2.3871e-01,\n",
       "           -2.4476e-01,  1.5428e-01],\n",
       "          ...,\n",
       "          [ 2.0173e-01, -8.1320e-02,  2.6279e-01,  ...,  2.7839e-01,\n",
       "           -1.8072e-01,  1.0525e-01],\n",
       "          [-1.2588e-01, -8.4002e-02,  2.7329e-01,  ..., -2.5227e-01,\n",
       "           -5.8455e-02, -1.9373e-01],\n",
       "          [-1.4501e-01,  4.4636e-03,  2.1413e-01,  ..., -3.2360e-01,\n",
       "            1.8835e-01,  7.1267e-02]]]], device='cuda:0',\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[ 4.8925e-04, -5.9560e-03, -3.6188e-03,  ..., -1.0247e+00,\n",
       "            5.1912e-01, -2.5444e-01],\n",
       "          [-9.9652e-01, -1.3060e+00, -9.3629e-01,  ...,  2.3682e+00,\n",
       "           -8.0255e+00, -1.3669e+00],\n",
       "          [ 2.8488e-01,  1.7821e-01, -3.5680e-01,  ...,  3.8705e+00,\n",
       "           -5.6495e+00,  3.1809e+00],\n",
       "          ...,\n",
       "          [-3.9790e-01, -1.7924e-01,  6.1456e-01,  ...,  1.8966e+00,\n",
       "           -7.7858e+00,  1.9217e+00],\n",
       "          [-6.6707e-01, -2.5964e-01, -3.0800e-01,  ...,  1.5442e+00,\n",
       "           -9.6471e+00,  1.7944e+00],\n",
       "          [-5.6775e-02,  2.3938e-01, -1.3331e-02,  ...,  1.4980e+00,\n",
       "           -7.2176e+00, -2.3260e-01]],\n",
       "\n",
       "         [[-1.1858e-02,  9.3094e-03,  8.8701e-03,  ...,  9.9578e-02,\n",
       "            2.2098e+00, -5.7982e-01],\n",
       "          [ 3.1827e-01, -1.8340e+00, -1.6135e+00,  ..., -1.4311e+00,\n",
       "           -3.0516e-01,  3.0011e+00],\n",
       "          [ 3.1824e+00, -3.9131e-01, -1.6214e+00,  ..., -2.0496e+00,\n",
       "           -1.7533e+00,  1.2314e+00],\n",
       "          ...,\n",
       "          [-2.2717e+00, -1.1218e+00,  1.2226e+00,  ..., -2.8639e+00,\n",
       "           -1.6246e+00,  2.0695e+00],\n",
       "          [-2.1126e-03, -3.6021e-01,  8.0691e-01,  ..., -2.2548e+00,\n",
       "           -3.0748e+00,  2.0229e+00],\n",
       "          [ 1.1326e-01, -2.6201e-01, -6.6918e-02,  ..., -1.3841e-01,\n",
       "           -3.6096e+00,  4.6192e-01]],\n",
       "\n",
       "         [[ 4.1079e-03, -3.7747e-03,  1.6547e-02,  ...,  1.5362e+00,\n",
       "           -8.3554e-02,  2.1806e+00],\n",
       "          [-4.9278e-01,  1.0519e+00, -7.7118e-01,  ..., -1.2996e+00,\n",
       "           -2.9515e+00, -2.8817e+00],\n",
       "          [-8.0319e-01, -3.3752e-02,  9.3118e-01,  ..., -4.1669e+00,\n",
       "            1.3555e-01, -2.4252e+00],\n",
       "          ...,\n",
       "          [-3.4601e-01,  5.7447e-01,  1.8796e-01,  ..., -4.9564e+00,\n",
       "            7.3333e-01, -1.9765e+00],\n",
       "          [-2.2195e-01,  6.1559e-01, -6.2616e-01,  ..., -3.3533e+00,\n",
       "           -3.1659e+00, -8.0111e+00],\n",
       "          [-1.5417e-02,  3.7902e-01, -9.4086e-01,  ..., -1.7540e+00,\n",
       "           -6.8088e-01, -6.3003e+00]],\n",
       "\n",
       "         [[ 1.8999e-02,  1.1250e-02, -1.5030e-02,  ...,  7.4062e-02,\n",
       "            2.0666e-01, -2.4207e-01],\n",
       "          [ 9.2752e-01,  5.1369e-01, -9.6988e-01,  ..., -1.1104e+00,\n",
       "            4.0490e+00,  8.5514e-01],\n",
       "          [-2.0435e+00, -1.2006e+00, -2.4479e+00,  ..., -8.0178e-01,\n",
       "            1.3532e+00,  5.9802e-01],\n",
       "          ...,\n",
       "          [ 1.1937e+00,  4.6035e-01,  1.6439e+00,  ..., -1.5747e+00,\n",
       "            2.5364e+00,  2.2062e+00],\n",
       "          [ 3.7559e-01, -5.2637e-01,  1.5882e-01,  ..., -2.8096e+00,\n",
       "            3.0885e+00,  7.7008e-01],\n",
       "          [ 6.7742e-01, -3.0383e+00, -5.0332e-01,  ..., -2.9032e+00,\n",
       "            9.8721e-01, -3.3704e-01]]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>), tensor([[[[-1.1693e-02,  1.7918e-03,  7.3503e-03,  ..., -1.7613e-02,\n",
       "            8.9874e-03, -2.8236e-03],\n",
       "          [ 3.1567e-01, -8.6661e-01, -3.0758e-01,  ..., -2.2378e-01,\n",
       "           -3.5480e-03,  7.2739e-02],\n",
       "          [-1.6382e+00,  1.8619e-01, -1.7340e+00,  ...,  3.5104e-01,\n",
       "           -1.0322e-02,  4.5611e-01],\n",
       "          ...,\n",
       "          [-7.6136e-01, -3.0690e-01, -9.9980e-02,  ...,  6.8998e-01,\n",
       "           -1.0223e+00, -5.6921e-01],\n",
       "          [-5.8148e-02,  2.2741e-01, -1.5209e-02,  ..., -1.0829e-02,\n",
       "            1.2598e-01, -3.7332e-01],\n",
       "          [-3.4199e-01,  2.7149e-01,  2.9830e-01,  ...,  1.1379e-01,\n",
       "           -1.5248e-01, -1.0657e-02]],\n",
       "\n",
       "         [[-1.5063e-02,  1.5680e-02, -1.2153e-02,  ...,  9.4842e-03,\n",
       "           -1.7077e-02, -7.6649e-03],\n",
       "          [-3.0798e-02, -2.4980e-01,  4.0686e-02,  ..., -1.1452e-01,\n",
       "            8.2573e-02, -1.1899e-01],\n",
       "          [ 1.1906e-01, -1.0530e-01,  1.1052e-01,  ..., -2.8602e-01,\n",
       "            6.3324e-01,  1.7153e-01],\n",
       "          ...,\n",
       "          [-1.1435e-01,  1.7610e-01,  4.6120e-01,  ...,  3.2760e-01,\n",
       "            1.7426e-01,  1.5004e-01],\n",
       "          [-2.3213e-03, -3.4057e-02,  3.9382e-02,  ...,  1.7001e-01,\n",
       "            1.9882e-01,  1.2792e-01],\n",
       "          [ 9.1927e-03,  1.7818e-01, -2.1967e-01,  ...,  3.7101e-01,\n",
       "            2.1155e-01,  6.1624e-03]],\n",
       "\n",
       "         [[ 1.2217e-02, -3.9376e-03,  1.3445e-02,  ..., -2.4023e-03,\n",
       "           -7.7857e-03,  6.6734e-03],\n",
       "          [-5.3629e-01,  2.8599e-02, -1.3729e-01,  ...,  4.1545e-01,\n",
       "            8.1388e-01,  2.2793e-02],\n",
       "          [-7.6681e-01,  7.3259e-01, -3.1756e-01,  ..., -5.8840e-02,\n",
       "            7.4590e-01,  6.8120e-02],\n",
       "          ...,\n",
       "          [-9.7931e-03,  6.4271e-01, -2.3667e-01,  ...,  3.9728e-02,\n",
       "           -5.3262e-01,  1.3453e-01],\n",
       "          [ 7.2072e-01,  2.4864e-01, -5.1344e-02,  ...,  4.7434e-02,\n",
       "           -6.2691e-01,  2.0288e-01],\n",
       "          [ 6.1499e-01,  1.2538e-01,  2.5728e-01,  ...,  2.3860e-01,\n",
       "           -1.9973e-01, -5.3282e-03]],\n",
       "\n",
       "         [[-1.0278e-02,  1.0420e-02, -1.2039e-02,  ...,  8.9144e-03,\n",
       "            2.9408e-04,  1.8879e-03],\n",
       "          [ 1.1204e-01, -3.1120e-01,  3.4011e-01,  ..., -1.6488e-01,\n",
       "           -2.3762e-01,  1.6370e-01],\n",
       "          [-1.0312e-01, -1.0164e-01,  1.0970e-01,  ..., -1.0830e-01,\n",
       "           -4.8224e-01,  4.5065e-02],\n",
       "          ...,\n",
       "          [ 6.4066e-01,  1.6036e-01,  1.6077e-01,  ..., -2.7594e-01,\n",
       "           -1.3628e-01,  5.1149e-01],\n",
       "          [ 4.2973e-01,  6.8041e-02, -7.0660e-02,  ..., -1.4960e-01,\n",
       "            2.5172e-02,  2.7299e-01],\n",
       "          [ 2.0985e-01,  1.7285e-01, -4.2265e-02,  ...,  1.0916e-01,\n",
       "           -6.9988e-02,  2.2056e-01]]]], device='cuda:0',\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[ 5.9825e-03, -4.7740e-03, -1.3825e-02,  ..., -7.3978e-03,\n",
       "            1.2995e-01,  3.6638e-01],\n",
       "          [-4.7699e-02, -2.9363e+00, -9.5250e-01,  ...,  1.4212e-01,\n",
       "            1.2185e+00, -8.5835e-01],\n",
       "          [-5.0372e-02, -1.8262e+00,  2.3077e-01,  ..., -1.5578e+00,\n",
       "            6.4652e-01, -5.9333e-02],\n",
       "          ...,\n",
       "          [-9.5921e-01, -2.4564e+00,  1.0202e+00,  ..., -1.6560e+00,\n",
       "            2.6189e-01, -1.5479e+00],\n",
       "          [-5.0773e-01, -1.1168e+00,  3.9093e-02,  ...,  3.5740e-01,\n",
       "            1.0251e+00, -5.6141e-02],\n",
       "          [ 1.9918e-01, -4.4988e-01,  2.4096e-01,  ...,  8.1830e-01,\n",
       "            1.8222e-01,  2.8768e-01]],\n",
       "\n",
       "         [[ 9.6600e-03, -2.7261e-02, -2.2369e-02,  ..., -7.1150e-01,\n",
       "           -6.9479e-01,  2.6375e+00],\n",
       "          [-2.6980e-01,  1.3685e-01, -7.3137e-01,  ...,  4.4592e+00,\n",
       "           -1.4030e+00, -4.7666e+00],\n",
       "          [-2.2353e-02,  8.9172e-01, -8.1921e-01,  ..., -6.0203e-01,\n",
       "            1.1148e+00, -5.6161e+00],\n",
       "          ...,\n",
       "          [ 1.8368e-02,  4.7816e-01,  1.6651e-01,  ..., -2.2526e+00,\n",
       "            6.6064e-01, -5.5195e+00],\n",
       "          [ 1.8243e-02,  5.9870e-01, -6.6415e-02,  ...,  2.5741e+00,\n",
       "           -1.4618e-01, -8.8374e+00],\n",
       "          [-2.2641e-01,  4.2754e-01,  3.5339e-01,  ...,  2.9213e+00,\n",
       "           -2.4224e-01, -7.0103e+00]],\n",
       "\n",
       "         [[ 1.9328e-02,  3.8114e-03,  1.0308e-02,  ..., -4.1716e-02,\n",
       "           -2.2109e+00, -6.6772e-02],\n",
       "          [-4.6642e-01, -1.0547e+00,  1.0425e+00,  ...,  5.7507e-01,\n",
       "            1.2008e+00, -2.8530e-01],\n",
       "          [-1.5426e-01, -1.6409e+00, -2.4573e-01,  ...,  3.5278e+00,\n",
       "            2.2649e+00,  1.9327e+00],\n",
       "          ...,\n",
       "          [-7.7572e-01, -1.3963e+00, -3.7977e-01,  ...,  3.0276e+00,\n",
       "            2.0205e+00,  2.4929e+00],\n",
       "          [-4.1818e-01, -8.8385e-01, -3.0359e-01,  ...,  2.3294e+00,\n",
       "            4.0549e+00,  1.8825e+00],\n",
       "          [ 5.6977e-01, -5.5607e-01,  9.1832e-01,  ...,  2.1172e+00,\n",
       "            3.5398e+00,  1.2779e+00]],\n",
       "\n",
       "         [[-2.3044e-02, -1.9040e-02,  1.7779e-02,  ...,  5.3467e-01,\n",
       "           -1.3089e+00, -6.6868e-01],\n",
       "          [ 3.1288e+00,  2.1676e+00,  9.4806e-01,  ..., -9.5971e-01,\n",
       "            2.7270e+00,  1.9918e+00],\n",
       "          [ 4.5653e+00,  3.2974e-01,  1.5835e+00,  ..., -1.1697e+00,\n",
       "            2.4014e+00,  3.1716e-01],\n",
       "          ...,\n",
       "          [-3.6844e+00,  1.2547e+00, -2.4112e+00,  ..., -1.7235e+00,\n",
       "            2.8202e+00,  7.6948e-01],\n",
       "          [-7.1698e-01,  7.9904e-01, -1.5063e+00,  ..., -1.8779e+00,\n",
       "            3.4448e+00,  2.4633e+00],\n",
       "          [ 1.6374e+00, -1.1476e+00, -3.3572e-01,  ..., -1.1560e+00,\n",
       "            3.1850e+00,  9.7445e-01]]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>), tensor([[[[-5.3384e-03, -1.0221e-02, -7.9622e-03,  ..., -1.3644e-02,\n",
       "            4.9465e-04,  3.6299e-03],\n",
       "          [ 9.9751e-01,  2.6719e-01,  5.6610e-02,  ...,  5.2512e-02,\n",
       "            6.9279e-02, -5.7000e-01],\n",
       "          [-2.8355e-01,  1.7786e-01, -4.8756e-01,  ...,  3.1817e-01,\n",
       "           -2.8145e-01, -1.4149e-01],\n",
       "          ...,\n",
       "          [ 2.3278e-01, -2.6684e-01,  3.5117e-02,  ..., -1.0698e-01,\n",
       "           -5.0416e-03, -2.0985e-01],\n",
       "          [ 2.0481e-01,  5.3473e-01, -7.8848e-02,  ..., -2.1099e-01,\n",
       "            2.8781e-01, -4.3064e-01],\n",
       "          [ 4.1771e-01,  1.5817e-01, -4.9052e-02,  ..., -9.4430e-02,\n",
       "            3.4234e-01, -5.1142e-01]],\n",
       "\n",
       "         [[ 2.7485e-02, -1.5739e-02,  7.1994e-03,  ...,  8.2670e-03,\n",
       "           -2.2644e-02,  2.4964e-02],\n",
       "          [-2.0363e-01,  5.0111e-02, -9.4930e-01,  ...,  1.8652e-01,\n",
       "            2.6113e-01, -2.7313e-01],\n",
       "          [-3.8554e-01,  1.0525e-01,  3.8917e-02,  ..., -1.8104e-01,\n",
       "            2.9240e-01, -1.0459e+00],\n",
       "          ...,\n",
       "          [-7.6103e-02,  3.7979e-02,  9.0350e-01,  ...,  1.0814e+00,\n",
       "            1.5765e+00,  1.1864e-01],\n",
       "          [ 2.9001e-01,  1.5445e-01,  3.7846e-01,  ...,  1.9964e-02,\n",
       "            3.2921e-01, -2.3192e-01],\n",
       "          [ 4.7147e-01,  1.5875e-01, -1.0646e-01,  ...,  1.5591e-01,\n",
       "            9.0630e-02, -1.0442e-01]],\n",
       "\n",
       "         [[ 2.7276e-02,  1.1997e-02, -2.5235e-03,  ..., -2.0692e-03,\n",
       "            9.2579e-03,  2.0607e-03],\n",
       "          [-3.3733e-01, -2.7047e-01,  6.6044e-01,  ...,  2.7207e-01,\n",
       "           -9.6329e-02,  6.0017e-01],\n",
       "          [ 3.1140e-02, -5.1584e-02,  6.0085e-01,  ...,  3.0979e-02,\n",
       "            8.0721e-02,  9.4592e-01],\n",
       "          ...,\n",
       "          [-2.1942e-01, -3.2023e-01,  1.3263e-01,  ..., -5.4624e-01,\n",
       "           -7.8623e-01, -7.9124e-02],\n",
       "          [-6.2869e-02,  1.9727e-01,  3.9704e-01,  ..., -3.4738e-01,\n",
       "            6.9823e-02,  1.0770e-02],\n",
       "          [ 2.9768e-01, -1.7730e-01,  1.7655e-01,  ..., -3.7358e-01,\n",
       "           -1.4046e-02,  4.4396e-02]],\n",
       "\n",
       "         [[ 6.6250e-03, -7.6494e-03,  1.2543e-02,  ...,  8.9300e-03,\n",
       "           -5.6724e-03,  8.2954e-04],\n",
       "          [ 6.2827e-02, -2.2524e-02,  4.4416e-01,  ...,  5.7789e-01,\n",
       "            1.6044e-03,  6.8607e-02],\n",
       "          [ 1.1755e-01,  5.4549e-02,  3.3533e-01,  ..., -8.6451e-02,\n",
       "            8.4009e-02, -3.3661e-01],\n",
       "          ...,\n",
       "          [ 2.7508e-01, -4.2465e-01,  2.2361e-01,  ...,  2.9196e-01,\n",
       "           -3.6662e-01, -1.0331e-01],\n",
       "          [ 3.9747e-02,  7.9354e-02,  6.4410e-01,  ...,  5.9894e-01,\n",
       "            1.9684e-01,  2.6732e-02],\n",
       "          [ 2.8370e-01,  1.1418e-01,  5.3499e-01,  ...,  4.6613e-01,\n",
       "           -3.0053e-02,  7.8407e-02]]]], device='cuda:0',\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[-1.3578e-02, -1.3017e-02,  3.2854e-02,  ...,  8.4758e-02,\n",
       "            3.1913e-01,  3.6301e-01],\n",
       "          [-2.4277e+00,  2.1160e+00,  1.6601e+00,  ..., -3.3746e-01,\n",
       "           -7.2889e-01,  1.8636e+00],\n",
       "          [ 1.3599e+00,  2.8597e+00,  2.4086e+00,  ..., -2.2173e-01,\n",
       "            1.4853e-01, -5.9013e-01],\n",
       "          ...,\n",
       "          [-1.2423e+00,  2.9881e-01, -1.3673e+00,  ..., -4.7465e-01,\n",
       "            7.3802e-01,  8.8134e-01],\n",
       "          [-2.1450e+00,  5.9510e-01, -7.2156e-01,  ..., -1.4271e-01,\n",
       "            1.4518e+00,  2.6167e+00],\n",
       "          [ 2.1275e-01, -3.2072e-02, -1.4379e+00,  ...,  1.8597e+00,\n",
       "           -1.7626e-01,  1.0255e+00]],\n",
       "\n",
       "         [[-1.1514e-02, -6.9339e-03, -1.2293e-02,  ...,  2.6294e+00,\n",
       "           -5.5523e-01, -1.6678e+00],\n",
       "          [ 1.8591e+00, -2.1169e-01,  8.3752e-01,  ..., -1.1976e+00,\n",
       "           -2.2970e-01,  6.0275e-01],\n",
       "          [-4.5407e-02,  3.8988e-02, -3.1387e-01,  ..., -1.5719e+00,\n",
       "           -3.1586e+00,  2.8970e-01],\n",
       "          ...,\n",
       "          [-2.9964e-02, -2.8956e-02,  6.1919e-02,  ..., -8.2561e-01,\n",
       "            3.3271e+00,  8.9377e-02],\n",
       "          [ 1.4835e+00, -1.0243e+00, -1.7810e+00,  ..., -4.0968e+00,\n",
       "            9.7018e-01,  1.8758e+00],\n",
       "          [ 1.6379e+00,  2.0383e-01, -1.0006e+00,  ..., -3.3293e+00,\n",
       "            6.9960e-01,  1.8299e+00]],\n",
       "\n",
       "         [[-1.5681e-02,  2.3319e-02,  3.9660e-03,  ..., -1.0707e+00,\n",
       "            9.3095e-01,  2.2525e+00],\n",
       "          [ 1.7246e+00,  2.3577e+00, -1.4842e+00,  ...,  6.9416e-01,\n",
       "           -2.2816e+00, -2.6030e+00],\n",
       "          [-2.0051e+00,  3.0923e+00, -1.5265e+00,  ...,  4.3548e+00,\n",
       "           -5.5345e-01, -2.4559e+00],\n",
       "          ...,\n",
       "          [ 2.3526e+00,  2.9341e+00,  2.3843e+00,  ...,  2.3626e+00,\n",
       "           -1.7821e+00, -2.4100e+00],\n",
       "          [ 2.6407e+00,  1.0206e+00,  6.3923e-01,  ...,  1.7130e+00,\n",
       "           -1.9127e+00, -4.7716e+00],\n",
       "          [ 1.1755e+00, -3.4098e-01, -8.4430e-01,  ...,  1.7119e+00,\n",
       "           -1.1334e+00, -4.2207e+00]],\n",
       "\n",
       "         [[ 7.1906e-03, -3.6320e-03, -1.7657e-02,  ..., -3.9419e-01,\n",
       "           -2.7272e-01, -2.0887e+00],\n",
       "          [-1.6651e+00, -3.4024e-01,  8.9409e-01,  ..., -7.8647e-01,\n",
       "            5.1597e-01,  1.2722e+00],\n",
       "          [-3.1696e+00, -8.9351e-01,  1.7905e+00,  ...,  2.7577e-02,\n",
       "            3.4755e-01,  1.4537e+00],\n",
       "          ...,\n",
       "          [ 2.6847e+00, -2.3756e-01, -2.0361e+00,  ...,  1.4064e+00,\n",
       "            1.2541e+00,  2.0509e+00],\n",
       "          [ 3.2310e-01, -1.4287e+00, -1.3995e+00,  ..., -1.1809e+00,\n",
       "            8.1557e-01,  4.4353e+00],\n",
       "          [-1.0297e+00, -4.7114e-01, -6.2502e-01,  ..., -8.4949e-01,\n",
       "            1.2285e+00,  3.3128e+00]]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>), tensor([[[[ 8.4047e-03,  2.9488e-02, -1.0138e-02,  ...,  8.2058e-03,\n",
       "            1.9863e-02,  5.7852e-03],\n",
       "          [ 4.4610e-03,  3.7691e-01,  1.1479e-01,  ..., -7.3790e-02,\n",
       "            2.3109e-01, -1.1423e-01],\n",
       "          [-2.3402e-01, -2.4103e-01,  6.3034e-01,  ...,  1.4653e-01,\n",
       "            5.3589e-02, -3.1910e-02],\n",
       "          ...,\n",
       "          [-4.3000e-01, -1.5548e-01,  2.2087e-01,  ..., -2.4867e-02,\n",
       "           -2.6318e-01,  6.0541e-02],\n",
       "          [ 4.8729e-01,  3.1957e-02, -2.3566e-01,  ...,  8.1973e-02,\n",
       "           -5.1680e-01, -2.7025e-02],\n",
       "          [ 1.7411e-01,  4.0806e-01,  9.9553e-02,  ..., -2.2580e-01,\n",
       "           -3.2708e-01, -4.3634e-01]],\n",
       "\n",
       "         [[ 1.3623e-02, -2.1291e-02,  8.5997e-02,  ...,  5.3146e-03,\n",
       "           -2.0870e-02, -9.6012e-03],\n",
       "          [ 7.3269e-01,  4.6682e-01, -5.0370e-01,  ...,  2.4139e-02,\n",
       "           -3.2333e-01,  1.8317e-01],\n",
       "          [-9.6594e-01, -2.4528e+00,  9.6052e-01,  ..., -4.5609e-01,\n",
       "           -5.1078e-01,  3.7371e-01],\n",
       "          ...,\n",
       "          [-2.5779e-02, -4.3227e-01,  5.1075e-02,  ..., -1.4709e+00,\n",
       "            9.8824e-01, -4.5599e-01],\n",
       "          [ 1.8778e-01, -3.7202e-02, -4.5168e-01,  ..., -2.1717e-01,\n",
       "           -1.2169e-03, -1.7062e-03],\n",
       "          [ 1.2485e-01, -1.5407e-02, -6.4931e-01,  ..., -3.3423e-01,\n",
       "            2.2247e-01,  3.2854e-01]],\n",
       "\n",
       "         [[ 5.7478e-03,  1.0398e-02,  1.0630e-02,  ...,  5.1242e-04,\n",
       "           -1.6192e-02,  2.4805e-03],\n",
       "          [ 8.7589e-02,  2.9554e-02, -5.9283e-01,  ..., -6.6387e-02,\n",
       "           -2.3689e-01, -4.1369e-01],\n",
       "          [ 1.1065e-01,  9.5990e-01, -1.3877e-01,  ..., -8.3997e-02,\n",
       "            1.7834e-01,  3.2851e-01],\n",
       "          ...,\n",
       "          [-6.5844e-01,  3.4182e-01,  2.1449e-02,  ...,  1.3500e-01,\n",
       "            6.7871e-02, -4.4432e-01],\n",
       "          [-1.3031e-01, -2.7457e-01, -2.2895e-01,  ..., -2.1396e-01,\n",
       "            2.9518e-01, -2.8915e-02],\n",
       "          [-2.6122e-01, -5.3807e-01,  1.3116e-02,  ..., -2.4064e-01,\n",
       "            3.2063e-01, -2.9796e-01]],\n",
       "\n",
       "         [[ 5.4836e-03,  2.6865e-03, -8.2877e-03,  ...,  2.0648e-02,\n",
       "           -7.2273e-03,  9.2062e-03],\n",
       "          [ 1.9193e-01, -4.8629e-02, -3.8948e-01,  ...,  1.5716e-01,\n",
       "            2.5420e-01,  3.1649e-01],\n",
       "          [ 1.0560e-01,  8.4725e-03, -6.8328e-01,  ..., -2.6021e-01,\n",
       "           -1.3243e-01,  6.8337e-01],\n",
       "          ...,\n",
       "          [ 2.5050e-01,  3.3542e-01, -7.1680e-01,  ..., -1.9438e-01,\n",
       "            2.9279e-02,  6.3579e-01],\n",
       "          [ 7.2275e-02,  2.7773e-01, -3.7371e-01,  ...,  2.7921e-02,\n",
       "            7.5317e-02,  3.6531e-01],\n",
       "          [ 1.9144e-01,  5.9826e-01,  3.2171e-01,  ..., -1.1149e-01,\n",
       "            5.5360e-03,  5.8346e-01]]]], device='cuda:0',\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[ 4.7534e-03,  1.7406e-02, -1.5779e-02,  ..., -7.5581e-01,\n",
       "            2.2628e-03,  2.2974e+00],\n",
       "          [-2.1086e+00, -2.5268e+00, -5.4673e-01,  ...,  2.2660e+00,\n",
       "            6.7809e-01, -1.7557e+00],\n",
       "          [-2.7933e+00, -4.0883e-01, -2.3191e-01,  ...,  3.0780e-01,\n",
       "            9.3791e-01, -1.0352e+00],\n",
       "          ...,\n",
       "          [ 2.3901e+00, -3.1130e+00,  1.3614e+00,  ...,  1.0954e+00,\n",
       "            1.4277e+00, -3.0768e+00],\n",
       "          [ 3.1121e-01,  4.3523e-03,  9.8073e-01,  ...,  1.7131e+00,\n",
       "            2.5538e-02, -4.2556e+00],\n",
       "          [-1.7321e+00,  1.3477e+00,  2.7325e-01,  ...,  1.0468e+00,\n",
       "            3.1821e-01, -3.0552e+00]],\n",
       "\n",
       "         [[ 6.3993e-03, -4.1568e-02, -7.2850e-02,  ...,  2.7114e-01,\n",
       "            1.6237e+00,  2.3621e+00],\n",
       "          [ 1.1890e+00,  9.3550e-01, -1.3214e+00,  ..., -3.0129e-01,\n",
       "           -1.4440e+00, -9.1792e-01],\n",
       "          [-3.1791e+00,  1.6183e+00, -3.0004e-01,  ..., -8.3434e-01,\n",
       "            1.9017e+00, -3.1985e+00],\n",
       "          ...,\n",
       "          [ 1.9938e+00,  1.4321e+00,  1.1994e+00,  ..., -5.1103e-02,\n",
       "           -1.4682e+00, -2.6936e+00],\n",
       "          [ 1.6458e+00,  1.8274e+00,  1.7930e+00,  ...,  3.5561e-01,\n",
       "           -2.7892e+00, -1.4437e+00],\n",
       "          [ 6.2127e-01,  1.1294e+00,  1.8890e+00,  ..., -8.8084e-01,\n",
       "           -2.8824e+00, -9.6353e-01]],\n",
       "\n",
       "         [[ 3.5516e-02,  2.2372e-02, -1.2581e-02,  ..., -2.6627e-02,\n",
       "           -8.0341e-01, -2.3250e+00],\n",
       "          [-2.5881e+00, -4.6878e-01,  3.0603e+00,  ..., -7.4793e-01,\n",
       "            2.7874e+00, -6.9678e-02],\n",
       "          [-2.6765e+00, -2.0924e+00,  2.3594e+00,  ...,  1.0592e+00,\n",
       "            1.2007e+00,  1.3969e+00],\n",
       "          ...,\n",
       "          [ 3.1878e+00, -8.1278e-02, -3.2101e+00,  ..., -2.5450e-01,\n",
       "            3.7932e+00,  1.5666e+00],\n",
       "          [ 7.1828e-01,  1.4349e+00, -2.0508e+00,  ..., -1.9208e+00,\n",
       "            1.6290e+00,  1.9757e+00],\n",
       "          [-1.5726e+00,  1.4330e+00,  9.9449e-02,  ..., -6.0444e-01,\n",
       "            1.7442e+00,  2.1850e+00]],\n",
       "\n",
       "         [[-8.5977e-03, -3.2651e-02, -1.2245e-02,  ..., -2.5749e+00,\n",
       "           -2.1820e-01,  6.6200e-01],\n",
       "          [-7.2977e-01, -1.2940e+00, -2.1427e-01,  ...,  1.4902e+00,\n",
       "            1.9941e-01,  1.6668e+00],\n",
       "          [ 5.8858e-01, -3.0829e-02, -8.5389e-01,  ...,  1.8907e+00,\n",
       "            1.0240e+00,  1.3083e-01],\n",
       "          ...,\n",
       "          [-4.0249e-01, -3.7072e-01, -1.7387e-01,  ...,  4.1383e+00,\n",
       "            1.4426e+00, -5.2991e-01],\n",
       "          [-1.2291e+00,  5.1168e-01,  7.5676e-01,  ...,  5.8071e+00,\n",
       "           -2.7868e-01,  1.1174e+00],\n",
       "          [-2.2747e-01,  7.0185e-01,  5.6522e-01,  ...,  4.6248e+00,\n",
       "            5.2072e-01,  3.0395e+00]]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>), tensor([[[[-8.9869e-03, -1.6469e-02,  1.5640e-03,  ..., -3.3024e-01,\n",
       "           -1.0705e-02,  1.8053e-02],\n",
       "          [-2.3845e-01,  3.1689e-01, -3.4420e-01,  ..., -8.1283e-01,\n",
       "            2.3936e-01,  2.2812e-01],\n",
       "          [-1.0694e-02,  5.6955e-01, -3.0147e-01,  ..., -5.8303e-01,\n",
       "            1.8971e-01, -4.7410e-02],\n",
       "          ...,\n",
       "          [-9.0872e-01,  8.1141e-01,  1.8543e-01,  ..., -1.0241e+00,\n",
       "            1.4329e+00, -1.9604e-01],\n",
       "          [-1.7222e-01,  2.8049e-01, -4.2835e-01,  ..., -1.0039e+00,\n",
       "           -4.0171e-01, -4.8584e-01],\n",
       "          [-2.1928e-01,  2.7211e-01, -8.8878e-01,  ..., -7.2919e-01,\n",
       "            1.9216e-01,  1.8266e-01]],\n",
       "\n",
       "         [[ 3.4268e-02, -4.5207e-02, -2.2760e-03,  ..., -2.0498e-02,\n",
       "            4.0293e-02,  5.3626e-03],\n",
       "          [-1.0080e-01, -3.8994e-01, -9.6887e-02,  ...,  8.5774e-03,\n",
       "            6.0695e-01, -2.4846e-03],\n",
       "          [-7.6743e-01, -5.8100e-04,  1.2550e-01,  ..., -4.1591e-01,\n",
       "           -1.8383e-01, -5.6103e-01],\n",
       "          ...,\n",
       "          [ 7.8315e-01, -2.3097e-01, -9.3160e-01,  ...,  4.5435e-02,\n",
       "           -3.1386e-01, -5.4629e-01],\n",
       "          [ 4.3234e-01, -4.4004e-01, -8.0751e-01,  ..., -5.7852e-01,\n",
       "           -6.6013e-02, -5.4204e-01],\n",
       "          [ 4.4489e-01, -1.0497e-01, -4.1108e-01,  ..., -7.0605e-01,\n",
       "            1.1204e-01, -4.0369e-01]],\n",
       "\n",
       "         [[-4.1616e-02,  3.9351e-02,  1.1111e-02,  ..., -1.2168e-02,\n",
       "           -3.8546e-03, -2.6303e-03],\n",
       "          [-1.2842e-01,  5.3821e-01,  4.4258e-01,  ...,  2.4951e-02,\n",
       "           -3.9734e-02, -2.6352e-03],\n",
       "          [-2.4495e-01,  3.8361e-01,  7.5698e-01,  ..., -3.2971e-01,\n",
       "           -1.6173e-01, -3.2824e-01],\n",
       "          ...,\n",
       "          [ 2.0297e-01,  7.3440e-01,  1.0889e-01,  ...,  1.6891e-01,\n",
       "            2.0424e-01,  7.8355e-01],\n",
       "          [ 6.4654e-01,  1.5018e-02,  5.0313e-01,  ...,  5.6245e-01,\n",
       "            4.7517e-01,  2.8496e-01],\n",
       "          [ 7.0491e-01, -4.2290e-01,  2.3204e-01,  ...,  6.3370e-03,\n",
       "            1.6334e-01,  1.8907e-01]],\n",
       "\n",
       "         [[-7.9474e-03, -3.6110e-02, -1.2243e-02,  ...,  1.1148e-02,\n",
       "            6.1077e-03, -5.9770e-05],\n",
       "          [ 2.8122e-01, -1.9470e+00,  1.9927e-01,  ...,  3.0870e-01,\n",
       "           -6.6497e-01,  1.6891e-01],\n",
       "          [-4.6401e-01, -4.9119e-01, -4.5904e-01,  ...,  6.3082e-01,\n",
       "           -2.7523e-01,  4.2457e-02],\n",
       "          ...,\n",
       "          [-5.1019e-01,  2.0943e-01, -4.5079e-01,  ...,  3.2189e-01,\n",
       "           -3.8896e-01,  2.0903e-01],\n",
       "          [-3.0343e-01,  1.1008e-01, -2.7746e-01,  ...,  1.9705e-01,\n",
       "           -3.5888e-01, -5.0030e-02],\n",
       "          [ 1.6587e-01, -4.0212e-01, -3.6038e-01,  ...,  2.2139e-01,\n",
       "           -8.6325e-01, -2.8893e-01]]]], device='cuda:0',\n",
       "       grad_fn=<TransposeBackward0>))), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LoRA_llama(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"attention_mask\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = LoRA_llama(**dict(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 384, 32002])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
