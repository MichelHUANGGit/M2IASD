{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The first cells of the notebook are the same as in the TP on text convolution. Apply the same preprocessing to get a dataset (with the same tokenizer) with a train and a validation split, with two columns review_ids (list of int) and label (int)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER** : Copying what we did in the TP on text convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version de pytorch :  2.3.0+cu121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tabulate import tabulate\n",
    "from datasets import load_dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "import functools\n",
    "from typing import Any\n",
    "import gc\n",
    "\n",
    "print(\"Version de pytorch : \", torch.__version__)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['review', 'sentiment'],\n",
      "    num_rows: 50000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"scikit-learn/imdb\", split=\"train\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of the tokenizer: <class 'collections.OrderedDict'>\n",
      "Length of the vocabulary: 30522\n",
      "OrderedDict({'[PAD]': 0, '[unused0]': 1, '[unused1\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of the tokenizer:\", type(tokenizer.vocab))\n",
    "VOCSIZE = len(tokenizer.vocab)\n",
    "print(\"Length of the vocabulary:\", VOCSIZE)\n",
    "print(str(tokenizer.vocab)[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_fn(x, tokenizer):\n",
    "    x[\"review_ids\"] = tokenizer(\n",
    "        x[\"review\"],\n",
    "        add_special_tokens=False,\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=False,\n",
    "    )[\"input_ids\"]\n",
    "    x[\"label\"] = 0 if x[\"sentiment\"] == \"negative\" else 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5000  # the number of training example\n",
    "\n",
    "# We first shuffle the data !\n",
    "dataset = dataset.shuffle(seed=0)\n",
    "\n",
    "# Select 5000 samples\n",
    "sampled_dataset = dataset.select(range(n_samples))\n",
    "\n",
    "# Tokenize the dataset\n",
    "sampled_dataset = sampled_dataset.map(\n",
    "    preprocessing_fn, fn_kwargs={\"tokenizer\" : tokenizer}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove useless columns\n",
    "sampled_dataset = sampled_dataset.select_columns(['review_ids','label'])\n",
    "\n",
    "# Split the train and validation\n",
    "splitted_dataset = sampled_dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "document_train_set = splitted_dataset['train']\n",
    "document_valid_set = splitted_dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a function extract_words_contexts. It should retrieve all pairs of valid $(w, C^+)$ from a list of ids representing a text document. It takes the radius $R$ as an argument. Its output is therefore two lists :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to make sure that every C has the same size, we add paddings at the beginning and the end of the sentence. For example the first word of the sentence, will have R paddings corresponding to the R tokens that should be before. We can also use the token itself, so that it has a high dot product with itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words_contexts(sample, R):\n",
    "    token_ids = sample[\"review_ids\"]\n",
    "    n_tokens = len(token_ids)\n",
    "    positive_context = []\n",
    "    token_ids_with_padding = [0]*R + token_ids + [0]*R\n",
    "    for i in range(n_tokens) :\n",
    "        # if out of bounds\n",
    "        if i<R or i>=n_tokens-R :\n",
    "            positive_context.append([token_ids_with_padding[i+r] for r in range(R)] + [token_ids_with_padding[i+R+r] for r in range(1,R+1, 1)])\n",
    "        else :\n",
    "            positive_context.append([token_ids[i+r] for r in range(-R, 0, 1)] + [token_ids[i+r] for r in range(1, R+1, 1)])\n",
    "            # positive_context.append([token_ids[i-R:i]] + [tokens_ids[i+1:i+R+1]])\n",
    "    return token_ids, positive_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "toto, test = extract_words_contexts(document_train_set[2], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 tokens : [2023, 2003, 4089, 2026, 8837]\n",
      "C+ of the first 5 tokens :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 2003, 4089, 2026],\n",
       " [0, 0, 2023, 4089, 2026, 8837],\n",
       " [0, 2023, 2003, 2026, 8837, 2143],\n",
       " [2023, 2003, 4089, 8837, 2143, 1012],\n",
       " [2003, 4089, 2026, 2143, 1012, 1037]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"First 5 tokens :\", toto[:5])\n",
    "print(\"C+ of the first 5 tokens :\")\n",
    "test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write a function flatten_dataset_to_list that applies the function extract_words_contexts on a whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dataset_to_list(dataset, R):\n",
    "    '''takes a dataset and returns the token_ids and positive context'''\n",
    "    token_ids = []\n",
    "    positive_contexts = []\n",
    "    for sample in dataset:\n",
    "        sample_token_ids, positive_context = extract_words_contexts(sample, R)\n",
    "        token_ids.append(sample_token_ids)\n",
    "        positive_contexts.append(positive_context)\n",
    "    return token_ids, positive_contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Apply the function to your initial document_train_set and document_valid_set, and get the corresponding flattened lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 2\n",
    "token_ids, positive_contexts = flatten_dataset_to_list(document_train_set, R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Embed these lists in two valid PyTorch Dataset, like in HW 1, call them train_set and valid_set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, document_set, R):\n",
    "        self.document_set = document_set\n",
    "        token_ids, positive_contexts = flatten_dataset_to_list(document_set, R)\n",
    "        self.token_ids = torch.tensor(token_ids)\n",
    "        self.positive_contexts = torch.tensor(positive_contexts)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"word_id\" : self.token_ids[idx], \n",
    "            \"positive_context_ids\" : self.positive_contexts[idx],\n",
    "            # \"label\" : torch.tensor(self.document_set[idx][\"label\"])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CustomDataset(document_train_set, R)\n",
    "valid_set = CustomDataset(document_valid_set, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_set), len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    valid_set[951], train_set[1347:-2000]\n",
    "except :\n",
    "    print(\"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Write a collate_fn function that adds the negative context to the batch. It should be parametrized by the scaling factor K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch, R, K, VOCSIZE):\n",
    "    ''' batch is a slice of the Dataset instance created above, of dictionaries with keys \"word_id\", \"positive_context_ids\" and \"label\" which contain tensors\n",
    "    What we want is that the output becomes a dictionary with keys :\n",
    "    - \"word_id\", which contains the all the token_ids for every review in the batch. It should be a tensor of shape (batch_size, n_tokens=256)\n",
    "    - \"positive_context_ids\", which contains the positive context of all tokens for every review in the batch. \n",
    "      It should be a tensor of shape (batch_size, n_tokens, 2R)\n",
    "    - \"negative_context_ids\", same thing for negative context. It should be a tensor of shape (batch_size, n_tokens, 2RK)\n",
    "    '''\n",
    "    batch_size = len(batch)\n",
    "    n_tokens = len(batch[0][\"word_id\"])\n",
    "    result = dict()\n",
    "    \n",
    "    result[\"word_id\"] = torch.stack([review[\"word_id\"] for review in batch])\n",
    "    result[\"positive_context_ids\"] = torch.stack([review[\"positive_context_ids\"] for review in batch])\n",
    "    # sample 2RK tokens from the vocabulary for each token in each review in the batch -> reshape it -> convert to a tensor\n",
    "    result[\"negative_context_ids\"] = torch.tensor(\n",
    "        np.random.choice(np.arange(VOCSIZE), 2*R*K*n_tokens*batch_size, replace=True)\\\n",
    "            .reshape(batch_size, n_tokens, 2*R*K)\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Wraps everything in a DataLoader, like in HW 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "R = 2\n",
    "K = 2\n",
    "collate_fn_with_params = functools.partial(collate_fn, R=R, K=K, VOCSIZE=VOCSIZE)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_set, batch_size=batch_size, collate_fn=collate_fn_with_params\n",
    ")   \n",
    "valid_dataloader = DataLoader(\n",
    "    valid_set, batch_size=batch_size, collate_fn=collate_fn_with_params\n",
    ")\n",
    "n_valid = len(valid_set)\n",
    "n_train = len(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Make 2 or 3 three iterations in the DataLoader and print R, K and the shapes of all the tensors in the batches (let the output be visible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R = 2\n",
      "K = 2\n",
      "batch 0 :\n",
      "dict_keys(['word_id', 'positive_context_ids', 'negative_context_ids'])\n",
      "'word_id' shape : torch.Size([32, 256])\n",
      "'positive_context_ids' shape : torch.Size([32, 256, 4])\n",
      "'negative_context_ids' shape : torch.Size([32, 256, 8])\n",
      "--------------------------------------------------\n",
      "batch 1 :\n",
      "dict_keys(['word_id', 'positive_context_ids', 'negative_context_ids'])\n",
      "'word_id' shape : torch.Size([32, 256])\n",
      "'positive_context_ids' shape : torch.Size([32, 256, 4])\n",
      "'negative_context_ids' shape : torch.Size([32, 256, 8])\n",
      "--------------------------------------------------\n",
      "batch 2 :\n",
      "dict_keys(['word_id', 'positive_context_ids', 'negative_context_ids'])\n",
      "'word_id' shape : torch.Size([32, 256])\n",
      "'positive_context_ids' shape : torch.Size([32, 256, 4])\n",
      "'negative_context_ids' shape : torch.Size([32, 256, 8])\n",
      "--------------------------------------------------\n",
      "batch 3 :\n",
      "dict_keys(['word_id', 'positive_context_ids', 'negative_context_ids'])\n",
      "'word_id' shape : torch.Size([32, 256])\n",
      "'positive_context_ids' shape : torch.Size([32, 256, 4])\n",
      "'negative_context_ids' shape : torch.Size([32, 256, 8])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"R =\", R)\n",
    "print(\"K =\", K)\n",
    "\n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    print(f\"batch {i} :\")\n",
    "    print(batch.keys())\n",
    "    for key, value in batch.items():\n",
    "        print(f\"'{key}' shape :\", value.shape)\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    if i > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Write a model named Word2Vec which is a valid torch.nn.Module (i.e.,\n",
    "write a class that inherits from the torch.nn.Module), and implement the\n",
    "Word2Vec model. It should be parametrized by the vocabulary size and\n",
    "the embeddings dimension. Use the module torch.nn.Embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to that model should directly output the similarity, not just the embeddings :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, VOCSIZE, emb_dim, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.VOCSIZE = VOCSIZE\n",
    "        self.emb_dim = emb_dim\n",
    "        self.emb = torch.nn.Embedding(self.VOCSIZE, self.emb_dim, padding_idx=0)\n",
    "    \n",
    "    def similarity(self, word_emb, context_emb):\n",
    "        '''[Not used outside of the class] Takes the word embeddings, the context_embeddings\n",
    "        and compute the dot product between each word embedding and its context embeddings\n",
    "        word_emb : (B,L,D) = (batch_size, max_length, embedding_dim)\n",
    "        context_emb : (B,L,C,D)\n",
    "        output : (B,L,C)\n",
    "        '''\n",
    "        word_emb_expanded = word_emb.unsqueeze(2) # (B,L,D) -> (B,L,1,D)\n",
    "        context_emb_transposed = context_emb.transpose(-1,-2) #(B,L,C,D) -> (B,L,D,C)\n",
    "        return torch.matmul(word_emb_expanded, context_emb_transposed).squeeze(2) # (B,L,1,D) @ (B,L,D,C) -> (B,L,1,C) -> squeezed into (B,L,C)\n",
    "    \n",
    "    def __call__(self, input:dict):\n",
    "        embeddings = dict()\n",
    "        for k,v in input.items():\n",
    "            embeddings[k] = self.emb(v)\n",
    "        positive_similarity = self.similarity(embeddings[\"word_id\"], embeddings[\"positive_context_ids\"])\n",
    "        negative_similarity = self.similarity(embeddings[\"word_id\"], embeddings[\"negative_context_ids\"])\n",
    "        return {\"positive_similarity\":positive_similarity, \"negative_similarity\":negative_similarity}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick sanity check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM = 50\n",
    "VOCSIZE = tokenizer.vocab_size\n",
    "model = Word2Vec(VOCSIZE, EMB_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['positive_similarity', 'negative_similarity'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(batch)\n",
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 256, 4]), torch.Size([32, 256, 8]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"positive_similarity\"].shape, out[\"negative_similarity\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Train the model. The training should be parametrized by the batch size B, and the number of epochs E.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we denote $y = \\mathbb{1}_{c \\in \\mathcal{C}^+}$, then our loss can be seen as a binary cross-entropy loss :\n",
    "$$ \\frac{1}{n} \\sum_{i=1}^n - [y_i \\log(x_i) + (1-y_i) \\log(1-x_i)]$$ \n",
    "where $x_i$ is $\\sigma(w_i \\cdot c_i)$. <br>\n",
    "Therefore we can use the torch module BCEWithLogitLoss :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.BCELoss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def __call__(self, positive_similarity, negative_similarity):\n",
    "        '''computes the loss'''\n",
    "        # Positive context\n",
    "        y_positive = torch.ones_like(positive_similarity, dtype=torch.float32)\n",
    "        loss = self.BCELoss(positive_similarity, y_positive)\n",
    "\n",
    "        # Negative context\n",
    "        y_negative = torch.zeros_like(negative_similarity, dtype=torch.float32)\n",
    "        loss += self.BCELoss(negative_similarity, y_negative)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyLoss = CustomLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.2419, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyLoss(**out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word2Vec(\n",
       "  (emb): Embedding(30522, 50, padding_idx=0)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, valid_dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    loss_total = 0.\n",
    "    acc = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_dataloader):\n",
    "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "            output = model(batch)\n",
    "            loss = loss_fn(**output)\n",
    "            loss_total += loss.detach().cpu().item()\n",
    "            total_predictions = output[\"positive_similarity\"].shape.numel() + output[\"negative_similarity\"].shape.numel()\n",
    "            acc += ((torch.sum(output[\"positive_similarity\"]>0)+torch.sum(output[\"negative_similarity\"]<=0))/total_predictions).cpu().item()\n",
    "    return loss_total / len(valid_dataloader), acc / len(valid_dataloader)\n",
    "\n",
    "# validation(model, valid_dataloader, MyLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, lr, E, B, loss_fn, train_dataloader, valid_dataloader, writer):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Performance metric tracking\n",
    "    list_val_acc = []\n",
    "    list_train_acc = []\n",
    "    list_train_loss = []\n",
    "    list_val_loss = []\n",
    "\n",
    "    for e in range(E):\n",
    "        # ========== Training ==========\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        acc = 0.\n",
    "        for batch in tqdm(train_dataloader):\n",
    "            batch = {k:v.to(DEVICE) for k,v in batch.items()}\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch)\n",
    "            loss = loss_fn(**output)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.detach().cpu().item()\n",
    "            total_predictions = output[\"positive_similarity\"].shape.numel() + output[\"negative_similarity\"].shape.numel()\n",
    "            acc += ((torch.sum(output[\"positive_similarity\"]>0)+torch.sum(output[\"negative_similarity\"]<=0))/total_predictions).cpu().item()\n",
    "        list_train_loss.append(train_loss / len(train_dataloader))\n",
    "        list_train_acc.append(100 * acc / len(train_dataloader))\n",
    "\n",
    "        # ========== Validation ==========\n",
    "        l, a = validation(model, valid_dataloader, loss_fn)\n",
    "        list_val_loss.append(l)\n",
    "        list_val_acc.append(a * 100)\n",
    "\n",
    "        # ========== Metric Tracking =========\n",
    "        writer.add_scalar(\"Train loss\", list_train_loss[-1], e)\n",
    "        writer.add_scalar(\"Val loss\", l, e)\n",
    "        writer.add_scalar(\"Train acc\", list_train_acc[-1], e)\n",
    "        writer.add_scalar(\"Val acc\", a, e)\n",
    "        print(\n",
    "            e,\n",
    "            \"\\n\\t - Train loss: {:.4f}\".format(list_train_loss[-1]),\n",
    "            \"Train acc: {:.4f}\".format(list_train_acc[-1]),\n",
    "            \"Val loss: {:.4f}\".format(l),\n",
    "            \"Val acc:{:.4f}\".format(a * 100),\n",
    "        )\n",
    "    return list_train_loss, list_train_acc, list_val_loss, list_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word2Vec(\n",
       "  (emb): Embedding(30522, 50, padding_idx=0)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:04<00:00, 30.67it/s] \n",
      "100%|██████████| 32/32 [00:00<00:00, 326.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "\t - Train loss: 4.8865 Train acc: 53.8097 Val loss: 4.7038 Val acc:54.0156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:01<00:00, 111.14it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 332.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "\t - Train loss: 4.5636 Train acc: 54.3602 Val loss: 4.4091 Val acc:54.7579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:01<00:00, 120.79it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 376.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \n",
      "\t - Train loss: 4.2785 Train acc: 55.0003 Val loss: 4.1590 Val acc:55.3108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:00<00:00, 157.67it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 383.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \n",
      "\t - Train loss: 4.0283 Train acc: 55.6695 Val loss: 3.9241 Val acc:55.9890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:00<00:00, 152.67it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 395.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 \n",
      "\t - Train loss: 3.8011 Train acc: 56.3894 Val loss: 3.7134 Val acc:56.6635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:00<00:00, 144.11it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 450.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 \n",
      "\t - Train loss: 3.5912 Train acc: 57.1555 Val loss: 3.5164 Val acc:57.4964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:00<00:00, 150.23it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 464.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 \n",
      "\t - Train loss: 3.3986 Train acc: 57.9803 Val loss: 3.3434 Val acc:58.2111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:00<00:00, 153.61it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 443.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 \n",
      "\t - Train loss: 3.2186 Train acc: 58.8280 Val loss: 3.1721 Val acc:59.0767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:00<00:00, 157.74it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 444.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 \n",
      "\t - Train loss: 3.0508 Train acc: 59.6667 Val loss: 3.0216 Val acc:59.8398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:00<00:00, 151.97it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 415.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 \n",
      "\t - Train loss: 2.8950 Train acc: 60.5070 Val loss: 2.8733 Val acc:60.6737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "E = 10\n",
    "lr = 5e-4\n",
    "B=32\n",
    "writer = SummaryWriter(\"runs/TestWord2Vec\")\n",
    "list_train_loss, list_train_acc, list_val_loss, list_val_acc = training(\n",
    "    model=model, \n",
    "    lr=lr,\n",
    "    E=E, \n",
    "    B=B, \n",
    "    loss_fn=MyLoss, \n",
    "    train_dataloader=train_dataloader, \n",
    "    valid_dataloader=valid_dataloader,\n",
    "    writer=writer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11. Validates its accuracy on the test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:01<00:00, 22.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.871535398066044, 0.607081750407815)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation(model, valid_dataloader, MyLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no sign of overfitting yet, the model clearly hasn't finished training yet !\n",
    "Let's take a look at the dot product of a few tokens :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_similarity(model, w, Cplus, Cminus):\n",
    "    token1_id = tokenizer.convert_tokens_to_ids(w)\n",
    "    token2_id = tokenizer.convert_tokens_to_ids(Cplus)\n",
    "    R = len(token2_id) if isinstance(token2_id, list) else 1\n",
    "    token3_id = tokenizer.convert_tokens_to_ids(Cminus)\n",
    "    RK = len(token3_id) if isinstance(token3_id, list) else 1\n",
    "    model_input = {\n",
    "        \"word_id\":torch.tensor([token1_id]).view(1,1,1).cuda(), \n",
    "        \"positive_context_ids\":torch.tensor([token2_id]).view(1,1,R).cuda(),\n",
    "        \"negative_context_ids\":torch.tensor([token3_id]).view(1,1,RK).cuda()\n",
    "    }\n",
    "    # print(model_input)\n",
    "    with torch.no_grad():\n",
    "        return model(model_input)\n",
    "\n",
    "# test_similarity(model, \"I\", [\"am\"], \"earth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive_similarity': tensor([[[[4.2176, 0.3346, 7.9493]]]], device='cuda:0'),\n",
       " 'negative_similarity': tensor([[[[2.3552, 0.5468, 0.7110]]]], device='cuda:0')}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_similarity(model, \"good\", [\"movie\",\"actor\",\"story\"], [\"random\",\"maths\",\"physics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some embeddings seem to be well learned already, some not so much, for example \"I\" and \"earth\" have a positive dot product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12. Write a function save_model that saves the model’s embeddings in a file.** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, root):\n",
    "    embeddings = model.emb.weight\n",
    "    model_filepath = root + f\"model_dim-{model.emb_dim}_radius-{R}_ratio-{K}-batch-{B}-epoch-{E}.ckpt\"\n",
    "    torch.save(embeddings, model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, \"runs/TestWord2Vec/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13. Once you have a working code, you can launch a bigger training, using more documents, if it does not take too much time.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the full dataset with 50k reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shuffle(seed=0)\n",
    "full_dataset = dataset.select_columns([\"review\", \"sentiment\"])\n",
    "full_dataset = full_dataset.map(\n",
    "    preprocessing_fn, fn_kwargs={\"tokenizer\" : tokenizer}\n",
    ")\n",
    "splitted_dataset = full_dataset.train_test_split(0.2)\n",
    "document_train_set = splitted_dataset[\"train\"]\n",
    "document_valid_set = splitted_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "R=4\n",
    "K=2\n",
    "B=32\n",
    "E=20\n",
    "VOCSIZE=tokenizer.vocab_size\n",
    "D=200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~1 min execution\n",
    "train_set = CustomDataset(document_train_set, R)\n",
    "valid_set = CustomDataset(document_valid_set, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn_with_params = functools.partial(collate_fn, R=R, K=K, VOCSIZE=VOCSIZE)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_set, batch_size=B, collate_fn=collate_fn_with_params\n",
    ")   \n",
    "valid_dataloader = DataLoader(\n",
    "    valid_set, batch_size=B, collate_fn=collate_fn_with_params\n",
    ")\n",
    "n_valid = len(valid_set)\n",
    "n_train = len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word2Vec(\n",
       "  (emb): Embedding(30522, 200, padding_idx=0)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(VOCSIZE, D)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:26<00:00, 47.96it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 159.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "\t - Train loss: 2.6022 Train acc: 73.0679 Val loss: 1.3543 Val acc:77.1392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:24<00:00, 51.86it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 162.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "\t - Train loss: 1.1310 Train acc: 78.0302 Val loss: 1.0160 Val acc:78.4675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:23<00:00, 52.28it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 164.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \n",
      "\t - Train loss: 0.9422 Train acc: 78.7656 Val loss: 0.9137 Val acc:78.8742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:22<00:00, 56.66it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 188.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \n",
      "\t - Train loss: 0.8765 Train acc: 79.1537 Val loss: 0.8689 Val acc:79.2169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:19<00:00, 62.79it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 191.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 \n",
      "\t - Train loss: 0.8457 Train acc: 79.4206 Val loss: 0.8462 Val acc:79.4163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:20<00:00, 60.89it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 174.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 \n",
      "\t - Train loss: 0.8286 Train acc: 79.5983 Val loss: 0.8342 Val acc:79.5770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:20<00:00, 62.09it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 180.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 \n",
      "\t - Train loss: 0.8180 Train acc: 79.7322 Val loss: 0.8285 Val acc:79.6508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:20<00:00, 61.00it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 151.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 \n",
      "\t - Train loss: 0.8112 Train acc: 79.8158 Val loss: 0.8255 Val acc:79.7019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:21<00:00, 58.53it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 192.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 \n",
      "\t - Train loss: 0.8063 Train acc: 79.8783 Val loss: 0.8250 Val acc:79.7218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:20<00:00, 60.73it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 194.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 \n",
      "\t - Train loss: 0.8024 Train acc: 79.9321 Val loss: 0.8248 Val acc:79.7348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:20<00:00, 61.53it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 197.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 \n",
      "\t - Train loss: 0.7993 Train acc: 79.9813 Val loss: 0.8248 Val acc:79.7569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:21<00:00, 58.78it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 162.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 \n",
      "\t - Train loss: 0.7967 Train acc: 80.0266 Val loss: 0.8247 Val acc:79.7838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:20<00:00, 61.45it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 170.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 \n",
      "\t - Train loss: 0.7949 Train acc: 80.0650 Val loss: 0.8250 Val acc:79.7915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:20<00:00, 61.46it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 159.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 \n",
      "\t - Train loss: 0.7935 Train acc: 80.0929 Val loss: 0.8254 Val acc:79.8065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:21<00:00, 57.87it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 195.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 \n",
      "\t - Train loss: 0.7924 Train acc: 80.1114 Val loss: 0.8252 Val acc:79.8109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:20<00:00, 60.76it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 149.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 \n",
      "\t - Train loss: 0.7915 Train acc: 80.1257 Val loss: 0.8255 Val acc:79.8221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:20<00:00, 59.90it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 193.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 \n",
      "\t - Train loss: 0.7909 Train acc: 80.1380 Val loss: 0.8257 Val acc:79.8161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:21<00:00, 57.13it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 197.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 \n",
      "\t - Train loss: 0.7902 Train acc: 80.1445 Val loss: 0.8259 Val acc:79.8237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:20<00:00, 60.02it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 174.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 \n",
      "\t - Train loss: 0.7897 Train acc: 80.1612 Val loss: 0.8260 Val acc:79.8328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:20<00:00, 61.27it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 166.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 \n",
      "\t - Train loss: 0.7893 Train acc: 80.1703 Val loss: 0.8262 Val acc:79.8325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lr=5e-3\n",
    "writer = SummaryWriter(\"runs/Word2Vec_v1\")\n",
    "\n",
    "list_train_loss, list_train_acc, list_val_loss, list_val_acc = training(\n",
    "    model=model, \n",
    "    lr=lr,\n",
    "    E=E, \n",
    "    B=B, \n",
    "    loss_fn=MyLoss, \n",
    "    train_dataloader=train_dataloader, \n",
    "    valid_dataloader=valid_dataloader,\n",
    "    writer=writer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list_train_acc, label=\"train\")\n",
    "plt.plot(list_val_acc, label=\"val\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.legend()\n",
    "plt.xticks(range(0,E,3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performance plateaus at 80% accuracy, it overfits after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive_similarity': tensor([[[[7.4358, 4.2657, 5.6937]]]], device='cuda:0'),\n",
       " 'negative_similarity': tensor([[[[ 1.1374, -5.7729, -1.3434]]]], device='cuda:0')}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_similarity(model, \"good\", [\"movie\",\"actor\",\"story\"], [\"random\",\"maths\",\"physics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'positive_similarity': tensor([[[[ 4.0833,  4.2657,  3.1083,  2.4544,  4.4783,  2.3907, 10.0830]]]],\n",
      "       device='cuda:0'), 'negative_similarity': tensor([[[[-1.3646, -1.5742,  0.0000,  2.7094, -5.9168, -5.9168, -2.2380]]]],\n",
      "       device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "print(test_similarity(\n",
    "    model, \n",
    "    w=\"actor\", \n",
    "    Cplus=[\"bad\",\"good\",\"terrible\",\"handsome\",\"great\",\"absolutely\", \"actor\"], \n",
    "    Cminus=[\"mathematician\",\"robotic\",\"[PAD]\",\"?\",\"Newton\",\"stochastic\",\"reinforcement\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a good model should have negative values for words in $C^-$ and positive for $C^+$. Interestingly enough, the token \"[PAD]\", has a null dot product with every word. This is because we used it as a placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, root=\"runs/Word2Vec_v1/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try different things : \n",
    "- for tokens at the beginning and end of the reviews, we will add the token itself as their positive context instead of \"[PAD]\". <br>\n",
    "  For example the review \"I liked this movie\" should have (for the word \"I\" and R=2) $C^+ =$  [\"I\", \"I\", \"I\", \"liked\", \"this\"]. <br>\n",
    "  So that the dot product of a token with itself is high. Using \"[PAD]\" forces every tokens at the beginning of the reviews, to have a high similarity with \"[PAD]\", which is not necessarily what we want.\n",
    "- Reduce the embedding dimension. As we've seen, there is a little bit of overfitting, reducing the size of the embeddings will simplify the model a little bit and reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1802"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "R=4\n",
    "K=2\n",
    "B=32\n",
    "E=20\n",
    "VOCSIZE=tokenizer.vocab_size\n",
    "D=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shuffle(seed=1)\n",
    "full_dataset = dataset.select_columns([\"review\", \"sentiment\"])\n",
    "full_dataset = full_dataset.map(\n",
    "    preprocessing_fn, fn_kwargs={\"tokenizer\" : tokenizer}\n",
    ")\n",
    "splitted_dataset = full_dataset.train_test_split(0.2)\n",
    "document_train_set = splitted_dataset[\"train\"]\n",
    "document_valid_set = splitted_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words_contexts(sample, R):\n",
    "    token_ids = sample[\"review_ids\"]\n",
    "    n_tokens = len(token_ids)\n",
    "    positive_context = []\n",
    "    for i in range(n_tokens):\n",
    "        # if at the beginning\n",
    "        if i<R:\n",
    "            positive_context.append([token_ids[i]]*(R-i) + [token_ids[i+r] for r in range(-i,R+1, 1) if r!=0])\n",
    "        elif i>=n_tokens-R:\n",
    "            positive_context.append([token_ids[i+r] for r in range(-R, n_tokens-i, 1) if r!=0] + [token_ids[i]]*(i-n_tokens+R+1))\n",
    "        else:\n",
    "            positive_context.append([token_ids[i+r] for r in range(-R, R+1, 1) if r!=0])\n",
    "    return token_ids, positive_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dataset_to_list(dataset, R):\n",
    "    '''takes a dataset and returns the token_ids and positive context'''\n",
    "    token_ids = []\n",
    "    positive_contexts = []\n",
    "    for sample in dataset:\n",
    "        sample_token_ids, positive_context = extract_words_contexts(sample, R)\n",
    "        token_ids.append(sample_token_ids)\n",
    "        positive_contexts.append(positive_context)\n",
    "    return token_ids, positive_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, document_set, R):\n",
    "        self.document_set = document_set\n",
    "        token_ids, positive_contexts = flatten_dataset_to_list(document_set, R)\n",
    "        self.token_ids = torch.tensor(token_ids)\n",
    "        self.positive_contexts = torch.tensor(positive_contexts)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"word_id\" : self.token_ids[idx], \n",
    "            \"positive_context_ids\" : self.positive_contexts[idx],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ 1 min exec\n",
    "train_set = CustomDataset(document_train_set, R)\n",
    "valid_set = CustomDataset(document_valid_set, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First word of the first review : tensor(2757)\n",
      "its positive context : tensor([2757, 2757, 2757, 2757, 2030, 4142, 1024, 2345])\n",
      "Last word of the first review : tensor(4523)\n",
      "its positive context : tensor([ 1011, 13077, 28616,  3270,  4523,  4523,  4523,  4523])\n"
     ]
    }
   ],
   "source": [
    "id = 700\n",
    "print(\"First word of the first review :\", train_set[id][\"word_id\"][0])\n",
    "print(\"its positive context :\", train_set[id][\"positive_context_ids\"][0])\n",
    "print(\"Last word of the first review :\", train_set[id][\"word_id\"][-1])\n",
    "print(\"its positive context :\", train_set[id][\"positive_context_ids\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn_with_params = functools.partial(collate_fn, R=R, K=K, VOCSIZE=VOCSIZE)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_set, batch_size=B, collate_fn=collate_fn_with_params\n",
    ")   \n",
    "valid_dataloader = DataLoader(\n",
    "    valid_set, batch_size=B, collate_fn=collate_fn_with_params\n",
    ")\n",
    "n_valid = len(valid_set)\n",
    "n_train = len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, E, loss_fn, optimizer, train_dataloader, valid_dataloader, writer):\n",
    "\n",
    "    # Performance metric tracking\n",
    "    list_val_acc = []\n",
    "    list_train_acc = []\n",
    "    list_train_loss = []\n",
    "    list_val_loss = []\n",
    "\n",
    "    for e in range(E):\n",
    "        # ========== Training ==========\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        acc = 0.\n",
    "        for batch in tqdm(train_dataloader):\n",
    "            batch = {k:v.to(DEVICE) for k,v in batch.items()}\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch)\n",
    "            loss = loss_fn(**output)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.detach().cpu().item()\n",
    "            total_predictions = output[\"positive_similarity\"].shape.numel() + output[\"negative_similarity\"].shape.numel()\n",
    "            acc += ((torch.sum(output[\"positive_similarity\"]>0)+torch.sum(output[\"negative_similarity\"]<=0))/total_predictions).cpu().item()\n",
    "        list_train_loss.append(train_loss / len(train_dataloader))\n",
    "        list_train_acc.append(100 * acc / len(train_dataloader))\n",
    "\n",
    "        # ========== Validation ==========\n",
    "        l, a = validation(model, valid_dataloader, loss_fn)\n",
    "        list_val_loss.append(l)\n",
    "        list_val_acc.append(a * 100)\n",
    "        # Tensorboard\n",
    "        writer.add_scalar(\"Train loss\", list_train_loss[-1], e)\n",
    "        writer.add_scalar(\"Val loss\", l, e)\n",
    "        writer.add_scalar(\"Train acc\", list_train_acc[-1], e)\n",
    "        writer.add_scalar(\"Val acc\", a, e)\n",
    "        print(\n",
    "            e,\n",
    "            \"\\n\\t - Train loss: {:.4f}\".format(list_train_loss[-1]),\n",
    "            \"Train acc: {:.4f}\".format(list_train_acc[-1]),\n",
    "            \"Val loss: {:.4f}\".format(l),\n",
    "            \"Val acc:{:.4f}\".format(a * 100),\n",
    "        )\n",
    "    return list_train_loss, list_train_acc, list_val_loss, list_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word2Vec(\n",
       "  (emb): Embedding(30522, 100, padding_idx=0)\n",
       ")"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(VOCSIZE, D)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyLoss = CustomLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:12<00:00, 101.44it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 268.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "\t - Train loss: 1.8682 Train acc: 73.3845 Val loss: 1.0477 Val acc:77.7433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:12<00:00, 100.81it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 257.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "\t - Train loss: 0.9473 Train acc: 78.4864 Val loss: 0.8912 Val acc:78.9585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:12<00:00, 100.82it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 246.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \n",
      "\t - Train loss: 0.8657 Train acc: 79.0669 Val loss: 0.8499 Val acc:79.3005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:12<00:00, 97.80it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 210.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \n",
      "\t - Train loss: 0.8370 Train acc: 79.4819 Val loss: 0.8305 Val acc:79.6722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:12<00:00, 100.57it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 265.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 \n",
      "\t - Train loss: 0.8221 Train acc: 79.7344 Val loss: 0.8210 Val acc:79.8445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:12<00:00, 102.60it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 260.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 \n",
      "\t - Train loss: 0.8131 Train acc: 79.8943 Val loss: 0.8156 Val acc:79.9603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:12<00:00, 100.22it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 236.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 \n",
      "\t - Train loss: 0.8071 Train acc: 80.0096 Val loss: 0.8125 Val acc:80.0452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:12<00:00, 97.56it/s] \n",
      "100%|██████████| 313/313 [00:01<00:00, 265.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 \n",
      "\t - Train loss: 0.8028 Train acc: 80.0914 Val loss: 0.8111 Val acc:80.0869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:12<00:00, 102.48it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 262.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 \n",
      "\t - Train loss: 0.7997 Train acc: 80.1422 Val loss: 0.8107 Val acc:80.1128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:12<00:00, 100.09it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 237.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 \n",
      "\t - Train loss: 0.7971 Train acc: 80.1878 Val loss: 0.8105 Val acc:80.1309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:12<00:00, 100.73it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 268.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 \n",
      "\t - Train loss: 0.7952 Train acc: 80.2184 Val loss: 0.8105 Val acc:80.1593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:12<00:00, 97.79it/s] \n",
      "100%|██████████| 313/313 [00:01<00:00, 269.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 \n",
      "\t - Train loss: 0.7935 Train acc: 80.2497 Val loss: 0.8101 Val acc:80.1846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:12<00:00, 102.30it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 274.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 \n",
      "\t - Train loss: 0.7922 Train acc: 80.2747 Val loss: 0.8104 Val acc:80.1985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:12<00:00, 97.45it/s] \n",
      "100%|██████████| 313/313 [00:01<00:00, 265.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 \n",
      "\t - Train loss: 0.7909 Train acc: 80.2999 Val loss: 0.8105 Val acc:80.1973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:12<00:00, 101.25it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 234.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 \n",
      "\t - Train loss: 0.7901 Train acc: 80.3132 Val loss: 0.8103 Val acc:80.2170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:12<00:00, 99.16it/s] \n",
      "100%|██████████| 313/313 [00:01<00:00, 267.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 \n",
      "\t - Train loss: 0.7892 Train acc: 80.3317 Val loss: 0.8106 Val acc:80.2231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:12<00:00, 97.40it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 203.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 \n",
      "\t - Train loss: 0.7887 Train acc: 80.3420 Val loss: 0.8103 Val acc:80.2385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:12<00:00, 96.98it/s] \n",
      "100%|██████████| 313/313 [00:01<00:00, 257.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 \n",
      "\t - Train loss: 0.7880 Train acc: 80.3533 Val loss: 0.8108 Val acc:80.2409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 32/1250 [00:00<00:13, 87.91it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m exp_decay_lr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mExponentialLR(Adam, \u001b[38;5;241m0.9\u001b[39m)\n\u001b[0;32m      4\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns/Word2Vec_v2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m list_train_loss, list_train_acc, list_val_loss, list_val_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mE\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMyLoss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp_decay_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[115], line 22\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(model, E, loss_fn, optimizer, scheduler, train_dataloader, valid_dataloader, writer)\u001b[0m\n\u001b[0;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# scheduler.step()\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     23\u001b[0m total_predictions \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositive_similarity\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m+\u001b[39m output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative_similarity\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[0;32m     24\u001b[0m acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ((torch\u001b[38;5;241m.\u001b[39msum(output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositive_similarity\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m+\u001b[39mtorch\u001b[38;5;241m.\u001b[39msum(output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative_similarity\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m/\u001b[39mtotal_predictions)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr=5e-3\n",
    "Adam = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "writer = SummaryWriter(\"runs/Word2Vec_v2\")\n",
    "\n",
    "list_train_loss, list_train_acc, list_val_loss, list_val_acc = training(\n",
    "    model=model,\n",
    "    E=E,\n",
    "    loss_fn=MyLoss,\n",
    "    optimizer=Adam,\n",
    "    train_dataloader=train_dataloader, \n",
    "    valid_dataloader=valid_dataloader,\n",
    "    writer=writer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems slightly better, but not much better either, there is still some overfitting. But we reduced the embedding dimension from 200 to 100 while maintaining the same performance, which is good !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_token_id = tokenizer.pad_token_id\n",
    "print(pad_token_id)\n",
    "model.emb.weight[pad_token_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason \"[PAD]\" had a null dot product with every tokens was because it's the null vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "2537\n",
      "1117\n",
      "1537\n",
      "679\n",
      "690\n",
      "857\n",
      "1571\n",
      "775\n",
      "691\n",
      "860\n",
      "865\n"
     ]
    }
   ],
   "source": [
    "for i,sample in enumerate(dataset):\n",
    "    print(len(sample[\"review\"]))\n",
    "    if i>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255.26204"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.clip([len(sample[\"review\"]) for sample in dataset], 0, 256).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:01<00:00, 212.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8103908273739556, 0.8022715778777394)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(validation(model, valid_dataloader, MyLoss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if in the accuracy we slightly modify the definition :\n",
    "- if the dot product is exactly 0, then the prediction is \"positive\" (1)\n",
    "- before, if the dot product was 0, then the prediction would be \"negative\" (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation2(model, valid_dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    loss_total = 0.\n",
    "    acc = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_dataloader):\n",
    "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "            output = model(batch)\n",
    "            loss = loss_fn(**output)\n",
    "            loss_total += loss.detach().cpu().item()\n",
    "            total_predictions = output[\"positive_similarity\"].shape.numel() + output[\"negative_similarity\"].shape.numel()\n",
    "            acc += ((torch.sum(output[\"positive_similarity\"]>=0)+torch.sum(output[\"negative_similarity\"]<0))/total_predictions).cpu().item()\n",
    "    return loss_total / len(valid_dataloader), acc / len(valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:01<00:00, 210.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8112295610836139, 0.7381510730749502)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(validation2(model, valid_dataloader, MyLoss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss is roughly the same, but the accuracy metric drops by 6%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'positive_similarity': tensor([[[[3.5665, 4.3642, 2.9271, 2.0463, 4.4855, 2.6258, 6.8280]]]],\n",
      "       device='cuda:0'), 'negative_similarity': tensor([[[[-1.8789, -0.7771,  0.0000,  2.6950, -5.0612, -5.0612, -3.1894]]]],\n",
      "       device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "print(test_similarity(\n",
    "    model, \n",
    "    w=\"actor\", \n",
    "    Cplus=[\"bad\",\"good\",\"terrible\",\"handsome\",\"great\",\"absolutely\", \"actor\"], \n",
    "    Cminus=[\"mathematician\",\"robotic\",\"[PAD]\",\"?\",\"Newton\",\"stochastic\",\"reinforcement\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, root=\"runs/Word2Vec_v2/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third model : bigger radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "R=8\n",
    "K=1\n",
    "B=32\n",
    "E=20\n",
    "VOCSIZE=tokenizer.vocab_size\n",
    "D=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CustomDataset(document_train_set, R)\n",
    "valid_set = CustomDataset(document_valid_set, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn_with_params = functools.partial(collate_fn, R=R, K=K, VOCSIZE=VOCSIZE)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_set, batch_size=B, collate_fn=collate_fn_with_params\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_set, batch_size=B, collate_fn=collate_fn_with_params\n",
    ")\n",
    "n_valid = len(valid_set)\n",
    "n_train = len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word2Vec(\n",
       "  (emb): Embedding(30522, 100, padding_idx=0)\n",
       ")"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(VOCSIZE, D)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 84.38it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 218.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "\t - Train loss: 1.8248 Train acc: 71.9160 Val loss: 1.0217 Val acc:75.8286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 86.59it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 227.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "\t - Train loss: 0.9359 Train acc: 76.4304 Val loss: 0.8921 Val acc:76.6528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 84.71it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 216.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \n",
      "\t - Train loss: 0.8687 Train acc: 76.8612 Val loss: 0.8573 Val acc:76.9228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 86.95it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 226.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \n",
      "\t - Train loss: 0.8446 Train acc: 77.1330 Val loss: 0.8417 Val acc:77.1377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 86.65it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 221.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 \n",
      "\t - Train loss: 0.8327 Train acc: 77.2830 Val loss: 0.8338 Val acc:77.2381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 86.94it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 205.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 \n",
      "\t - Train loss: 0.8255 Train acc: 77.3814 Val loss: 0.8291 Val acc:77.3232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 85.13it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 234.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 \n",
      "\t - Train loss: 0.8207 Train acc: 77.4514 Val loss: 0.8268 Val acc:77.3619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 87.50it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 231.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 \n",
      "\t - Train loss: 0.8174 Train acc: 77.4984 Val loss: 0.8257 Val acc:77.3814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 87.18it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 222.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 \n",
      "\t - Train loss: 0.8143 Train acc: 77.5470 Val loss: 0.8255 Val acc:77.3883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 86.23it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 220.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 \n",
      "\t - Train loss: 0.8120 Train acc: 77.5834 Val loss: 0.8259 Val acc:77.3885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 87.28it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 229.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 \n",
      "\t - Train loss: 0.8099 Train acc: 77.6161 Val loss: 0.8259 Val acc:77.3994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 87.13it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 218.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 \n",
      "\t - Train loss: 0.8086 Train acc: 77.6376 Val loss: 0.8259 Val acc:77.4115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 86.59it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 227.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 \n",
      "\t - Train loss: 0.8074 Train acc: 77.6613 Val loss: 0.8259 Val acc:77.4185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 85.71it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 217.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 \n",
      "\t - Train loss: 0.8066 Train acc: 77.6762 Val loss: 0.8260 Val acc:77.4239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 85.54it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 225.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 \n",
      "\t - Train loss: 0.8057 Train acc: 77.6908 Val loss: 0.8258 Val acc:77.4308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 85.79it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 218.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 \n",
      "\t - Train loss: 0.8052 Train acc: 77.6996 Val loss: 0.8260 Val acc:77.4320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 86.81it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 231.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 \n",
      "\t - Train loss: 0.8045 Train acc: 77.7104 Val loss: 0.8264 Val acc:77.4372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 86.65it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 226.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 \n",
      "\t - Train loss: 0.8041 Train acc: 77.7225 Val loss: 0.8266 Val acc:77.4405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 86.99it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 222.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 \n",
      "\t - Train loss: 0.8036 Train acc: 77.7315 Val loss: 0.8263 Val acc:77.4478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 84.55it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 187.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 \n",
      "\t - Train loss: 0.8032 Train acc: 77.7389 Val loss: 0.8266 Val acc:77.4516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lr=5e-3\n",
    "Adam = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "writer = SummaryWriter(\"runs/Word2Vec_v3\")\n",
    "\n",
    "list_train_loss, list_train_acc, list_val_loss, list_val_acc = training(\n",
    "    model=model,\n",
    "    E=E,\n",
    "    loss_fn=MyLoss,\n",
    "    optimizer=Adam,\n",
    "    train_dataloader=train_dataloader, \n",
    "    valid_dataloader=valid_dataloader,\n",
    "    writer=writer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, root=\"runs/Word2Vec_v3/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourth model : same radius, bigger ratio K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "R=4\n",
    "K=4\n",
    "B=32\n",
    "E=20\n",
    "VOCSIZE=tokenizer.vocab_size\n",
    "D=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CustomDataset(document_train_set, R)\n",
    "valid_set = CustomDataset(document_valid_set, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn_with_params = functools.partial(collate_fn, R=R, K=K, VOCSIZE=VOCSIZE)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_set, batch_size=B, collate_fn=collate_fn_with_params\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_set, batch_size=B, collate_fn=collate_fn_with_params\n",
    ")\n",
    "n_valid = len(valid_set)\n",
    "n_train = len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word2Vec(\n",
       "  (emb): Embedding(30522, 100, padding_idx=0)\n",
       ")"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(VOCSIZE, D)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:17<00:00, 72.21it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 174.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "\t - Train loss: 1.8261 Train acc: 75.0745 Val loss: 1.0261 Val acc:79.2042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:16<00:00, 73.66it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 165.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "\t - Train loss: 0.9286 Train acc: 80.1207 Val loss: 0.8822 Val acc:80.4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:17<00:00, 72.21it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 166.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \n",
      "\t - Train loss: 0.8550 Train acc: 80.7487 Val loss: 0.8448 Val acc:80.9695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:17<00:00, 73.30it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 174.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \n",
      "\t - Train loss: 0.8292 Train acc: 81.2510 Val loss: 0.8283 Val acc:81.3136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:17<00:00, 73.00it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 163.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 \n",
      "\t - Train loss: 0.8162 Train acc: 81.4863 Val loss: 0.8202 Val acc:81.5118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:16<00:00, 73.55it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 171.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 \n",
      "\t - Train loss: 0.8082 Train acc: 81.6494 Val loss: 0.8158 Val acc:81.6465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:16<00:00, 73.98it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 175.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 \n",
      "\t - Train loss: 0.8029 Train acc: 81.7595 Val loss: 0.8135 Val acc:81.7192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:16<00:00, 74.01it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 172.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 \n",
      "\t - Train loss: 0.7992 Train acc: 81.8269 Val loss: 0.8124 Val acc:81.7478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:17<00:00, 73.09it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 172.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 \n",
      "\t - Train loss: 0.7964 Train acc: 81.8704 Val loss: 0.8119 Val acc:81.7774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:17<00:00, 71.02it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 141.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 \n",
      "\t - Train loss: 0.7942 Train acc: 81.8988 Val loss: 0.8118 Val acc:81.7994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:18<00:00, 67.80it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 142.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 \n",
      "\t - Train loss: 0.7923 Train acc: 81.9206 Val loss: 0.8121 Val acc:81.8037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:18<00:00, 68.71it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 141.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 \n",
      "\t - Train loss: 0.7909 Train acc: 81.9416 Val loss: 0.8123 Val acc:81.8285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:18<00:00, 68.97it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 149.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 \n",
      "\t - Train loss: 0.7896 Train acc: 81.9625 Val loss: 0.8129 Val acc:81.8308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:18<00:00, 69.14it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 148.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 \n",
      "\t - Train loss: 0.7886 Train acc: 81.9815 Val loss: 0.8132 Val acc:81.8526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:17<00:00, 69.62it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 147.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 \n",
      "\t - Train loss: 0.7878 Train acc: 81.9976 Val loss: 0.8135 Val acc:81.8673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:18<00:00, 69.32it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 149.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 \n",
      "\t - Train loss: 0.7871 Train acc: 82.0139 Val loss: 0.8134 Val acc:81.8851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:17<00:00, 70.29it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 155.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 \n",
      "\t - Train loss: 0.7866 Train acc: 82.0270 Val loss: 0.8137 Val acc:81.8882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:18<00:00, 69.16it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 148.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 \n",
      "\t - Train loss: 0.7861 Train acc: 82.0410 Val loss: 0.8140 Val acc:81.8961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:18<00:00, 69.10it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 145.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 \n",
      "\t - Train loss: 0.7856 Train acc: 82.0514 Val loss: 0.8139 Val acc:81.9207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:17<00:00, 71.56it/s]\n",
      "100%|██████████| 313/313 [00:01<00:00, 159.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 \n",
      "\t - Train loss: 0.7851 Train acc: 82.0658 Val loss: 0.8140 Val acc:81.9321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lr=5e-3\n",
    "Adam = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "writer = SummaryWriter(\"runs/Word2Vec_v4\")\n",
    "\n",
    "list_train_loss, list_train_acc, list_val_loss, list_val_acc = training(\n",
    "    model=model,\n",
    "    E=E,\n",
    "    loss_fn=MyLoss,\n",
    "    optimizer=Adam,\n",
    "    train_dataloader=train_dataloader, \n",
    "    valid_dataloader=valid_dataloader,\n",
    "    writer=writer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, root=\"runs/Word2Vec_v4/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 4 models in : \n",
    "- runs\\Word2Vec_v1\\model_dim-200_radius-4_ratio-2-batch-32-epoch-20.ckpt\n",
    "- runs\\Word2Vec_v2\\model_dim-100_radius-4_ratio-2-batch-32-epoch-20.ckpt\n",
    "- runs\\Word2Vec_v3\\model_dim-100_radius-8_ratio-1-batch-32-epoch-20.ckpt\n",
    "- runs\\Word2Vec_v4\\model_dim-100_radius-4_ratio-4-batch-32-epoch-20.ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Classification Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reloading everything, so that this part is independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version de pytorch :  2.3.0+cu121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tabulate import tabulate\n",
    "from datasets import load_dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "import functools\n",
    "from typing import Any\n",
    "import gc\n",
    "\n",
    "print(\"Version de pytorch : \", torch.__version__)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"scikit-learn/imdb\", split=\"train\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
    "def preprocessing_fn(x, tokenizer):\n",
    "    x[\"review_ids\"] = tokenizer(\n",
    "        x[\"review\"],\n",
    "        add_special_tokens=False,\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=False,\n",
    "    )[\"input_ids\"]\n",
    "    x[\"label\"] = 0 if x[\"sentiment\"] == \"negative\" else 1\n",
    "    return x\n",
    "\n",
    "dataset.shuffle(seed=1)\n",
    "full_dataset = dataset.map(\n",
    "    preprocessing_fn, fn_kwargs={\"tokenizer\" : tokenizer}\n",
    ")\n",
    "full_dataset = full_dataset.select_columns([\"review_ids\", \"label\"])\n",
    "splitted_dataset = full_dataset.train_test_split(0.2)\n",
    "train_set = splitted_dataset[\"train\"]\n",
    "valid_set = splitted_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCollator:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # `batch` is a list of dictionary with keys \"review_ids\" and \"label\".\n",
    "        features = [{\"input_ids\": x[\"review_ids\"]} for x in batch]\n",
    "        features = self.tokenizer.pad(\n",
    "            features, padding=\"max_length\", max_length=256, return_tensors=\"pt\"\n",
    "        )\n",
    "        label = torch.tensor([x[\"label\"] for x in batch])[:, None]\n",
    "        return {\"review_ids\": features[\"input_ids\"], \"label\": label}\n",
    "\n",
    "data_collator = DataCollator(tokenizer)\n",
    "\n",
    "B = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_set, batch_size=B, collate_fn=data_collator\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_set, batch_size=B, collate_fn=data_collator\n",
    ")\n",
    "n_valid = len(valid_set)\n",
    "n_train = len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 32 # batch size\n",
    "D = 100 # embedding dim\n",
    "VOCSIZE = tokenizer.vocab_size\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a function load_model that takes a path to a saved Word2Vec\n",
    "embeddings (with the previous formatting) and loads the checkpoint the\n",
    "embeddings directly to the ConvolutionModel (you can use either the\n",
    "state-of-the art model or the first small model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionModel(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_weights, channels, kernel_size, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.vocsize, self.emb_dim = emb_weights.shape\n",
    "        self.emb = nn.Embedding(self.vocsize, self.emb_dim, padding_idx=0)\n",
    "        self.emb.weight = emb_weights\n",
    "        \n",
    "        self.conv = nn.Conv1d(self.emb_dim, channels, kernel_size)\n",
    "        self.activ = nn.ReLU()\n",
    "        self.pool = nn.AdaptiveAvgPool1d(output_size=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.hidden_layers = nn.Sequential(\n",
    "            self.conv, self.activ, self.pool, self.dropout\n",
    "        )\n",
    "        self.lin = nn.Linear(channels, 1)\n",
    "\n",
    "    def __call__(self, input_ids):\n",
    "        '''input_ids (B, L) \n",
    "        where B is batch_size, L is max_length, D is emb_dim, C is channels'''\n",
    "        emb = self.emb(input_ids).mT # (B,L) -> emb -> (B,L,D) -> .mT -> (B,D,L)\n",
    "        return self.lin(self.hidden_layers(emb).squeeze()) # (B,D,L) -> hidden_layers -> (B,C,1) -> squeeze -> (B,C) ->  (B,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_filepath, *args, **kwargs):\n",
    "    embeddings_weights = torch.load(model_filepath)\n",
    "    model = ConvolutionModel(embeddings_weights, *args, **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_model = load_model(\n",
    "    model_filepath=r\"runs\\Word2Vec_v2\\model_dim-100_radius-4_ratio-2-batch-32-epoch-20.ckpt\",\n",
    "    channels=8,\n",
    "    kernel_size=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionModel(\n",
       "  (emb): Embedding(30522, 100, padding_idx=0)\n",
       "  (conv): Conv1d(100, 8, kernel_size=(3,), stride=(1,))\n",
       "  (activ): ReLU()\n",
       "  (pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (hidden_layers): Sequential(\n",
       "    (0): Conv1d(100, 8, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): AdaptiveAvgPool1d(output_size=1)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (lin): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = torch.randint(0, VOCSIZE, size=(32,256)).to(DEVICE)\n",
    "cls_model(test_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[\"label\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train the model, initialized with these embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, valid_dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0.\n",
    "        correct = 0\n",
    "        for batch in tqdm(valid_dataloader):\n",
    "            input_ids, target = batch[\"review_ids\"].to(DEVICE), batch[\"label\"].float().to(DEVICE)\n",
    "            output = model(input_ids)\n",
    "            loss = loss_fn(output, target)\n",
    "            total_loss += loss.detach().cpu().item()\n",
    "            correct += ((output>=0) == target).float().sum().cpu().item()\n",
    "    return total_loss / len(valid_dataloader), 100*correct / (len(valid_dataloader)*valid_dataloader.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, E, loss_fn, optimizer, train_dataloader, valid_dataloader, writer):\n",
    "\n",
    "    # Performance metric tracking\n",
    "    list_val_acc = []\n",
    "    list_train_acc = []\n",
    "    list_train_loss = []\n",
    "    list_val_loss = []\n",
    "\n",
    "    for e in range(E):\n",
    "        # ========== Training ==========\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        correct = 0\n",
    "        for batch in tqdm(train_dataloader):\n",
    "            input_ids, target = batch[\"review_ids\"].to(DEVICE), batch[\"label\"].float().to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input_ids)\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.detach().cpu().item()\n",
    "            correct += ((output>=0) == target).float().sum().cpu().item()\n",
    "        list_train_loss.append(train_loss / len(train_dataloader))\n",
    "        list_train_acc.append(100 * correct / (len(train_dataloader) * train_dataloader.batch_size))\n",
    "\n",
    "        # ========== Validation ==========\n",
    "        l, a = validation(model, valid_dataloader, loss_fn)\n",
    "        list_val_loss.append(l)\n",
    "        list_val_acc.append(a)\n",
    "        # Tensorboard\n",
    "        writer.add_scalar(\"Train loss\", list_train_loss[-1], e)\n",
    "        writer.add_scalar(\"Val loss\", list_val_loss[-1], e)\n",
    "        writer.add_scalar(\"Train acc\", list_train_acc[-1], e)\n",
    "        writer.add_scalar(\"Val acc\", list_val_acc[-1], e)\n",
    "        print(\n",
    "            e,\n",
    "            \"\\n\\t - Train loss: {:.4f}\".format(list_train_loss[-1]),\n",
    "            \"Train acc: {:.4f}\".format(list_train_acc[-1]),\n",
    "            \"Val loss: {:.4f}\".format(l),\n",
    "            \"Val acc:{:.4f}\".format(a),\n",
    "        )\n",
    "    return list_train_loss, list_train_acc, list_val_loss, list_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:13<00:00, 94.80it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 137.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "\t - Train loss: 0.4623 Train acc: 77.4725 Val loss: 0.3322 Val acc:87.3103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 86.89it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 134.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "\t - Train loss: 0.3734 Train acc: 82.8700 Val loss: 0.3148 Val acc:86.8411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 89.02it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 141.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \n",
      "\t - Train loss: 0.3365 Train acc: 84.9050 Val loss: 0.3107 Val acc:87.1006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 88.30it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 135.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \n",
      "\t - Train loss: 0.3028 Train acc: 86.7575 Val loss: 0.3219 Val acc:86.4617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 88.37it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 142.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 \n",
      "\t - Train loss: 0.2800 Train acc: 87.7100 Val loss: 0.3457 Val acc:85.5831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BCE = nn.BCEWithLogitsLoss()\n",
    "lr = 5e-3\n",
    "Adam = torch.optim.Adam(cls_model.parameters(), lr)\n",
    "writer = SummaryWriter(\"runs/Classification_pretrained_v2\")\n",
    "\n",
    "list_train_loss, list_train_acc, list_val_loss, list_val_acc = training(\n",
    "    cls_model,\n",
    "    epochs,\n",
    "    BCE,\n",
    "    Adam,\n",
    "    train_dataloader,\n",
    "    valid_dataloader,\n",
    "    writer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Compare the results with the model without this initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionModel(\n",
       "  (emb): Embedding(30522, 100, padding_idx=0)\n",
       "  (conv): Conv1d(100, 8, kernel_size=(3,), stride=(1,))\n",
       "  (activ): ReLU()\n",
       "  (pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (hidden_layers): Sequential(\n",
       "    (0): Conv1d(100, 8, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): AdaptiveAvgPool1d(output_size=1)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (lin): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_model2 = ConvolutionModel(\n",
    "    emb_weights=torch.nn.parameter.Parameter(torch.randn(VOCSIZE, D)),\n",
    "    channels=8,\n",
    "    kernel_size=3\n",
    ")\n",
    "cls_model2.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:12<00:00, 97.91it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 146.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "\t - Train loss: 0.4944 Train acc: 75.0150 Val loss: 0.3348 Val acc:86.5615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:13<00:00, 91.38it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 148.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "\t - Train loss: 0.3860 Train acc: 82.8100 Val loss: 0.3159 Val acc:86.8910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:13<00:00, 93.12it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 149.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \n",
      "\t - Train loss: 0.3433 Train acc: 85.1850 Val loss: 0.3146 Val acc:86.6114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:13<00:00, 91.11it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 143.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \n",
      "\t - Train loss: 0.3187 Train acc: 86.3675 Val loss: 0.3198 Val acc:86.3618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:13<00:00, 92.01it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 139.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 \n",
      "\t - Train loss: 0.2960 Train acc: 87.8225 Val loss: 0.3319 Val acc:86.0823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BCE = nn.BCEWithLogitsLoss()\n",
    "lr = 5e-3\n",
    "Adam = torch.optim.Adam(cls_model2.parameters(), lr)\n",
    "writer = SummaryWriter(\"runs/Classification_scratch\")\n",
    "\n",
    "list_train_loss, list_train_acc, list_val_loss, list_val_acc = training(\n",
    "    cls_model2,\n",
    "    epochs,\n",
    "    BCE,\n",
    "    Adam,\n",
    "    train_dataloader,\n",
    "    valid_dataloader,\n",
    "    writer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Make a small ablation study on the influence of some parameters of the\n",
    "Word2Vec model on the classification task. Analyze the results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec_v3 : D=100, R=8, K=1, B=32, E=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionModel(\n",
       "  (emb): Embedding(30522, 100, padding_idx=0)\n",
       "  (conv): Conv1d(100, 8, kernel_size=(3,), stride=(1,))\n",
       "  (activ): ReLU()\n",
       "  (pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (hidden_layers): Sequential(\n",
       "    (0): Conv1d(100, 8, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): AdaptiveAvgPool1d(output_size=1)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (lin): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_model3 = load_model(model_filepath=r\"runs\\Word2Vec_v3\\model_dim-100_radius-8_ratio-1-batch-32-epoch-20.ckpt\", channels=8, kernel_size=3)\n",
    "cls_model3.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:13<00:00, 95.72it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 147.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "\t - Train loss: 0.4836 Train acc: 75.5775 Val loss: 0.3438 Val acc:85.8027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:13<00:00, 90.36it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 144.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "\t - Train loss: 0.3963 Train acc: 81.7150 Val loss: 0.3287 Val acc:85.7728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:13<00:00, 90.04it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 147.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \n",
      "\t - Train loss: 0.3518 Train acc: 84.2900 Val loss: 0.3360 Val acc:84.9740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 85.69it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 133.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \n",
      "\t - Train loss: 0.3208 Train acc: 86.1300 Val loss: 0.3463 Val acc:84.8642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 87.71it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 146.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 \n",
      "\t - Train loss: 0.2948 Train acc: 87.3275 Val loss: 0.3707 Val acc:83.6761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BCE = nn.BCEWithLogitsLoss()\n",
    "lr = 5e-3\n",
    "Adam = torch.optim.Adam(cls_model3.parameters(), lr)\n",
    "writer = SummaryWriter(\"runs/Classification_pretrained_v3\")\n",
    "\n",
    "list_train_loss, list_train_acc, list_val_loss, list_val_acc = training(\n",
    "    cls_model3,\n",
    "    epochs,\n",
    "    BCE,\n",
    "    Adam,\n",
    "    train_dataloader,\n",
    "    valid_dataloader,\n",
    "    writer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec_v4 : D=100, R=4, K=4, B=32, E=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionModel(\n",
       "  (emb): Embedding(30522, 100, padding_idx=0)\n",
       "  (conv): Conv1d(100, 8, kernel_size=(3,), stride=(1,))\n",
       "  (activ): ReLU()\n",
       "  (pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (hidden_layers): Sequential(\n",
       "    (0): Conv1d(100, 8, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): AdaptiveAvgPool1d(output_size=1)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (lin): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_model4 = load_model(model_filepath=r\"runs\\Word2Vec_v4\\model_dim-100_radius-4_ratio-4-batch-32-epoch-20.ckpt\", channels=8, kernel_size=3)\n",
    "cls_model4.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:13<00:00, 92.71it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 138.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "\t - Train loss: 0.4714 Train acc: 76.6275 Val loss: 0.3256 Val acc:86.9010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 89.13it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 143.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "\t - Train loss: 0.3820 Train acc: 82.6150 Val loss: 0.3132 Val acc:86.9708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 86.89it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 145.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \n",
      "\t - Train loss: 0.3407 Train acc: 85.1500 Val loss: 0.3247 Val acc:86.1322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 88.59it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 146.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \n",
      "\t - Train loss: 0.3096 Train acc: 86.8975 Val loss: 0.3324 Val acc:86.1222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 88.64it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 139.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 \n",
      "\t - Train loss: 0.2877 Train acc: 87.7125 Val loss: 0.3527 Val acc:85.1038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BCE = nn.BCEWithLogitsLoss()\n",
    "lr = 5e-3\n",
    "Adam = torch.optim.Adam(cls_model4.parameters(), lr)\n",
    "writer = SummaryWriter(\"runs/Classification_pretrained_v4\")\n",
    "\n",
    "list_train_loss, list_train_acc, list_val_loss, list_val_acc = training(\n",
    "    cls_model4,\n",
    "    epochs,\n",
    "    BCE,\n",
    "    Adam,\n",
    "    train_dataloader,\n",
    "    valid_dataloader,\n",
    "    writer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec_v1 : D=200, R=4, K=2, B=32, E=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionModel(\n",
       "  (emb): Embedding(30522, 200, padding_idx=0)\n",
       "  (conv): Conv1d(200, 8, kernel_size=(3,), stride=(1,))\n",
       "  (activ): ReLU()\n",
       "  (pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (hidden_layers): Sequential(\n",
       "    (0): Conv1d(200, 8, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): AdaptiveAvgPool1d(output_size=1)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (lin): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_model1 = load_model(model_filepath=r\"runs\\Word2Vec_v1\\model_dim-200_radius-4_ratio-2-batch-32-epoch-20.ckpt\", channels=8, kernel_size=3)\n",
    "cls_model1.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 85.98it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 145.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "\t - Train loss: 0.4645 Train acc: 76.8925 Val loss: 0.3338 Val acc:86.7312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 88.03it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 152.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "\t - Train loss: 0.3787 Train acc: 82.8900 Val loss: 0.3167 Val acc:86.6314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 88.14it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 156.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \n",
      "\t - Train loss: 0.3387 Train acc: 85.3125 Val loss: 0.3175 Val acc:86.7612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 86.93it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 152.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \n",
      "\t - Train loss: 0.3107 Train acc: 86.6875 Val loss: 0.3309 Val acc:86.1122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:14<00:00, 87.68it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 151.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 \n",
      "\t - Train loss: 0.2834 Train acc: 88.1950 Val loss: 0.3513 Val acc:85.6230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BCE = nn.BCEWithLogitsLoss()\n",
    "lr = 5e-3\n",
    "Adam = torch.optim.Adam(cls_model1.parameters(), lr)\n",
    "writer = SummaryWriter(\"runs/Classification_pretrained_v1\")\n",
    "\n",
    "list_train_loss, list_train_acc, list_val_loss, list_val_acc = training(\n",
    "    cls_model1,\n",
    "    epochs,\n",
    "    BCE,\n",
    "    Adam,\n",
    "    train_dataloader,\n",
    "    valid_dataloader,\n",
    "    writer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis :\n",
    "R=8, K=1 is worse than (R=4,K=2). The best we've had is (R=4,K=4). <br>\n",
    "So too big radius is not good, it may yield consider tokens that have nothing in common to have close embeddings. <br>\n",
    "D=100 is better than D=200 (embedding dimension) <br>\n",
    "Because for our small classification problem it overfits, 100 is enough. <br>\n",
    "\n",
    "Having pretrained embeddings is better for the classfication, though the difference between a pretrained and a one randomly initialized one doesn't seem that big. We only observe a difference before epoch 1, after that it catches up quickly, at leatst for our classification problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
