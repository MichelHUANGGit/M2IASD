{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The first cells of the notebook are the same as in the TP on text convolution. Apply the same preprocessing to get a dataset (with the same tokenizer) with a train and a validation split, with two columns review_ids (list of int) and label (int)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER** : Copying what we did in the TP on text convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huang\\Desktop\\M2IASD\\NLP\\NLP\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torch.utils.data import DataLoader\n",
    "from tabulate import tabulate\n",
    "from datasets import load_dataset\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version de pytorch :  2.2.0+cu121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Version de pytorch : \", torch.__version__)\n",
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['review', 'sentiment'],\n",
      "    num_rows: 50000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"scikit-learn/imdb\", split=\"train\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of the tokenizer: <class 'collections.OrderedDict'>\n",
      "Length of the vocabulary: 30522\n",
      "OrderedDict({'[PAD]': 0, '[unused0]': 1, '[unused1\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of the tokenizer:\", type(tokenizer.vocab))\n",
    "VOCSIZE = len(tokenizer.vocab)\n",
    "print(\"Length of the vocabulary:\", VOCSIZE)\n",
    "print(str(tokenizer.vocab)[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_fn(x, tokenizer):\n",
    "    x[\"review_ids\"] = tokenizer(\n",
    "        x[\"review\"],\n",
    "        add_special_tokens=False,\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        padding=False,\n",
    "        return_attention_mask=False,\n",
    "    )[\"input_ids\"]\n",
    "    x[\"label\"] = 0 if x[\"sentiment\"] == \"negative\" else 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': \"An awful film! It must have been up against some real stinkers to be nominated for the Golden Globe. They've taken the story of the first famous female Renaissance painter and mangled it beyond recognition. My complaint is not that they've taken liberties with the facts; if the story were good, that would perfectly fine. But it's simply bizarre -- by all accounts the true story of this artist would have made for a far better film, so why did they come up with this dishwater-dull script? I suppose there weren't enough naked people in the factual version. It's hurriedly capped off in the end with a summary of the artist's life -- we could have saved ourselves a couple of hours if they'd favored the rest of the film with same brevity.\",\n",
       " 'sentiment': 'negative',\n",
       " 'review_ids': [2019,\n",
       "  9643,\n",
       "  2143,\n",
       "  999,\n",
       "  2009,\n",
       "  2442,\n",
       "  2031,\n",
       "  2042,\n",
       "  2039,\n",
       "  2114,\n",
       "  2070,\n",
       "  2613,\n",
       "  27136,\n",
       "  2545,\n",
       "  2000,\n",
       "  2022,\n",
       "  4222,\n",
       "  2005,\n",
       "  1996,\n",
       "  3585,\n",
       "  7595,\n",
       "  1012,\n",
       "  2027,\n",
       "  1005,\n",
       "  2310,\n",
       "  2579,\n",
       "  1996,\n",
       "  2466,\n",
       "  1997,\n",
       "  1996,\n",
       "  2034,\n",
       "  3297,\n",
       "  2931,\n",
       "  8028,\n",
       "  5276,\n",
       "  1998,\n",
       "  2158,\n",
       "  11533,\n",
       "  2009,\n",
       "  3458,\n",
       "  5038,\n",
       "  1012,\n",
       "  2026,\n",
       "  12087,\n",
       "  2003,\n",
       "  2025,\n",
       "  2008,\n",
       "  2027,\n",
       "  1005,\n",
       "  2310,\n",
       "  2579,\n",
       "  18271,\n",
       "  2007,\n",
       "  1996,\n",
       "  8866,\n",
       "  1025,\n",
       "  2065,\n",
       "  1996,\n",
       "  2466,\n",
       "  2020,\n",
       "  2204,\n",
       "  1010,\n",
       "  2008,\n",
       "  2052,\n",
       "  6669,\n",
       "  2986,\n",
       "  1012,\n",
       "  2021,\n",
       "  2009,\n",
       "  1005,\n",
       "  1055,\n",
       "  3432,\n",
       "  13576,\n",
       "  1011,\n",
       "  1011,\n",
       "  2011,\n",
       "  2035,\n",
       "  6115,\n",
       "  1996,\n",
       "  2995,\n",
       "  2466,\n",
       "  1997,\n",
       "  2023,\n",
       "  3063,\n",
       "  2052,\n",
       "  2031,\n",
       "  2081,\n",
       "  2005,\n",
       "  1037,\n",
       "  2521,\n",
       "  2488,\n",
       "  2143,\n",
       "  1010,\n",
       "  2061,\n",
       "  2339,\n",
       "  2106,\n",
       "  2027,\n",
       "  2272,\n",
       "  2039,\n",
       "  2007,\n",
       "  2023,\n",
       "  9841,\n",
       "  5880,\n",
       "  1011,\n",
       "  10634,\n",
       "  5896,\n",
       "  1029,\n",
       "  1045,\n",
       "  6814,\n",
       "  2045,\n",
       "  4694,\n",
       "  1005,\n",
       "  1056,\n",
       "  2438,\n",
       "  6248,\n",
       "  2111,\n",
       "  1999,\n",
       "  1996,\n",
       "  25854,\n",
       "  2544,\n",
       "  1012,\n",
       "  2009,\n",
       "  1005,\n",
       "  1055,\n",
       "  23878,\n",
       "  13880,\n",
       "  2125,\n",
       "  1999,\n",
       "  1996,\n",
       "  2203,\n",
       "  2007,\n",
       "  1037,\n",
       "  12654,\n",
       "  1997,\n",
       "  1996,\n",
       "  3063,\n",
       "  1005,\n",
       "  1055,\n",
       "  2166,\n",
       "  1011,\n",
       "  1011,\n",
       "  2057,\n",
       "  2071,\n",
       "  2031,\n",
       "  5552,\n",
       "  9731,\n",
       "  1037,\n",
       "  3232,\n",
       "  1997,\n",
       "  2847,\n",
       "  2065,\n",
       "  2027,\n",
       "  1005,\n",
       "  1040,\n",
       "  12287,\n",
       "  1996,\n",
       "  2717,\n",
       "  1997,\n",
       "  1996,\n",
       "  2143,\n",
       "  2007,\n",
       "  2168,\n",
       "  7987,\n",
       "  6777,\n",
       "  3012,\n",
       "  1012],\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_fn(dataset[19], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5000  # the number of training example\n",
    "\n",
    "# We first shuffle the data !\n",
    "dataset = dataset.shuffle(seed=0)\n",
    "\n",
    "# Select 5000 samples\n",
    "sampled_dataset = dataset.select(range(n_samples))\n",
    "\n",
    "# Tokenize the dataset\n",
    "sampled_dataset = sampled_dataset.map(\n",
    "    preprocessing_fn, fn_kwargs={\"tokenizer\" : tokenizer}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove useless columns\n",
    "sampled_dataset = sampled_dataset.select_columns(['review_ids','label'])\n",
    "\n",
    "# Split the train and validation\n",
    "splitted_dataset = sampled_dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "train_set = splitted_dataset['train']\n",
    "valid_set = splitted_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review_ids': [2023,\n",
       "  3185,\n",
       "  2001,\n",
       "  2200,\n",
       "  2200,\n",
       "  19960,\n",
       "  3695,\n",
       "  16748,\n",
       "  1998,\n",
       "  2200,\n",
       "  2200,\n",
       "  2175,\n",
       "  2854,\n",
       "  1012,\n",
       "  3071,\n",
       "  2187,\n",
       "  2037,\n",
       "  3772,\n",
       "  8220,\n",
       "  2012,\n",
       "  2188,\n",
       "  1998,\n",
       "  6135,\n",
       "  9471,\n",
       "  2129,\n",
       "  2000,\n",
       "  2552,\n",
       "  1045,\n",
       "  2812,\n",
       "  2009,\n",
       "  2001,\n",
       "  2061,\n",
       "  2919,\n",
       "  1998,\n",
       "  2018,\n",
       "  2053,\n",
       "  2613,\n",
       "  5436,\n",
       "  1998,\n",
       "  11793,\n",
       "  2545,\n",
       "  2071,\n",
       "  2031,\n",
       "  2517,\n",
       "  1037,\n",
       "  2488,\n",
       "  2466,\n",
       "  5436,\n",
       "  3524,\n",
       "  2054,\n",
       "  2466,\n",
       "  5436,\n",
       "  1012,\n",
       "  2025,\n",
       "  2012,\n",
       "  2035,\n",
       "  12459,\n",
       "  999],\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a function extract_words_contexts. It should retrieve all pairs of valid $(w, C^+)$ from a list of ids representing a text document. It takes the radius $R$ as an argument. Its output is therefore two lists :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to make sure that every C has the same size, we add padding at the beginning and the end of the sentence. For example the first word of the sentence, will have R paddings corresponding to the R tokens that should be before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words_contexts(sample, R):\n",
    "    token_ids = sample[\"review_ids\"]\n",
    "    n_tokens = len(token_ids)\n",
    "    local_window = []\n",
    "    token_ids_with_padding = [0]*R + token_ids + [0]*R\n",
    "    for i in range(n_tokens) :\n",
    "        # if out of bounds\n",
    "        if i<R or i>=n_tokens-R :\n",
    "            local_window.append([token_ids_with_padding[i+r] for r in range(R)] + [token_ids_with_padding[i+R+r] for r in range(1,R+1, 1)])\n",
    "        else :\n",
    "            local_window.append([token_ids[i+r] for r in range(-R, 0, 1)] + [token_ids[i+r] for r in range(1, R+1, 1)])\n",
    "    return token_ids, local_window\n",
    "\n",
    "toto, tata = extract_words_contexts(train_set[0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 15373, 2006],\n",
       " [0, 1000, 2006, 2148],\n",
       " [1000, 15373, 2148, 2395],\n",
       " [15373, 2006, 2395, 1000],\n",
       " [2006, 2148, 1000, 2003],\n",
       " [2148, 2395, 2003, 1037],\n",
       " [2395, 1000, 1037, 2152],\n",
       " [1000, 2003, 2152, 3177],\n",
       " [2003, 1037, 3177, 3689],\n",
       " [1037, 2152, 3689, 2055],\n",
       " [2152, 3177, 2055, 1037],\n",
       " [3177, 3689, 1037, 2235],\n",
       " [3689, 2055, 2235, 2051],\n",
       " [2055, 1037, 2051, 4735],\n",
       " [1037, 2235, 4735, 2040],\n",
       " [2235, 2051, 2040, 3402],\n",
       " [2051, 4735, 3402, 4858],\n",
       " [4735, 2040, 4858, 2370],\n",
       " [2040, 3402, 2370, 7861],\n",
       " [3402, 4858, 7861, 12618],\n",
       " [4858, 2370, 12618, 18450],\n",
       " [2370, 7861, 18450, 1999],\n",
       " [7861, 12618, 1999, 1996],\n",
       " [12618, 18450, 1996, 3450],\n",
       " [18450, 1999, 3450, 1997],\n",
       " [1999, 1996, 1997, 1037],\n",
       " [1996, 3450, 1037, 2177],\n",
       " [3450, 1997, 2177, 1997],\n",
       " [1997, 1037, 1997, 13009],\n",
       " [1037, 2177, 13009, 1012],\n",
       " [2177, 1997, 1012, 1996],\n",
       " [1997, 13009, 1996, 2895],\n",
       " [13009, 1012, 2895, 2003],\n",
       " [1012, 1996, 2003, 3591],\n",
       " [1996, 2895, 3591, 1999],\n",
       " [2895, 2003, 1999, 1037],\n",
       " [2003, 3591, 1037, 2200],\n",
       " [3591, 1999, 2200, 3622],\n",
       " [1999, 1037, 3622, 1998],\n",
       " [1037, 2200, 1998, 8790],\n",
       " [2200, 3622, 8790, 2806],\n",
       " [3622, 1998, 2806, 1998],\n",
       " [1998, 8790, 1998, 1996],\n",
       " [8790, 2806, 1996, 11071],\n",
       " [2806, 1998, 11071, 2003],\n",
       " [1998, 1996, 2003, 2921],\n",
       " [1996, 11071, 2921, 2039],\n",
       " [11071, 2003, 2039, 2011],\n",
       " [2003, 2921, 2011, 2965],\n",
       " [2921, 2039, 2965, 1997],\n",
       " [2039, 2011, 1997, 2070],\n",
       " [2011, 2965, 2070, 8235],\n",
       " [2965, 1997, 8235, 9260],\n",
       " [1997, 2070, 9260, 1012],\n",
       " [2070, 8235, 1012, 1996],\n",
       " [8235, 9260, 1996, 2224],\n",
       " [9260, 1012, 2224, 1997],\n",
       " [1012, 1996, 1997, 1037],\n",
       " [1996, 2224, 1037, 2898],\n",
       " [2224, 1997, 2898, 3528],\n",
       " [1997, 1037, 3528, 1997],\n",
       " [1037, 2898, 1997, 2367],\n",
       " [2898, 3528, 2367, 4950],\n",
       " [3528, 1997, 4950, 12113],\n",
       " [1997, 2367, 12113, 1998],\n",
       " [2367, 4950, 1998, 4621],\n",
       " [4950, 12113, 4621, 2485],\n",
       " [12113, 1998, 2485, 1011],\n",
       " [1998, 4621, 1011, 11139],\n",
       " [4621, 2485, 11139, 2036],\n",
       " [2485, 1011, 2036, 9002],\n",
       " [1011, 11139, 9002, 2000],\n",
       " [11139, 2036, 2000, 1996],\n",
       " [2036, 9002, 1996, 3452],\n",
       " [9002, 2000, 3452, 8605],\n",
       " [2000, 1996, 8605, 1997],\n",
       " [1996, 3452, 1997, 5377],\n",
       " [3452, 8605, 5377, 4367],\n",
       " [8605, 1997, 4367, 1998],\n",
       " [1997, 5377, 1998, 8995],\n",
       " [5377, 4367, 8995, 3012],\n",
       " [4367, 1998, 3012, 1012],\n",
       " [1998, 8995, 1012, 5212],\n",
       " [8995, 3012, 5212, 12548],\n",
       " [3012, 1012, 12548, 1005],\n",
       " [1012, 5212, 1005, 1055],\n",
       " [5212, 12548, 1055, 2806],\n",
       " [12548, 1005, 2806, 1997],\n",
       " [1005, 1055, 1997, 9855],\n",
       " [1055, 2806, 9855, 1998],\n",
       " [2806, 1997, 1998, 1996],\n",
       " [1997, 9855, 1996, 16434],\n",
       " [9855, 1998, 16434, 2011],\n",
       " [1998, 1996, 2011, 3312],\n",
       " [1996, 16434, 3312, 10406],\n",
       " [16434, 2011, 10406, 2024],\n",
       " [2011, 3312, 2024, 6581],\n",
       " [3312, 10406, 6581, 1998],\n",
       " [10406, 2024, 1998, 2045],\n",
       " [2024, 6581, 2045, 2024],\n",
       " [6581, 1998, 2024, 2116],\n",
       " [1998, 2045, 2116, 5019],\n",
       " [2045, 2024, 5019, 2029],\n",
       " [2024, 2116, 2029, 2083],\n",
       " [2116, 5019, 2083, 2037],\n",
       " [5019, 2029, 2037, 5512],\n",
       " [2029, 2083, 5512, 1998],\n",
       " [2083, 2037, 1998, 7497],\n",
       " [2037, 5512, 7497, 3965],\n",
       " [5512, 1998, 3965, 1037],\n",
       " [1998, 7497, 1037, 2844],\n",
       " [7497, 3965, 2844, 3168],\n",
       " [3965, 1037, 3168, 1997],\n",
       " [1037, 2844, 1997, 6888],\n",
       " [2844, 3168, 6888, 1998],\n",
       " [3168, 1997, 1998, 7224],\n",
       " [1997, 6888, 7224, 1012],\n",
       " [6888, 1998, 1012, 1026],\n",
       " [1998, 7224, 1026, 7987],\n",
       " [7224, 1012, 7987, 1013],\n",
       " [1012, 1026, 1013, 1028],\n",
       " [1026, 7987, 1028, 1026],\n",
       " [7987, 1013, 1026, 7987],\n",
       " [1013, 1028, 7987, 1013],\n",
       " [1028, 1026, 1013, 1028],\n",
       " [1026, 7987, 1028, 9078],\n",
       " [7987, 1013, 9078, 4060],\n",
       " [1013, 1028, 4060, 6873],\n",
       " [1028, 9078, 6873, 19869],\n",
       " [9078, 4060, 19869, 2102],\n",
       " [4060, 6873, 2102, 1998],\n",
       " [6873, 19869, 1998, 9377],\n",
       " [19869, 2102, 9377, 25042],\n",
       " [2102, 1998, 25042, 13558],\n",
       " [1998, 9377, 13558, 16075],\n",
       " [9377, 25042, 16075, 1006],\n",
       " [25042, 13558, 1006, 2957],\n",
       " [13558, 16075, 2957, 15536],\n",
       " [16075, 1006, 15536, 22117],\n",
       " [1006, 2957, 22117, 17007],\n",
       " [2957, 15536, 17007, 1007],\n",
       " [15536, 22117, 1007, 4152],\n",
       " [22117, 17007, 4152, 2046],\n",
       " [17007, 1007, 2046, 2784],\n",
       " [1007, 4152, 2784, 2300],\n",
       " [4152, 2046, 2300, 2043],\n",
       " [2046, 2784, 2043, 2002],\n",
       " [2784, 2300, 2002, 15539],\n",
       " [2300, 2043, 15539, 1037],\n",
       " [2043, 2002, 1037, 15882],\n",
       " [2002, 15539, 15882, 2013],\n",
       " [15539, 1037, 2013, 1037],\n",
       " [1037, 15882, 1037, 2402],\n",
       " [15882, 2013, 2402, 2450],\n",
       " [2013, 1037, 2450, 2315],\n",
       " [1037, 2402, 2315, 9485],\n",
       " [2402, 2450, 9485, 1006],\n",
       " [2450, 2315, 1006, 3744],\n",
       " [2315, 9485, 3744, 12420],\n",
       " [9485, 1006, 12420, 1007],\n",
       " [1006, 3744, 1007, 2006],\n",
       " [3744, 12420, 2006, 1996],\n",
       " [12420, 1007, 1996, 2047],\n",
       " [1007, 2006, 2047, 2259],\n",
       " [2006, 1996, 2259, 10798],\n",
       " [1996, 2047, 10798, 1012],\n",
       " [2047, 2259, 1012, 2016],\n",
       " [2259, 10798, 2016, 2001],\n",
       " [10798, 1012, 2001, 2108],\n",
       " [1012, 2016, 2108, 2109],\n",
       " [2016, 2001, 2109, 2011],\n",
       " [2001, 2108, 2011, 2014],\n",
       " [2108, 2109, 2014, 4654],\n",
       " [2109, 2011, 4654, 1011],\n",
       " [2011, 2014, 1011, 6898],\n",
       " [2014, 4654, 6898, 9558],\n",
       " [4654, 1011, 9558, 1006],\n",
       " [1011, 6898, 1006, 2957],\n",
       " [6898, 9558, 2957, 11382],\n",
       " [9558, 1006, 11382, 3051],\n",
       " [1006, 2957, 3051, 1007],\n",
       " [2957, 11382, 1007, 2000],\n",
       " [11382, 3051, 2000, 2191],\n",
       " [3051, 1007, 2191, 1037],\n",
       " [1007, 2000, 1037, 6959],\n",
       " [2000, 2191, 6959, 2000],\n",
       " [2191, 1037, 2000, 2028],\n",
       " [1037, 6959, 2028, 1997],\n",
       " [6959, 2000, 1997, 2010],\n",
       " [2000, 2028, 2010, 10402],\n",
       " [2028, 1997, 10402, 1999],\n",
       " [1997, 2010, 1999, 1037],\n",
       " [2010, 10402, 1037, 4750],\n",
       " [10402, 1999, 4750, 5502],\n",
       " [1999, 1037, 5502, 1998],\n",
       " [1037, 4750, 1998, 4242],\n",
       " [4750, 5502, 4242, 2000],\n",
       " [5502, 1998, 2000, 2014],\n",
       " [1998, 4242, 2014, 1010],\n",
       " [4242, 2000, 1010, 2016],\n",
       " [2000, 2014, 2016, 2001],\n",
       " [2014, 1010, 2001, 4755],\n",
       " [1010, 2016, 4755, 2149],\n",
       " [2016, 2001, 2149, 2231],\n",
       " [2001, 4755, 2231, 7800],\n",
       " [4755, 2149, 7800, 2680],\n",
       " [2149, 2231, 2680, 2006],\n",
       " [2231, 7800, 2006, 12702],\n",
       " [7800, 2680, 12702, 23665],\n",
       " [2680, 2006, 23665, 1012],\n",
       " [2006, 12702, 1012, 2048],\n",
       " [12702, 23665, 2048, 8495],\n",
       " [23665, 1012, 8495, 6074],\n",
       " [1012, 2048, 6074, 2018],\n",
       " [2048, 8495, 2018, 2042],\n",
       " [8495, 6074, 2042, 2206],\n",
       " [6074, 2018, 2206, 9485],\n",
       " [2018, 2042, 9485, 1998],\n",
       " [2042, 2206, 1998, 9741],\n",
       " [2206, 9485, 9741, 1996],\n",
       " [9485, 1998, 1996, 11933],\n",
       " [1998, 9741, 11933, 1012],\n",
       " [9741, 1996, 1012, 2028],\n",
       " [1996, 11933, 2028, 1997],\n",
       " [11933, 1012, 1997, 1996],\n",
       " [1012, 2028, 1996, 6074],\n",
       " [2028, 1997, 6074, 4247],\n",
       " [1997, 1996, 4247, 2000],\n",
       " [1996, 6074, 2000, 5725],\n",
       " [6074, 4247, 5725, 2014],\n",
       " [4247, 2000, 2014, 2067],\n",
       " [2000, 5725, 2067, 2000],\n",
       " [5725, 2014, 2000, 9558],\n",
       " [2014, 2067, 9558, 1005],\n",
       " [2067, 2000, 1005, 1055],\n",
       " [2000, 9558, 1055, 4545],\n",
       " [9558, 1005, 4545, 1998],\n",
       " [1005, 1055, 1998, 1996],\n",
       " [1055, 4545, 1996, 2060],\n",
       " [4545, 1998, 2060, 1010],\n",
       " [1998, 1996, 1010, 23564],\n",
       " [1996, 2060, 23564, 2527],\n",
       " [2060, 1010, 2527, 1006],\n",
       " [1010, 23564, 1006, 12688],\n",
       " [23564, 2527, 12688, 8945],\n",
       " [2527, 1006, 8945, 19140],\n",
       " [1006, 12688, 19140, 2100],\n",
       " [12688, 8945, 2100, 1007],\n",
       " [8945, 19140, 1007, 1010],\n",
       " [19140, 2100, 1010, 7879],\n",
       " [2100, 1007, 7879, 2610],\n",
       " [1007, 1010, 2610, 2952],\n",
       " [1010, 7879, 2952, 4907],\n",
       " [7879, 2610, 4907, 6816],\n",
       " [2610, 2952, 6816, 0],\n",
       " [2952, 4907, 0, 0]]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dataset_to_list():\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
